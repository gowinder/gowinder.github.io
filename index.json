[{"categories":null,"content":"useQuery直接使用honojs client报错: TypeError: Cannot read properties of undefined (reading ‘replace’) 最近开发了一个项目, 使用nextjs, honojs, drizzle-orm, 部署在cloudflare pages上, 因为honojs对于边缘计算比较友好,所以采用. ","date":"2024-06-06","objectID":"/honojs-usequery-error/:0:0","tags":["nextjs","cloudflare","cloudflare pages","cloudflare workers","honojs","useQuery"],"title":"useQuery直接使用honojs client报错: TypeError: Cannot read properties of undefined (reading 'replace')","uri":"/honojs-usequery-error/"},{"categories":null,"content":"honojs 查询接口定义 export const runtime = 'edge'; type Bindings = { DB: D1Database; }; const app = new Hono\u003c{ Bindings: Bindings }\u003e() .get('/', async (c) =\u003e { try { const conditions: Record\u003cstring, any\u003e = {}; const results = await getDb().query.someTable.findMany({}); return c.json(results); // return c.json(resultData); } catch (error: Error | any) { console.error(error); return c.json(error); } }); export default app; ","date":"2024-06-06","objectID":"/honojs-usequery-error/:1:0","tags":["nextjs","cloudflare","cloudflare pages","cloudflare workers","honojs","useQuery"],"title":"useQuery直接使用honojs client报错: TypeError: Cannot read properties of undefined (reading 'replace')","uri":"/honojs-usequery-error/"},{"categories":null,"content":"hono app的route设置 const app = new Hono\u003c{ Bindings: Bindings }\u003e().basePath('/api'); const routes = app.route('/sometable', someTable); export const GET = handle(app); export const POST = handle(app); export type AppType = typeof routes; ","date":"2024-06-06","objectID":"/honojs-usequery-error/:2:0","tags":["nextjs","cloudflare","cloudflare pages","cloudflare workers","honojs","useQuery"],"title":"useQuery直接使用honojs client报错: TypeError: Cannot read properties of undefined (reading 'replace')","uri":"/honojs-usequery-error/"},{"categories":null,"content":"useQuery 调用 export const useGetSomeTable = () =\u003e { const query = useQuery({ queryKey: ['someTable'], // 使用 filters 作为查询键 queryFn: async () =\u003e { const response = await client.api.someTable.$get(); console.log('API Response: ', response); if (!response.ok) { throw new Error('Failed to fetch sometable'); } return response.json(); }, throwOnError: true, refetchOnWindowFocus: false, staleTime: 1000 * 60 * 5, }); return query; }; ","date":"2024-06-06","objectID":"/honojs-usequery-error/:3:0","tags":["nextjs","cloudflare","cloudflare pages","cloudflare workers","honojs","useQuery"],"title":"useQuery直接使用honojs client报错: TypeError: Cannot read properties of undefined (reading 'replace')","uri":"/honojs-usequery-error/"},{"categories":null,"content":"调用时报错 TypeError: Cannot read properties of undefined (reading 'replace') 问题出在: const response = await client.api.someTable.$get(); 这里. 调了两天, chatgpt问了, gemini pro问了,试了好多方法,没有结果. 正要放弃时,又回去看了视频教程: https://www.youtube.com/watch?v=N_uNKAus0II\u0026t=23162s, 我是照着来的, 突然发现一个东西: export const client = hc\u003cAppType\u003e(process.env.NEXT_PUBLIC_APP_URL!); 一去检查发现, 我在wrangler.toml中定义了NEXT_PUBLIC_APP_URL, 但是我是bun dev本地启动的, 在.env文件中没有, 于是在.env中增加NEXT_PUBLIC_APP_URL=\"http://localhost:3000\". ","date":"2024-06-06","objectID":"/honojs-usequery-error/:4:0","tags":["nextjs","cloudflare","cloudflare pages","cloudflare workers","honojs","useQuery"],"title":"useQuery直接使用honojs client报错: TypeError: Cannot read properties of undefined (reading 'replace')","uri":"/honojs-usequery-error/"},{"categories":null,"content":"结果 好了, 没有这个变量, hono/client/hc 输入一个undefined 他也不会报错,太奇怪. 记录一下, 喜欢遇到同样问题的人有帮助. ","date":"2024-06-06","objectID":"/honojs-usequery-error/:5:0","tags":["nextjs","cloudflare","cloudflare pages","cloudflare workers","honojs","useQuery"],"title":"useQuery直接使用honojs client报错: TypeError: Cannot read properties of undefined (reading 'replace')","uri":"/honojs-usequery-error/"},{"categories":null,"content":"批量删除Cloudflare KV中的key ","date":"2024-04-18","objectID":"/bulk-delete-key-in-cloudflare-kv/:0:0","tags":["cloudflare","cloudflare pages","cloudflare KV"],"title":"批量删除`Cloudflare KV`中的`key`","uri":"/bulk-delete-key-in-cloudflare-kv/"},{"categories":null,"content":"取得key列表 先执行 pnpm wrangler kv:key list --namespace-id=${namespaceID} \u003e PURGE.json` 拿到完整key列表, 如果要条件,就加上: --prefix=\"prefix\" ","date":"2024-04-18","objectID":"/bulk-delete-key-in-cloudflare-kv/:1:0","tags":["cloudflare","cloudflare pages","cloudflare KV"],"title":"批量删除`Cloudflare KV`中的`key`","uri":"/bulk-delete-key-in-cloudflare-kv/"},{"categories":null,"content":"批量删除 cat purge.json | jq -r '.[].name' | xargs -I {} pnpm wrangler kv:key delete --namespace-id=${namespaceID} {} ","date":"2024-04-18","objectID":"/bulk-delete-key-in-cloudflare-kv/:2:0","tags":["cloudflare","cloudflare pages","cloudflare KV"],"title":"批量删除`Cloudflare KV`中的`key`","uri":"/bulk-delete-key-in-cloudflare-kv/"},{"categories":null,"content":"将remix项目迁移到cloudflare 最近使用remix开发了一个项目,之前没有做过全栈开发,reactjs用过一些,不是很熟,用的是Nextjs, 感觉太难用, 主要是13版本换了app router后,有点摸不着头脑了. 后来发现remix这个, 直接用文件名路由,要方便许多, loader, action 的方式也非常直观, 于是就选用了remix 项目开发得差不多了,就想怎么部署,之前准备Vercel, 有一天看到 https://blog.meathill.com/infra/vercel-vs-cloudflare-pages-how-to-choose-to-deploy-your-website.html, 还是觉得cloudflare猛啊(适合白嫖) 于是准备迁移到cloudflare ","date":"2024-04-08","objectID":"/migrate-remix-to-cloudflare/:0:0","tags":["remix","cloudflare","cloudflare pages","cloudflare workers","machine learning"],"title":"将remix项目迁移到cloudflare","uri":"/migrate-remix-to-cloudflare/"},{"categories":null,"content":"步骤 remix是支持直接创建cloudflare部署的项目的,但是我已经是开发中的项目了,就不能用模板创建了. ","date":"2024-04-08","objectID":"/migrate-remix-to-cloudflare/:1:0","tags":["remix","cloudflare","cloudflare pages","cloudflare workers","machine learning"],"title":"将remix项目迁移到cloudflare","uri":"/migrate-remix-to-cloudflare/"},{"categories":null,"content":"复制文件 先用remix创建一个cloudflare模板项目: pnpm create cloudflare@latest my-remix-app -- --framework=remix 创建完成后, 和我自己的项目比较一下: 多出了这些文件,拷贝过去 ","date":"2024-04-08","objectID":"/migrate-remix-to-cloudflare/:1:1","tags":["remix","cloudflare","cloudflare pages","cloudflare workers","machine learning"],"title":"将remix项目迁移到cloudflare","uri":"/migrate-remix-to-cloudflare/"},{"categories":null,"content":"安装库 pnpm add -d vite @cloudflare/workers-types autoprefixer postcss vite-tsconfig-paths wrangler pnpm add @remix-run/cloudflare @remix-run/cloudflare-pages ","date":"2024-04-08","objectID":"/migrate-remix-to-cloudflare/:1:2","tags":["remix","cloudflare","cloudflare pages","cloudflare workers","machine learning"],"title":"将remix项目迁移到cloudflare","uri":"/migrate-remix-to-cloudflare/"},{"categories":null,"content":"文件修改 在tsconfig.json中添加: \"compilerOptions\": { \"lib\": [\"DOM\", \"DOM.Iterable\", \"ES2022\"], \"types\": [ \"@remix-run/cloudflare\", \"vite/client\", \"@cloudflare/workers-types/2023-07-01\" ], wrangler.toml 按需配置wrangler.toml, 用到那些就配置那些, 我用到了d1_database, r2_buckets 等 postcss.config.cjs[js] module.exports = { plugins: { tailwindcss: {}, autoprefixer: {}, }, }; tailwind.css @tailwind base; @tailwind components; @tailwind utilities; export default {} entry.server.tsx import type { AppLoadContext, EntryContext } from \"@remix-run/cloudflare\"; import { RemixServer } from \"@remix-run/react\"; import { isbot } from \"isbot\"; import { renderToReadableStream } from \"react-dom/server\"; export default async function handleRequest( request: Request, responseStatusCode: number, responseHeaders: Headers, remixContext: EntryContext, // This is ignored so we can keep it in the template for visibility. Feel // free to delete this parameter in your app if you're not using it! // eslint-disable-next-line @typescript-eslint/no-unused-vars loadContext: AppLoadContext ) { const body = await renderToReadableStream( \u003cRemixServer context={remixContext} url={request.url} /\u003e, { signal: request.signal, onError(error: unknown) { // Log streaming rendering errors from inside the shell console.error(error); responseStatusCode = 500; }, } ); if (isbot(request.headers.get(\"user-agent\") || \"\")) { await body.allReady; } responseHeaders.set(\"Content-Type\", \"text/html\"); return new Response(body, { headers: responseHeaders, status: responseStatusCode, }); } root.tsx import { cssBundleHref } from '@remix-run/css-bundle'; import type { LinksFunction } from '@remix-run/node'; import { Links, LiveReload, Meta, Outlet, Scripts, ScrollRestoration, } from '@remix-run/react'; import styles from './tailwind.css?url'; import { ThemeProvider } from './context/themeContext'; // export const links: LinksFunction = () =\u003e [{ rel: 'stylesheet', href: './tailwind.css' }]; export const links = () =\u003e { return [ { rel: \"stylesheet\", href: styles } ]; } export default function App() { return ( \u003cThemeProvider\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charSet=\"utf-8\" /\u003e \u003cmeta name=\"viewport\" content=\"width=device-width, initial-scale=1\" /\u003e \u003cMeta /\u003e \u003cLinks /\u003e \u003c/head\u003e \u003cbody\u003e \u003cOutlet /\u003e \u003cScrollRestoration /\u003e \u003cScripts /\u003e \u003cLiveReload /\u003e \u003c/body\u003e \u003c/html\u003e \u003c/ThemeProvider\u003e ); } 注意这个: import styles from './tailwind.css?url';, 多了个?url package.json \"scripts\": { \"build\": \"remix vite:build\", \"deploy\": \"pnpm run build \u0026\u0026 wrangler pages deploy ./build/client\", \"dev\": \"remix vite:dev\", \"lint\": \"eslint --ignore-path .gitignore --cache --cache-location ./node_modules/.cache/eslint .\", \"start\": \"wrangler pages dev ./build/client\", \"typecheck\": \"tsc\", \"typegen\": \"wrangler types\", \"preview\": \"pnpm run build \u0026\u0026 wrangler pages dev ./build/client\", \"build-cf-types\": \"wrangler types\" }, ","date":"2024-04-08","objectID":"/migrate-remix-to-cloudflare/:1:3","tags":["remix","cloudflare","cloudflare pages","cloudflare workers","machine learning"],"title":"将remix项目迁移到cloudflare","uri":"/migrate-remix-to-cloudflare/"},{"categories":null,"content":"Node compatibility 根据官方, nodejs的一些核心库是不能直接在worker pages中运行的, 有两种方法, 第一种: Use runtime APIs directly, 我没有使用成功, 我使用的是第二种, Add polyfills using Wrangler, 在wrangler.toml中增加: node_compat = true, 注意两种不能兼容. ","date":"2024-04-08","objectID":"/migrate-remix-to-cloudflare/:1:4","tags":["remix","cloudflare","cloudflare pages","cloudflare workers","machine learning"],"title":"将remix项目迁移到cloudflare","uri":"/migrate-remix-to-cloudflare/"},{"categories":null,"content":"prisma 迁移 数据库之前是PostgresSQL,现在要迁移到D1 Database, 常见Prisma文档: https://www.prisma.io/docs/orm/prisma-client/deployment/edge/deploy-to-cloudflare 假设数据库名称为 my-d1, 先要生成sql pnpm npx wrangler d1 migrations create my-d1 --local 会在本地生成migration目录, 在执行: pnpm npx prisma migrate diff \\ --from-empty \\ --to-schema-datamodel ./prisma/schema.prisma \\ --script \\ \u003e\u003e migrations/0001_init_.sql 第一次生成迁移文件, 会存放到migrations/0001_init_.sql中去. 执行迁移文件: pnpm npx wrangler d1 migrations apply my-d1 --local 到这一步,迁移就完成了,但是,不出意外的出意外了: near \"CONSTRAINT\": syntax error at offset 41 [code: 7500] 这玩意也没有说是哪一行代码, 提示的41根本就不是, 只能一行行删除后实验, 最后发现是: ALTER TABLE \"tablename\" ADD CONSTRAINT 的错误, 差了一下:https://developers.cloudflare.com/d1/reference/migrations/#foreign-key-constraints ","date":"2024-04-08","objectID":"/migrate-remix-to-cloudflare/:1:5","tags":["remix","cloudflare","cloudflare pages","cloudflare workers","machine learning"],"title":"将remix项目迁移到cloudflare","uri":"/migrate-remix-to-cloudflare/"},{"categories":null,"content":"bindings 使用 在cloudflare pages中使用bindings, 比如: KV, R2时,老是读取不到这些binding, 仔细研究测试多次,发现一些流程: functions/[[path]].ts export const onRequest = createPagesFunctionHandler({ build, mode: process.env.NODE_ENV, getLoadContext: context =\u003e ({ env: context.context.cloudflare.env }), }); getLoadContext要设置env: context.context.cloudflare.env wrangler.toml 在文件中需要配置对应binding的信息, 并且, 在cloudflare pages 的dashboard里,也要配置对应环境(production, preview)的binding, 名称要一样 typegen 修改wrangler.toml或者dashboard中的bindings后, 需要运行: pnpm run types, 也就是: wrangler types, 会生成worker-configuration.d.ts 文件, wrangler.toml中对应的设置就会更新: interface Env { SOME_KV: KVNamespace; SOME_R2: R2Bucket; } 在remix服务端使用: context.env.SOME_KV.put(key, 'some value'); ","date":"2024-04-08","objectID":"/migrate-remix-to-cloudflare/:1:6","tags":["remix","cloudflare","cloudflare pages","cloudflare workers","machine learning"],"title":"将remix项目迁移到cloudflare","uri":"/migrate-remix-to-cloudflare/"},{"categories":null,"content":"部署ComfyUI玩 之前AIGC非常火, 我本地部署了Stable Diffusion 的WebUI玩了一下,见: text 但是吧, WebUI 界面, 太复杂了, 元素太多了, 看起来非常专业, 但是用起来也是有一定难度的. 正好那段时间工作比较忙, 玩了一段时间, 就放着没有继续玩了. 最近, 又发现一个特别好用的Stable Diffusion 的UI, 叫做ComfyUI, 看起来非常舒服, 使用的是 节点链接: 可以看到, 不同的节点可以根据输入输出来链接, 每个节点有自己的功能, 非常直观, 擦了一下, 这个类型的UI叫: **可视化工作流 ** ","date":"2024-03-25","objectID":"/play-with-comfyui/:0:0","tags":["comfyui","comfyui-manager","ai","stable diffusion","machine learning"],"title":"部署ComfyUI玩","uri":"/play-with-comfyui/"},{"categories":null,"content":"安装 ComfyUI 安装也很方便, 参照官网就可以了: https://github.com/comfyanonymous/ComfyUI?tab=readme-ov-file#installing. 注意 Nvidia卡需要先安装pytorch: pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu121 Apple Silicon 也及时M1/2/3也是可以运行的, 这就是我为什么搞了64G统一内存的MacbookPro的原因: 详见帖子. 需要安装pytorh的nightly 版本, 将: https://github.com/comfyanonymous/ComfyUI?tab=readme-ov-file#apple-mac-silicon 然后再安装ComfyUI-Manager: 直接用ComfyUI Manger, 地址: https://github.com/ltdrdata/ComfyUI-Manager, ComfyUI-Manger是一个插件,可以方便管理各种开源的附加类型节点, 有了这个, ComfyUI的可玩性才更高. 注意, 需要放在ComfyUI的custom_nodes目录下, 所以需要先安装ComfyUI: cd ComfyUI/custom_nodes git clone https://github.com/ltdrdata/ComfyUI-Manager.git ","date":"2024-03-25","objectID":"/play-with-comfyui/:1:0","tags":["comfyui","comfyui-manager","ai","stable diffusion","machine learning"],"title":"部署ComfyUI玩","uri":"/play-with-comfyui/"},{"categories":null,"content":"python 环境配置 最好使用conda来做, 安装conda后, 创建一个python环境: conda create -n py310sd python=3.10 pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch -c nvidia conda activate py310sd ","date":"2024-03-25","objectID":"/play-with-comfyui/:1:1","tags":["comfyui","comfyui-manager","ai","stable diffusion","machine learning"],"title":"部署ComfyUI玩","uri":"/play-with-comfyui/"},{"categories":null,"content":"模型配置 之前使用WebUI下载了的模型,就不用再次下载了,可以直接使用, 方法将文档:https://github.com/comfyanonymous/ComfyUI?tab=readme-ov-file#how-do-i-share-models-between-another-ui-and-comfyui, 简单说就是修改config.yaml: a111: base_path: path/to/stable-diffusion-webui/ 指定WebUI的路径, 然后, 就可以使用WebUI下载的模型了. ","date":"2024-03-25","objectID":"/play-with-comfyui/:1:2","tags":["comfyui","comfyui-manager","ai","stable diffusion","machine learning"],"title":"部署ComfyUI玩","uri":"/play-with-comfyui/"},{"categories":null,"content":"使用 python main.py --listen 0.0.0.0 注意--listen 0.0.0.0 可以让你在非本机也可以访问, 比如我在MacbookPro上启动, 在iPad上也可以访问. 访问: http://yourip:8188, 然后, 打开新世界!!! ","date":"2024-03-25","objectID":"/play-with-comfyui/:2:0","tags":["comfyui","comfyui-manager","ai","stable diffusion","machine learning"],"title":"部署ComfyUI玩","uri":"/play-with-comfyui/"},{"categories":null,"content":"更多玩法 ComfyUI社区发展非常快, 各种Node层出不穷, 个人感觉已经超过WebUI的流行程度了. 最近又发现了一个好玩的: https://comfyworkflows.com/. 是一个ComfyUI的Workflow的聚集地, 有很多Workflow可以直接使用, 也可以自己创建, 然后分享给大家. 有了这个, 就可以直接使用别人的Workflow了, 不用自己创建了, 也可以学习别人的Workflow是怎么创建的. 比如, 我现在用这个: https://comfyworkflows.com/workflows/e6c1c436-f878-4cc3-be0a-43ee96864467 下载后, 在ComfyUI中选择Upload, 选择刚才下载的json文件, 然后就可以导入了. 我这里会报错: 这个时候就体现ComfyUI-Manager的好处了, 点击’Manger’: 选择Install Custom Nodes: 然后在搜索中选择需要的节点, 比如UltimateSDUpscale, 搜索出来后安装就可以了. 最后加载的效果: ","date":"2024-03-25","objectID":"/play-with-comfyui/:3:0","tags":["comfyui","comfyui-manager","ai","stable diffusion","machine learning"],"title":"部署ComfyUI玩","uri":"/play-with-comfyui/"},{"categories":null,"content":"总结 ComfyUI这种形式,确实比以前的WebUI要方便很多, 可玩性极高, 我也是刚开始搞, 最近工作比较慢, 空了慢慢搞, AIGC这一关发展速度太快了, 感觉一天一个变, 希望不要掉队了哈… ","date":"2024-03-25","objectID":"/play-with-comfyui/:4:0","tags":["comfyui","comfyui-manager","ai","stable diffusion","machine learning"],"title":"部署ComfyUI玩","uri":"/play-with-comfyui/"},{"categories":null,"content":"将家庭服务器从DELL R720迁移到蜗牛星际+MacbookPro 后续 ","date":"2024-03-21","objectID":"/migrate-homelab-from-dell-r720-to-j1900-and-macbookpro-2/:0:0","tags":["homeserver","r720","dell","MacbookPro","pve","蜗牛星际","休眠"],"title":"将家庭服务器从DELL R720迁移到蜗牛星际+MacbookPro 后续","uri":"/migrate-homelab-from-dell-r720-to-j1900-and-macbookpro-2/"},{"categories":null,"content":"千兆网络断流问题 迁移已经完成了,试用了一段时间, 星际蜗牛功耗很低(相对R720 100多瓦), 3块HDD, 1块SSD 功耗35瓦, 一天不到1度电,非常不错. 但是目前有个问题,就是MacbookPro, 只要一盒盖,或者锁定屏幕, 或者远程桌面关闭后, 雷电HUB上的有线网卡就断开了. 这个时候非要重新登入,如果是远程的话,用MacbookPro 的无线网卡的IP连接,才可以再次使用有线网卡的IP. 一开始以为是HP G2雷电hub的问题, 换了别的USB HUB使用千兆网口也是一样. 继续测试,我用旧的Intel 架构的老Macbook 测试, 结果也是一样. ","date":"2024-03-21","objectID":"/migrate-homelab-from-dell-r720-to-j1900-and-macbookpro-2/:1:0","tags":["homeserver","r720","dell","MacbookPro","pve","蜗牛星际","休眠"],"title":"将家庭服务器从DELL R720迁移到蜗牛星际+MacbookPro 后续","uri":"/migrate-homelab-from-dell-r720-to-j1900-and-macbookpro-2/"},{"categories":null,"content":"解决 于是开始漫长的google, 发现很多人有这个问题,但是,没什么解决办法, 都是说在设置-节能中修改, 我也改了: 主要就是: 使用电源适配器时,防治自动进入休眠 唤醒以供网络访问 这两个选项的各种排列组合我都试过了, 不行. 然后又有说去pmset -g看hibernatemode, pmset是Mac系统查看电源管理的cli工具. 我看了下我的, 是3, 觉得跟这个没有关系, 但是这个时候我看到pmset -g结果中有一个 SleepDisabled 0, 这个参数我去查了一下: 表示禁用休眠,难道是这个?抱着试一试的心态我执行了: sudo pmset -a disablesleep 1 执行完成后, pmset -g输出结果: System-wide power settings: SleepDisabled 1 Currently in use: standby 1 Sleep On Power Button 1 hibernatefile /var/vm/sleepimage powernap 1 networkoversleep 0 disksleep 10 sleep 0 (sleep prevented by screensharingd, powerd) hibernatemode 3 ttyskeepawake 1 displaysleep 1 tcpkeepalive 1 powermode 0 womp 1 其中SleepDisabled 1表示设置成功了,测试一下, 果然. 不管多长时间, 有线网卡都是可以使用的了. 这样看来,Mac没有类似Windows 那样的设置开关, 让系统在接电源时一直不休眠. M1架构一直开机待机,功耗也就不到10瓦 现在可以安心使用emby随时看片了… ","date":"2024-03-21","objectID":"/migrate-homelab-from-dell-r720-to-j1900-and-macbookpro-2/:2:0","tags":["homeserver","r720","dell","MacbookPro","pve","蜗牛星际","休眠"],"title":"将家庭服务器从DELL R720迁移到蜗牛星际+MacbookPro 后续","uri":"/migrate-homelab-from-dell-r720-to-j1900-and-macbookpro-2/"},{"categories":null,"content":" 一个youtube app使用quic引起的问题 ","date":"2024-03-16","objectID":"/sing-box-youtube-app-quic-issue/:0:0","tags":["旁路由","r2s","quic","sing-box","hysteria","youtube"],"title":"一个youtube app使用quic引起的问题","uri":"/sing-box-youtube-app-quic-issue/"},{"categories":null,"content":"问题描述 家里是r2s做旁路由,使用的是sing-box的tun模式, 之前一直用的是cn2 gia的线路,每天晚上用apple tv上的youtube 看看视频睡觉,没有什么问题, 这个月服务器流量用光了, 就在普通线路上用hysteria2, 半天用的都没有什么问题,结果到了晚上, youtube根本不能看,想到可能是晚上udp丢包比较严重,于是就没有管. 有一天实在受不了了, 晚上用笔记本开浏览器上speed.cloudflare.com测试了一下速度,确实正常的,有40M以上的下行速度,我寻思着这个看YouTube没有问题啊,于是用笔记本浏览器打开youtube, 发现速度正常, 2W+Kbps,4k都没问题. 我赶紧又去apple tv上测试,发现还是卡,速度只有2,3百Kbps. 百思不得其解. ","date":"2024-03-16","objectID":"/sing-box-youtube-app-quic-issue/:1:0","tags":["旁路由","r2s","quic","sing-box","hysteria","youtube"],"title":"一个youtube app使用quic引起的问题","uri":"/sing-box-youtube-app-quic-issue/"},{"categories":null,"content":"解决过程 于是我用各种不通的设备测试, 发现,出来apple tv 和 chromecast tv上的youtube app, 其他,手机app, 浏览器,全部都正常. 这明显有问题, 我又想这个问题是最近出现的,就去google了一下,看看有没有能有同样的问题,我分别按apple tv和chromecast tv上的youtube app的版本号去搜索,都没有发现有相关资料. 于是去sing-box的dashboard上看了下, 用正常速度播放的时候, 看连接就是正常的, 用电视上的youtube tv播放, 连接速度就起不来,始终只有不到100KBps. 真是郁闷至极, 我测试了把协议换成vmess, 居然都比现在快, 但是浏览器和app速度都不怎么样了. 就在我又准备放弃的时候, 我发现dashboard上,apple tv的关闭连接数量在不停的增长, 再看pc对应ip的,却是正常的, 这明显有问题, apple tv怎么会发起那么多的连接, 我再仔细一看, 发现apple tv连YouTube的连接, 协议是tun(udp), 明明是视频,走443端口,怎么是tcp, 我突然想到了quic, 会不会是因为走的quic, 而quic又是基于udp的,是一个一个包,而tun这边收到包后,转给hysteria的端口跳跃,每一个(或多个)包都会换端口,而且会建立新的连接,这样\"关闭\"的连接如此多就说的通了. 于是我去google了一下, 找到一个 issue, 使用一下rule: { \"protocol\": [ \"quic\" ], \"outbound\": \"block\" }, 更新了一下配置, 结果…, 没用. 唉, 搞到快凌晨一点了,算了明天再搞, 由于下午喝了咖啡,再加上心理惦记这个事情,一晚上没有睡好, 周末起个大早, 再试试. ","date":"2024-03-16","objectID":"/sing-box-youtube-app-quic-issue/:2:0","tags":["旁路由","r2s","quic","sing-box","hysteria","youtube"],"title":"一个youtube app使用quic引起的问题","uri":"/sing-box-youtube-app-quic-issue/"},{"categories":null,"content":"解决 想了一晚上, 我觉得我的思路是对的, 肯定是走的quic, 把这个禁用了, youtube app就会换成tcp了. 看了下dashboard, 发现tun(udp)这条对应的rule并不是我设置的block, 就是没有生效. 于是又继续看sing-box的文档, 换了一段rule配置: { \"type\": \"logical\", \"mode\": \"and\", \"rules\": [ { \"network\": [\"udp\"] }, { \"port\": [443] } ], \"outbound\": \"block\" } 这段很明确了, udp并且是443端口, 就block, 这个可能会有误杀, 但是应该不会放过youtube的quic了. 更新配置, 应用陪着, 测试: 终于正常了. 这不是我用浏览器测试了一下,还一直蒙在鼓里, 现在,终于可以放心看视频睡觉了… ","date":"2024-03-16","objectID":"/sing-box-youtube-app-quic-issue/:3:0","tags":["旁路由","r2s","quic","sing-box","hysteria","youtube"],"title":"一个youtube app使用quic引起的问题","uri":"/sing-box-youtube-app-quic-issue/"},{"categories":null,"content":"将家庭服务器从DELL R720迁移到蜗牛星际+MacbookPro 前几年网HomeLab, 买了一台二手Dell R720机架服务器, 用来做家庭服务器. 但是由于这台服务器的功耗太高, 双cpu待机就要快200w, 换了低功耗的志强后,只安装一个cpu,也有100w+, 一年下来电费不少,而且,到了夏天,非常的热,后来使用ipmi工具,用python写了个代码,根据温度来调节暴力风扇,要舒服许多,但是,夏天,室温升高,风扇还是会平方提高转速. 一直想换成低功耗的服务器. 之前买了蜗牛星际, 这个使用的是j1900, 功耗很低的, 于是就把家庭服务器从Dell R720迁移到了蜗牛星际. ","date":"2024-03-11","objectID":"/migrate-homelab-from-dell-r720-to-j1900-and-macbookpro/:0:0","tags":["homeserver","r720","dell","MacbookPro","pve","蜗牛星际"],"title":"将家庭服务器从DELL R720迁移到蜗牛星际+MacbookPro","uri":"/migrate-homelab-from-dell-r720-to-j1900-and-macbookpro/"},{"categories":null,"content":"尝试 Dell R720买回家后,前前后后装了太多vm, lxc, 折腾k8s, rancher等,内存加到了64G, 还可以往上加,毕竟ddr3 ecc的服务器内存太便宜了,不过64g足够了,根本用不完,搞多了费电. 目前保留了两个lxc, 一个跑bt,qt, 我都用的是qbittorrent, 把bt和pt服务分开了. 目前已经用qbittorrent下载了快40t的数据: qbittorrent非常稳定,之前用transmission,感觉不好用,速度也一般. 这个lxc是必须要迁移的. 另一个lxc也是是跑ubuntu, 用来存储整套媒体工作流: jellyseerr 用来检索影片 prowlarr 用来检索index,提交下载任务 sonarr 用来提交电视剧任务 radarr 用来提价电影任务 jellyfin 用来播放影片 这套工作流非常稳定了, 需要迁移. 因为这些用不了太多资源, 放R720上太浪费资源. ","date":"2024-03-11","objectID":"/migrate-homelab-from-dell-r720-to-j1900-and-macbookpro/:1:0","tags":["homeserver","r720","dell","MacbookPro","pve","蜗牛星际"],"title":"将家庭服务器从DELL R720迁移到蜗牛星际+MacbookPro","uri":"/migrate-homelab-from-dell-r720-to-j1900-and-macbookpro/"},{"categories":null,"content":"步骤 星际蜗牛上安装pve, 这个是必须的. 星际蜗牛上配置两个ubuntu的lxc, 这个是必须的. 将原来各个docker使用的docker-compose文件和挂载用的config文件夹,用rsync全部同步过来 在蜗牛上使用mount -t nfs挂载影视资源和下载目录. 将docker-compose映射的目录改成mount后的目录 docker-compose up -d 启动所有服务 就这样完成了,为什么需要挂载nfs,而不直接将硬盘移动过来,因为我不知道蜗牛的j1900+4G 内存是否能搞定这多的服务. 先测试过可以,最后再迁移硬盘. ","date":"2024-03-11","objectID":"/migrate-homelab-from-dell-r720-to-j1900-and-macbookpro/:2:0","tags":["homeserver","r720","dell","MacbookPro","pve","蜗牛星际"],"title":"将家庭服务器从DELL R720迁移到蜗牛星际+MacbookPro","uri":"/migrate-homelab-from-dell-r720-to-j1900-and-macbookpro/"},{"categories":null,"content":"发现的问题 ","date":"2024-03-11","objectID":"/migrate-homelab-from-dell-r720-to-j1900-and-macbookpro/:3:0","tags":["homeserver","r720","dell","MacbookPro","pve","蜗牛星际"],"title":"将家庭服务器从DELL R720迁移到蜗牛星际+MacbookPro","uri":"/migrate-homelab-from-dell-r720-to-j1900-and-macbookpro/"},{"categories":null,"content":"内存不够 星际蜗牛开机没多久,就会出现cpu占用100%, 但是top查看, 是一个叫kswapd名称的进程, google了一下, 是交换空间管理进程, 说明4g内存不够了. 默认swap只有512M, 于是准备用swapon等命令创建几个G的swap分区, 结果发现root分区不够了,因为我一开始就是测试下, 所以在蜗牛上内置的sata接了一个120G的ssd, 用来做root分区, 但是120G的ssd太小了, 光是lxc的硬盘就占了80G, 现在没有去买大的sata接口的ssd了,就先将就,后面直接用大的ssd, 用clonezilla替换. 先把lxc的硬盘迁移到机械硬盘组的zpool上去,慢一点其实无所谓,都是后台服务,不需要太快的io读写. 然后用swapon加了4G空间,现在好多了: 占用cpu最多的是baidupan的服务,其实什么也没有下载,截图的时候. 可以看到qbittorrent确实占了很多内存,因为任务太多了. 几百个,能不多吗. ","date":"2024-03-11","objectID":"/migrate-homelab-from-dell-r720-to-j1900-and-macbookpro/:3:1","tags":["homeserver","r720","dell","MacbookPro","pve","蜗牛星际"],"title":"将家庭服务器从DELL R720迁移到蜗牛星际+MacbookPro","uri":"/migrate-homelab-from-dell-r720-to-j1900-and-macbookpro/"},{"categories":null,"content":"j1900 解码能力 j1900毕竟快10年了,好多解码不支持. 对比n100 解码: 特别是现在下载的都是4k HDR的视频,大多是h.256, HEVC编码的,都不支持,就做不了转码,好多客户端使用jellyfin就看不了4k的视频. 于是我想了一个办法,我的MacbookPro不是在家里吗, M1Max应该可以解码大部分了吧: 除了AV1, 基本都可以了,于是在MacbookPro上安装jellyfin, 这个时候又出了两个问题: jellyfin在m1 mac上,运行一段时间,他的服务端就卡死了,原因不明,搜索了下github上的issue, 也有人提了这样的问题,但是没有解决. MacbookPro 我使用的是HP G2 的雷电hub, 连接了有线网卡, 只要合盖或者锁屏, 有线网卡就断开, 这个问题之前使用mac的桌面共享就发现了,使用有线网卡的ip去连是不行的,这个时候如果用无线网卡的ip连一下,有线网卡的ip就通了. 解决办法 换emby, 没什么问题. 应该是休眠问题, 使用sudo pmset -g: System-wide power settings: SleepDisabled 0 Currently in use: standby 1 Sleep On Power Button 1 hibernatefile /var/vm/sleepimage powernap 1 networkoversleep 0 disksleep 10 sleep 0 (sleep prevented by EmbyServer, screensharingd) hibernatemode 3 ttyskeepawake 1 displaysleep 3 tcpkeepalive 1 powermode 0 womp 1 使用命令pmset -a disablesleep 1 禁用系统休眠, 完美解决, 还在m1待机功耗,真的太低了,比起R720真实天壤之别. ","date":"2024-03-11","objectID":"/migrate-homelab-from-dell-r720-to-j1900-and-macbookpro/:3:2","tags":["homeserver","r720","dell","MacbookPro","pve","蜗牛星际"],"title":"将家庭服务器从DELL R720迁移到蜗牛星际+MacbookPro","uri":"/migrate-homelab-from-dell-r720-to-j1900-and-macbookpro/"},{"categories":null,"content":"其他要迁移的 icloud_photo_backup 这个是用来备份icloud的照片的 cron 一些定时任务,比如使用acme更新证书等. cups 打印机服务, 我直接迁移过来, 配好了,结果打印没有反应,最后把打印机重启,就好了. 全部完成后,再把硬盘转移过来, 重新在/etc/fstab中挂载就可以了. ","date":"2024-03-11","objectID":"/migrate-homelab-from-dell-r720-to-j1900-and-macbookpro/:4:0","tags":["homeserver","r720","dell","MacbookPro","pve","蜗牛星际"],"title":"将家庭服务器从DELL R720迁移到蜗牛星际+MacbookPro","uri":"/migrate-homelab-from-dell-r720-to-j1900-and-macbookpro/"},{"categories":null,"content":"使用chatgpt帮我编写一个给视频文件生成中文字幕的脚本 ","date":"2024-03-06","objectID":"/use-chatgpt-to-make-a-sub-generator-script/:0:0","tags":["chatgpt","shell script","ffmpeg","whisper","openai","chatgpt-subtitle-translator"],"title":"使用chatgpt帮我编写一个给视频文件生成中文字幕的脚本","uri":"/use-chatgpt-to-make-a-sub-generator-script/"},{"categories":null,"content":"背景 因为有些冷门的电影或者视频，很难找到中文字幕，但是又有故事情节，这时候就需要自己手动添加中文字幕。但是手动添加中文字幕非常耗时，尤其是对于长视频来说。所以我想要使用chatgpt来帮我编写一个脚本，能够自动给视频文件生成中文字幕。 ","date":"2024-03-06","objectID":"/use-chatgpt-to-make-a-sub-generator-script/:1:0","tags":["chatgpt","shell script","ffmpeg","whisper","openai","chatgpt-subtitle-translator"],"title":"使用chatgpt帮我编写一个给视频文件生成中文字幕的脚本","uri":"/use-chatgpt-to-make-a-sub-generator-script/"},{"categories":null,"content":"实现思路 首先要把流程分解成几个步骤： 使用ffmpeg提取视频的音频文件 使用whisper.cpp将音频文件转换成文本文件 使用chatgpt-subtitle-translator将文本文件翻译成中文字幕 每个步骤的命令大概如下: ","date":"2024-03-06","objectID":"/use-chatgpt-to-make-a-sub-generator-script/:2:0","tags":["chatgpt","shell script","ffmpeg","whisper","openai","chatgpt-subtitle-translator"],"title":"使用chatgpt帮我编写一个给视频文件生成中文字幕的脚本","uri":"/use-chatgpt-to-make-a-sub-generator-script/"},{"categories":null,"content":"ffmpeg提取音频 ffmpeg -i input.mp4 -hide_banner -vn -loglevel error -ar 16000 -ac 1 -c:a pcm_s16le -y output.wav -progress - ","date":"2024-03-06","objectID":"/use-chatgpt-to-make-a-sub-generator-script/:2:1","tags":["chatgpt","shell script","ffmpeg","whisper","openai","chatgpt-subtitle-translator"],"title":"使用chatgpt帮我编写一个给视频文件生成中文字幕的脚本","uri":"/use-chatgpt-to-make-a-sub-generator-script/"},{"categories":null,"content":"whisper.cpp 提取文本 whisper.cpp也可以翻译,但是只能到英文,如果用他翻译的英文再去翻译出中文,效果会更差,所以这里只是用来提取文本(英文)。 ./main -m models/ggml-small.bin -l $WHISPER_LANGUAGE -f $AUDIO_FILE_PATH -t 8 -osrt 这个命令直将$AUDIO_FILE_PATH的音频文件转换成文本文件，并且保存为.srt英文字幕。$WHISPER_LANGUAGE是指定语言，这里可以选择英文或者其他语言。-t 8是指定线程数，可以根据自己的电脑性能来调整。 ","date":"2024-03-06","objectID":"/use-chatgpt-to-make-a-sub-generator-script/:2:2","tags":["chatgpt","shell script","ffmpeg","whisper","openai","chatgpt-subtitle-translator"],"title":"使用chatgpt帮我编写一个给视频文件生成中文字幕的脚本","uri":"/use-chatgpt-to-make-a-sub-generator-script/"},{"categories":null,"content":"chatgpt-subtitle-translator翻译文本 本来准备自己写一个脚本来调用openai的API来翻译文本，但是发现已经有人写好了一个脚本，叫做chatgpt-subtitle-translator，可以直接使用。这个脚本的使用方法可以参考这里。 ","date":"2024-03-06","objectID":"/use-chatgpt-to-make-a-sub-generator-script/:2:3","tags":["chatgpt","shell script","ffmpeg","whisper","openai","chatgpt-subtitle-translator"],"title":"使用chatgpt帮我编写一个给视频文件生成中文字幕的脚本","uri":"/use-chatgpt-to-make-a-sub-generator-script/"},{"categories":null,"content":"chatgpt聊天过程 第一次提问: 我把问题描述得非常清楚了,有哪些步骤,每一步是什么,我具体的要求, 第一步他给出的答案: #!/bin/bash # 定义变量 VIDEO_FILE_PATH=\\$1 WHISPER_PATH=\"/User/gowinder/code/whisper.cpp/main\" WHISPER_LANGUAGE=\"Japanese\" WHISPER_MODEL=\"/User/gowinder/code/whisper.cpp/models/ggml-small.bin\" TRANSLATOR_PATH=\"/User/gowinder/code/chatgpt-subtitle-translator/\" TRANSLATOR_TO_LANGUAGE=\"Chinese\" # 提取音频并转换为wav格式 AUDIO_FILE_PATH=\"${VIDEO_FILE_PATH%.*}.wav\" ffmpeg -i \"$VIDEO_FILE_PATH\" -hide_banner -vn -loglevel error -ar 16000 -ac 1 -c:a pcm_s16le -y \"$AUDIO_FILE_PATH\" # 使用whisper生成srt字幕文件 SRT_FILE_PATH=\"${AUDIO_FILE_PATH%.*}.srt\" $WHISPER_PATH -m $WHISPER_MODEL -l $WHISPER_LANGUAGE -f \"$AUDIO_FILE_PATH\" -t \"8\" -osr # 使用ChatGPT翻译字幕 TRANSLATED_SRT_FILE_PATH=\"${AUDIO_FILE_PATH%.*}.out_${TRANSLATOR_TO_LANGUAGE}.srt\" cd $TRANSLATOR_PATH cli/translator.mjs --stream --temperature 0 --from \"$WHISPER_LANGUAGE\" --to \"$TRANSLATOR_TO_LANGUAGE\" --file \"$SRT_FILE_PATH\" # 重命名输出文件 FINAL_SRT_FILE_PATH=\"${AUDIO_FILE_PATH%.*}.chs.srt\" mv \"$TRANSLATED_SRT_FILE_PATH\" \"$FINAL_SRT_FILE_PATH\" 这时可见回复基本已经把我需要的编辑好了,但是还有几个问题,如: 没有检查每一步的返回结果等,于是我继续提问: 第二次提问: 需要修改: - 检测每一步时候正常完成,如果没有就退出 - `使用ChatGPT翻译字幕` 这一步不要`cd`到`TRANSLATOR_PATH` 目录去,而是设置他的工作目录 回答: #!/bin/bash # 定义变量 VIDEO_FILE_PATH=\\$1 WHISPER_PATH=\"/User/gowinder/code/whisper.cpp/main\" WHISPER_LANGUAGE=\"Japanese\" WHISPER_MODEL=\"/User/gowinder/code/whisper.cpp/models/ggml-small.bin\" TRANSLATOR_PATH=\"/User/gowinder/code/chatgpt-subtitle-translator/\" TRANSLATOR_TO_LANGUAGE=\"Chinese\" # 提取音频并转换为wav格式 AUDIO_FILE_PATH=\"${VIDEO_FILE_PATH%.*}.wav\" ffmpeg -i \"$VIDEO_FILE_PATH\" -hide_banner -vn -loglevel error -ar 16000 -ac 1 -c:a pcm_s16le -y \"$AUDIO_FILE_PATH\" if [ $? -ne 0 ]; then echo \"Error: Failed to extract audio from video.\" exit 1 fi # 使用whisper生成srt字幕文件 SRT_FILE_PATH=\"${AUDIO_FILE_PATH%.*}.srt\" $WHISPER_PATH -m $WHISPER_MODEL -l $WHISPER_LANGUAGE -f \"$AUDIO_FILE_PATH\" -t \"8\" -osr if [ $? -ne 0 ]; then echo \"Error: Failed to generate srt file.\" exit 1 fi # 使用ChatGPT翻译字幕 TRANSLATED_SRT_FILE_PATH=\"${AUDIO_FILE_PATH%.*}.out_${TRANSLATOR_TO_LANGUAGE}.srt\" pushd $TRANSLATOR_PATH cli/translator.mjs --stream --temperature 0 --from \"$WHISPER_LANGUAGE\" --to \"$TRANSLATOR_TO_LANGUAGE\" --file \"$SRT_FILE_PATH\" popd if [ $? -ne 0 ]; then echo \"Error: Failed to translate srt file.\" exit 1 fi # 重命名输出文件 FINAL_SRT_FILE_PATH=\"${AUDIO_FILE_PATH%.*}.chs.srt\" mv \"$TRANSLATED_SRT_FILE_PATH\" \"$FINAL_SRT_FILE_PATH\" if [ $? -ne 0 ]; then echo \"Error: Failed to rename srt file.\" exit 1 fi echo \"Subtitle generation completed successfully.\" 我想把一些配置放到.env文件中去,于是 第三次提问: 将 : WHISPER_PATH=\"/User/gowinder/code/whisper.cpp/main\" WHISPER_LANGUAGE=\"Japanese\" WHISPER_MODEL=\"/User/gowinder/code/whisper.cpp/models/ggml-small.bin\" TRANSLATOR_PATH=\"/User/gowinder/code/chatgpt-subtitle-translator/\" TRANSLATOR_TO_LANGUAGE=\"Chinese\" 放到env文件中去 输出结果: #!/bin/bash # 读取环境变量 source .env # 输入的视频文件路径 VIDEO_FILE_PATH=\\$1 # 提取音频并转换为wav格式 AUDIO_FILE_PATH=\"${VIDEO_FILE_PATH%.*}.wav\" ffmpeg -i \"$VIDEO_FILE_PATH\" -hide_banner -vn -loglevel error -ar 16000 -ac 1 -c:a pcm_s16le -y \"$AUDIO_FILE_PATH\" if [ $? -ne 0 ]; then echo \"Error: Failed to extract audio from video.\" exit 1 fi # 使用whisper生成srt字幕文件 SRT_FILE_PATH=\"${AUDIO_FILE_PATH%.*}.srt\" $WHISPER_PATH -m $WHISPER_MODEL -l $WHISPER_LANGUAGE -f \"$AUDIO_FILE_PATH\" -t \"8\" -osr if [ $? -ne 0 ]; then echo \"Error: Failed to generate srt file.\" exit 1 fi # 使用ChatGPT翻译字幕 TRANSLATED_SRT_FILE_PATH=\"${AUDIO_FILE_PATH%.*}.out_${TRANSLATOR_TO_LANGUAGE}.srt\" pushd $TRANSLATOR_PATH cli/translator.mjs --stream --temperature 0 --from \"$WHISPER_LANGUAGE\" --to \"$TRANSLATOR_TO_LANGUAGE\" --file \"$SRT_FILE_PATH\" popd if [ $? -ne 0 ]; then echo \"Error: Failed to translate srt file.\" exit 1 fi # 重命名输出文件 FINAL_SRT_FILE_PATH=\"${AUDIO_FILE_PATH%.*}.chs.srt\" mv \"$TRANSLATED_SRT_FILE_PATH\" \"$FINAL_SRT_FILE_PATH\" if [ $? -ne 0 ]; then echo \"Error: Failed to rename srt file.\" exit 1 fi echo \"Subtitle generation completed successfully.\" 然后我需要一些日志之类的,还有删除中间文件的操作,增加跳过的步骤等… 最终结果: #!/bin/bash","date":"2024-03-06","objectID":"/use-chatgpt-to-make-a-sub-generator-script/:3:0","tags":["chatgpt","shell script","ffmpeg","whisper","openai","chatgpt-subtitle-translator"],"title":"使用chatgpt帮我编写一个给视频文件生成中文字幕的脚本","uri":"/use-chatgpt-to-make-a-sub-generator-script/"},{"categories":null,"content":"效果 最后在macbook m1 max 64g上测试的效果, 一个1:38:50的mp4,最后: Total time: 622 seconds. Total tokens: 72580 Total cost: 0.145 USD Total number of subtitles: 198 差不多用了10分钟,(因为我的mp4文件是nfs挂载的,读取和写入wav都是通过网路,这块就花了75秒,whisper.cpp 花费了172秒, 差不多3分钟, 其他的时间就是调用openai翻译的时间了),其实还是很快的. 视频截图: ","date":"2024-03-06","objectID":"/use-chatgpt-to-make-a-sub-generator-script/:4:0","tags":["chatgpt","shell script","ffmpeg","whisper","openai","chatgpt-subtitle-translator"],"title":"使用chatgpt帮我编写一个给视频文件生成中文字幕的脚本","uri":"/use-chatgpt-to-make-a-sub-generator-script/"},{"categories":null,"content":"总结 最后这个脚本就非常好用了. 总结上面的,我个人会linux命令,但是对shell script不是很熟悉,而且不想写,因为调试不方便,用chatgpt非常方便,我个人觉得gpt-4已经很准确了,前提是需求一定要提明确,修改过程中需要偶尔再次提示一下上下文,不然他会忘记. ","date":"2024-03-06","objectID":"/use-chatgpt-to-make-a-sub-generator-script/:5:0","tags":["chatgpt","shell script","ffmpeg","whisper","openai","chatgpt-subtitle-translator"],"title":"使用chatgpt帮我编写一个给视频文件生成中文字幕的脚本","uri":"/use-chatgpt-to-make-a-sub-generator-script/"},{"categories":null,"content":"部署本地 Stable Diffusion运行环境 最近 midjourney 比较火，不过开始收费了，10刀一个月，消费不起，换成开源的Stable Diffusion来往，可以在Google Colab上一件部署： https://github.com/camenduru/stable-diffusion-webui-colab，不过Google Colab免费的gpu一下就没有了，付费的虽然便宜，还是得省着用，如果本地有gpu，而且有8G以上显存可以用自己的电脑来跑，节约成本，6G显存应该也可以，降低分辨率和关键字试试。 本文档参考https://github.com/camenduru/stable-diffusion-webui-colab，然后自己加了常用的一些模型 Stable Diffusion和midjourney的一个区别就是模型非常多，选好自己想要的风格的模型会更好的生成自己想要的效果，可玩性也更高。 选模型在几个常用的网站： https://huggingface.co/ 有很多开源的模型，搜索 stable diffusion就可以了,里面的用户分享类似github仓库，大文件可以直接下载也可以用git lfs https://civitai.com/ 也有用户分享模型，而且比较直观，有效果图，就像instagram一样，很方便，同样搜索stable diffusion就可以了 一些常用stable diffusion 网站： https://www.reddit.com/r/StableDiffusion/ reddit上的stable diffusion分区，他的 tutorials 非常好 https://stable-diffusion-art.com 有很多基础教程 下面开始记录部署 ","date":"2023-04-23","objectID":"/create-local-stable-diffusion-env/:0:0","tags":["ai","stable diffusion","machine learning"],"title":"部署本地 Stable Diffusion运行环境","uri":"/create-local-stable-diffusion-env/"},{"categories":null,"content":"硬件环境 在proxvox ev 7.3及ubuntu 20.04上部署成功过，显卡使用telsa P4 8G，3070 8G ","date":"2023-04-23","objectID":"/create-local-stable-diffusion-env/:1:0","tags":["ai","stable diffusion","machine learning"],"title":"部署本地 Stable Diffusion运行环境","uri":"/create-local-stable-diffusion-env/"},{"categories":null,"content":"设置根文件夹 google colab使用的及/content/stable-diffusion-webui，但我本地放在了zfs上，以为模型比较大，我可不想老是重复下载 export PROJ_DIR=/tank/download/ai-relate/stable-diffusion-webui 设置好$PROJ_DIR环境变量后，所有的下载都会以这个环境变量为基础。 ","date":"2023-04-23","objectID":"/create-local-stable-diffusion-env/:2:0","tags":["ai","stable diffusion","machine learning"],"title":"部署本地 Stable Diffusion运行环境","uri":"/create-local-stable-diffusion-env/"},{"categories":null,"content":"安装库 这一步好像不是必须的 sudo apt -y update -qq wget http://launchpadlibrarian.net/367274644/libgoogle-perftools-dev_2.5-2.2ubuntu3_amd64.deb wget https://launchpad.net/ubuntu/+source/google-perftools/2.5-2.2ubuntu3/+build/14795286/+files/google-perftools_2.5-2.2ubuntu3_all.deb wget https://launchpad.net/ubuntu/+source/google-perftools/2.5-2.2ubuntu3/+build/14795286/+files/libtcmalloc-minimal4_2.5-2.2ubuntu3_amd64.deb wget https://launchpad.net/ubuntu/+source/google-perftools/2.5-2.2ubuntu3/+build/14795286/+files/libgoogle-perftools4_2.5-2.2ubuntu3_amd64.deb sudo apt install -qq -y libunwind8-dev sudo dpkg -i *.deb env LD_PRELOAD=libtcmalloc.so rm *.deb sudo apt install libnvinfer8 python3-libnvinfer ","date":"2023-04-23","objectID":"/create-local-stable-diffusion-env/:3:0","tags":["ai","stable diffusion","machine learning"],"title":"部署本地 Stable Diffusion运行环境","uri":"/create-local-stable-diffusion-env/"},{"categories":null,"content":"安装conda 对于普通python项目我喜欢用poetry来管理包，但对于机器学习类项目，我一般用miniconda wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh bash Miniconda3-latest-Linux-x86_64.sh # agreements 。。。 创建conda环境： conda create -n py310sd python=3.10 ","date":"2023-04-23","objectID":"/create-local-stable-diffusion-env/:4:0","tags":["ai","stable diffusion","machine learning"],"title":"部署本地 Stable Diffusion运行环境","uri":"/create-local-stable-diffusion-env/"},{"categories":null,"content":"基本安装 安装 aria2,用这个可以多线程下载,比wget要快: sudo apt -y install aria2. 然后安装python库 pip install torch==1.13.1+cu116 torchvision==0.14.1+cu116 torchaudio==0.13.1 torchtext==0.14.1 torchdata==0.5.1 --extra-index-url https://download.pytorch.org/whl/cu116 -U pip install xformers==0.0.16 triton==2.0.0 -U pip install tensorrt 克隆stable-diffusion-webui及常用插件 #ln -s /opt/conda/lib/python3.10/site-packages/libnvinfer.so.8 /opt/conda/lib/python3.10/site-packages/libnvinfer.so.7 #ln -s /opt/conda/lib/python3.10/site-packages/libnvinfer_plugin.so.8 /opt/conda/lib/python3.10/site-packages/libnvinfer_plugin.so.7 #set -x LD_LIBRARY_PAH $LD_LIBRARY_PATH:/opt/conda/lib:/opt/conda/lib/python3.10/site-packages git clone -b v2.1 https://github.com/camenduru/stable-diffusion-webui git clone https://huggingface.co/embed/negative $PROJ_DIR/embeddings/negative git clone https://huggingface.co/embed/lora $PROJ_DIR/models/Lora/positive aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/embed/upscale/resolve/main/4x-UltraSharp.pth -d $PROJ_DIR/models/ESRGAN -o 4x-UltraSharp.pth wget https://raw.githubusercontent.com/camenduru/stable-diffusion-webui-scripts/main/run_n_times.py -O $PROJ_DIR/scripts/run_n_times.py git clone https://github.com/deforum-art/deforum-for-automatic1111-webui $PROJ_DIR/extensions/deforum-for-automatic1111-webui git clone https://github.com/camenduru/stable-diffusion-webui-images-browser $PROJ_DIR/extensions/stable-diffusion-webui-images-browser git clone https://github.com/camenduru/stable-diffusion-webui-huggingface $PROJ_DIR/extensions/stable-diffusion-webui-huggingface git clone https://github.com/camenduru/sd-civitai-browser $PROJ_DIR/extensions/sd-civitai-browser git clone https://github.com/kohya-ss/sd-webui-additional-networks $PROJ_DIR/extensions/sd-webui-additional-networks git clone https://github.com/Mikubill/sd-webui-controlnet $PROJ_DIR/extensions/sd-webui-controlnet git clone https://github.com/camenduru/openpose-editor $PROJ_DIR/extensions/openpose-editor git clone https://github.com/jexom/sd-webui-depth-lib $PROJ_DIR/extensions/sd-webui-depth-lib git clone https://github.com/hnmr293/posex $PROJ_DIR/extensions/posex git clone https://github.com/camenduru/sd-webui-tunnels $PROJ_DIR/extensions/sd-webui-tunnels git clone https://github.com/etherealxx/batchlinks-webui $PROJ_DIR/extensions/batchlinks-webui git clone https://github.com/camenduru/stable-diffusion-webui-catppuccin $PROJ_DIR/extensions/stable-diffusion-webui-catppuccin git clone https://github.com/KohakuBlueleaf/a1111-sd-webui-locon $PROJ_DIR/extensions/a1111-sd-webui-locon git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui-rembg $PROJ_DIR/extensions/stable-diffusion-webui-rembg git clone https://github.com/ashen-sensored/stable-diffusion-webui-two-shot $PROJ_DIR/extensions/stable-diffusion-webui-two-shot git clone https://github.com/camenduru/sd_webui_stealth_pnginfo $PROJ_DIR/extensions/sd_webui_stealth_pnginfo cd $PROJ_DIR git reset --hard aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet/resolve/main/control_canny-fp16.safetensors -d $PROJ_DIR/extensions/sd-webui-controlnet/models -o control_canny-fp16.safetensors aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet/resolve/main/control_depth-fp16.safetensors -d $PROJ_DIR/extensions/sd-webui-controlnet/models -o control_depth-fp16.safetensors aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet/resolve/main/control_hed-fp16.safetensors -d $PROJ_DIR/extensions/sd-webui-controlnet/models -o control_hed-fp16.safetensors aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet/resolve/main/control_mlsd-fp16.safetensors -d $PROJ_DIR/extensions/sd-webui-controlnet/models -o control_mlsd-fp16.safetensors aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet/resolve/main/control_normal-fp","date":"2023-04-23","objectID":"/create-local-stable-diffusion-env/:5:0","tags":["ai","stable diffusion","machine learning"],"title":"部署本地 Stable Diffusion运行环境","uri":"/create-local-stable-diffusion-env/"},{"categories":null,"content":"stable-diffusion 1.5 aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned.ckpt -d $PROJ_DIR/models/Stable-diffusion -o v1-5-pruned.ckpt ","date":"2023-04-23","objectID":"/create-local-stable-diffusion-env/:6:0","tags":["ai","stable diffusion","machine learning"],"title":"部署本地 Stable Diffusion运行环境","uri":"/create-local-stable-diffusion-env/"},{"categories":null,"content":"download AbyssOrangeMix2 NSFW aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/OrangeMixs/resolve/main/AbyssOrangeMix2_nsfw.safetensors -d $PROJ_DIR/models/Stable-diffusion -o AbyssOrangeMix2_nsfw.safetensors aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/OrangeMixs/resolve/main/AbyssOrangeMix2_hard.safetensors -d $PROJ_DIR/models/Stable-diffusion -o AbyssOrangeMix2_hard.safetensors aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/OrangeCocoaMix/resolve/main/OrangeCocoaMix2_hard.safetensors -d $PROJ_DIR/models/Stable-diffusion -o OrangeCocoaMix2_hard.safetensors aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.ckpt -d $PROJ_DIR/models/Stable-diffusion -o AbyssOrangeMix2_nsfw.vae.pt ","date":"2023-04-23","objectID":"/create-local-stable-diffusion-env/:7:0","tags":["ai","stable diffusion","machine learning"],"title":"部署本地 Stable Diffusion运行环境","uri":"/create-local-stable-diffusion-env/"},{"categories":null,"content":"download inkpunk https://huggingface.co/Envvi/Inkpunk-Diffusion aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Envvi/Inkpunk-Diffusion/resolve/main/Inkpunk-Diffusion-v2.ckpt -d $PROJ_DIR/models/Stable-diffusion -o Inkpunk-Diffusion-v2.ckpt ","date":"2023-04-23","objectID":"/create-local-stable-diffusion-env/:8:0","tags":["ai","stable diffusion","machine learning"],"title":"部署本地 Stable Diffusion运行环境","uri":"/create-local-stable-diffusion-env/"},{"categories":null,"content":"download Mo Di diffusion https://huggingface.co/nitrosocke/mo-di-diffusion aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/nitrosocke/mo-di-diffusion/blob/main/moDi-v1-pruned.ckpt -d $PROJ_DIR/models/Stable-diffusion -o moDi-v1-pruned.ckpt ","date":"2023-04-23","objectID":"/create-local-stable-diffusion-env/:9:0","tags":["ai","stable diffusion","machine learning"],"title":"部署本地 Stable Diffusion运行环境","uri":"/create-local-stable-diffusion-env/"},{"categories":null,"content":"AbyssOrangeMix3 https://huggingface.co/WarriorMama777/OrangeMixs aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix3/AOM3A1B_orangemixs.safetensors -d $PROJ_DIR/models/Stable-diffusion -o AOM3A1B_orangemixs.safetensors aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix3/AOM3A1_orangemixs.safetensors -d $PROJ_DIR/models/Stable-diffusion -o AOM3A1_orangemixs.safetensors aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix3/AOM3A3_orangemixs.safetensors -d $PROJ_DIR/models/Stable-diffusion -o AOM3A3_orangemixs.safetensors aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix3/AOM3A2_orangemixs.safetensors -d $PROJ_DIR/models/Stable-diffusion -o AOM3A2_orangemixs.safetensors aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix3/AOM3_orangemixs.safetensors -d $PROJ_DIR/models/Stable-diffusion -o AOM3_orangemixs.safetensors ","date":"2023-04-23","objectID":"/create-local-stable-diffusion-env/:10:0","tags":["ai","stable diffusion","machine learning"],"title":"部署本地 Stable Diffusion运行环境","uri":"/create-local-stable-diffusion-env/"},{"categories":null,"content":"SCIFI https://huggingface.co/Corruptlake/Sci-Fi-Diffusion/tree/main aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Corruptlake/Sci-Fi-Diffusion/resolve/main/Sci-Fi_Diffusion_1.0.safetensors -d $PROJ_DIR/models/Stable-diffusion -o Sci-Fi_Diffusion_1.0.safetensors aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Corruptlake/Sci-Fi-Diffusion/resolve/main/Sci-Fi_Diffusion_1.0.ckpt -d $PROJ_DIR/models/Stable-diffusion -o Sci-Fi_Diffusion_1.0.ckpt hentai model 图就不放了，地址在 aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Deltaadams/HD-22/resolve/main/HD22%20S.zip -d $PROJ_DIR/models/Stable-diffusion -o hd22.zip cd $PROJ_DIR/models/Stable-diffusion unzip hd22.zip ","date":"2023-04-23","objectID":"/create-local-stable-diffusion-env/:11:0","tags":["ai","stable diffusion","machine learning"],"title":"部署本地 Stable Diffusion运行环境","uri":"/create-local-stable-diffusion-env/"},{"categories":null,"content":"complexla style aria2c -x 15 -s 10 -c -k 1M https://huggingface.co/Conflictx/Complex-Lineart/resolve/main/ComplexLA%20Style.ckpt -d $PROJ_DIR/models/Stable-diffusion -o ComplexLA-Style.ckpt ","date":"2023-04-23","objectID":"/create-local-stable-diffusion-env/:12:0","tags":["ai","stable diffusion","machine learning"],"title":"部署本地 Stable Diffusion运行环境","uri":"/create-local-stable-diffusion-env/"},{"categories":null,"content":"f222 https://huggingface.co/acheong08/f222 aria2c -x 15 -s 10 -c -k 1M https://huggingface.co/acheong08/f222/resolve/main/f222.ckpt -d $PROJ_DIR/models/Stable-diffusion -o f222.ckpt ","date":"2023-04-23","objectID":"/create-local-stable-diffusion-env/:13:0","tags":["ai","stable diffusion","machine learning"],"title":"部署本地 Stable Diffusion运行环境","uri":"/create-local-stable-diffusion-env/"},{"categories":null,"content":"Chillout Mix https://civitai.com/models/6424/chilloutmix aria2c -x 15 -s 10 -c -k 1M https://civitai.com/api/download/models/11745 -d $PROJ_DIR/models/Stable-diffusion -o ChilloutMix.safetensors ","date":"2023-04-23","objectID":"/create-local-stable-diffusion-env/:14:0","tags":["ai","stable diffusion","machine learning"],"title":"部署本地 Stable Diffusion运行环境","uri":"/create-local-stable-diffusion-env/"},{"categories":null,"content":"URPM aria2c -x 15 -s 10 -c -k 1M https://civitai.com/api/download/models/15640 -d $PROJ_DIR/models/Stable-diffusion -o URPM.safetensors ","date":"2023-04-23","objectID":"/create-local-stable-diffusion-env/:15:0","tags":["ai","stable diffusion","machine learning"],"title":"部署本地 Stable Diffusion运行环境","uri":"/create-local-stable-diffusion-env/"},{"categories":null,"content":"OpenJourney https://huggingface.co/prompthero/openjourney aria2c -x 15 -s 10 -c -k 1M https://huggingface.co/prompthero/openjourney/resolve/main/mdjrny-v4.ckpt -d $PROJ_DIR/models/Stable-diffusion -o mdjrny-v4.ckpt ","date":"2023-04-23","objectID":"/create-local-stable-diffusion-env/:16:0","tags":["ai","stable diffusion","machine learning"],"title":"部署本地 Stable Diffusion运行环境","uri":"/create-local-stable-diffusion-env/"},{"categories":null,"content":"Anythings V5 https://civitai.com/models/9409/or-anything-v5 aria2c -x 15 -s 10 -c -k 1M https://civitai.com/api/download/models/30163 -d $PROJ_DIR/models/Stable-diffusion -o AnyThingsV5.ckpt ","date":"2023-04-23","objectID":"/create-local-stable-diffusion-env/:17:0","tags":["ai","stable diffusion","machine learning"],"title":"部署本地 Stable Diffusion运行环境","uri":"/create-local-stable-diffusion-env/"},{"categories":null,"content":"DreamShaper https://huggingface.co/Lykon/DreamShaper # DreamShaper_5_beta2_BakedVae_fp16.ckpt aria2c -x 15 -s 10 -c -k 1M https://huggingface.co/Lykon/DreamShaper/resolve/main/DreamShaper_5_beta2_BakedVae_fp16.ckpt -d $PROJ_DIR/models/Stable-diffusion -o DreamShaper_5_beta2_BakedVae_fp16.ckpt ","date":"2023-04-23","objectID":"/create-local-stable-diffusion-env/:18:0","tags":["ai","stable diffusion","machine learning"],"title":"部署本地 Stable Diffusion运行环境","uri":"/create-local-stable-diffusion-env/"},{"categories":null,"content":"运行webui cd $PROJ_DIR python launch.py --listen --xformers --enable-insecure-extension-access --theme dark --gradio-queue --multiple 如果需要外网访问，加上--share参数 ","date":"2023-04-23","objectID":"/create-local-stable-diffusion-env/:19:0","tags":["ai","stable diffusion","machine learning"],"title":"部署本地 Stable Diffusion运行环境","uri":"/create-local-stable-diffusion-env/"},{"categories":null,"content":"“解决React开发模式服务端Cors问题 ","date":"2023-03-28","objectID":"/react-scripts-cors/:0:0","tags":["react","CORS"],"title":"解决React开发模式服务端Cors问题","uri":"/react-scripts-cors/"},{"categories":null,"content":"启因 最近在做openai的后端代理服务,一个后台池账号池,缓冲前端过来的openai的completion请求. 后端基本开发完成了,所以需要一个demo前端做测试及演示用,就用react做了一个简单的前端聊天程序,代码基本由GPT-4来生成,生成了多次,拼接了一下,由于我也没有写过react,所以还花了点时间选择拼接,因为CHATGPT也经常出些错误,懂的人一看就知道,不懂的人就要上当. 程序运行起来后,因为后端给前端的接口是一个websocket,启动后就报错: Access to XMLHttpRequest at 'http://localhost:3014/socket.io/?EIO=4\u0026transport=polling\u0026t=OSYSDmI' from origin 'http://localhost:3000' has been blocked by CORS policy: No 'Access-Control-Allow-Origin' header is present on the requested resource. ","date":"2023-03-28","objectID":"/react-scripts-cors/:1:0","tags":["react","CORS"],"title":"解决React开发模式服务端Cors问题","uri":"/react-scripts-cors/"},{"categories":null,"content":"解决 查了一些资料,CORS问题其实需要在SERVER端解决,首先我的SERVER端用的是Nestjs,websocket用的是WebSocketGateway,定义如下: @WebSocketGateway({ cors: { origin: '*', }, namespace: 'main', }) export class WSGateway implements OnGatewayInit, OnGatewayConnection, OnGatewayDisconnect { ... } websockeet已经加了CORS了,应该不是这个问题,问题出在localhost:3000,这个是前端react用的web服务,报错也是这个3000,经过查询,开发模式启动react-scripts用的是webpack的开发服,根据官方文档: 新建一个scr/setupProxy.js const { createProxyMiddleware } = require(\"http-proxy-middleware\"); module.exports = function (app) { app.use( \"/\", createProxyMiddleware({ target: \"http://localhost:3014\", // Replace with the API server URL // changeOrigin: true, ws: true, logger: console, // pathRewrite: { // \"^/api\": \"\", // Remove the '/api' prefix from the request URL // }, }) ); }; target填入react要连接的目标服务器地址, ws设置成true ","date":"2023-03-28","objectID":"/react-scripts-cors/:2:0","tags":["react","CORS"],"title":"解决React开发模式服务端Cors问题","uri":"/react-scripts-cors/"},{"categories":null,"content":"Class Constructor TypeOrmCrudService Cannot Be Invoked Without ‘New’ 错误 ","date":"2023-02-28","objectID":"/class-constructor-typeormcrudservice-cannot-be-invoked-without-new/:0:0","tags":["nestjs","typescript","node","开发笔记","typeorm","es2017","es5","@nestjsx/crud-typeorm","chatgpt"],"title":"Class Constructor TypeOrmCrudService Cannot Be Invoked Without 'New'","uri":"/class-constructor-typeormcrudservice-cannot-be-invoked-without-new/"},{"categories":null,"content":"启因 最近开发一个chatgpt网关项目,使用nestjs,其中用nestjsx-crud来提高curd开发效率,有以下代码: @Injectable() export class ChatgptAccountService extends TypeOrmCrudService\u003cChatGPTAccount\u003e { constructor( @InjectRepository(ChatGPTAccount) private readonly chatgptAccountRepository: Repository\u003cChatGPTAccount\u003e, ) { super(chatgptAccountRepository); } 运行时会报错: Class Constructor TypeOrmCrudService Cannot Be Invoked Without 'New' ","date":"2023-02-28","objectID":"/class-constructor-typeormcrudservice-cannot-be-invoked-without-new/:1:0","tags":["nestjs","typescript","node","开发笔记","typeorm","es2017","es5","@nestjsx/crud-typeorm","chatgpt"],"title":"Class Constructor TypeOrmCrudService Cannot Be Invoked Without 'New'","uri":"/class-constructor-typeormcrudservice-cannot-be-invoked-without-new/"},{"categories":null,"content":"解决 网上查了下,在这里找到一个: For anyone stumbling over this issue: it's probably a tsconfig issue. Try bumping your target from es5 to es6. 看一下我的项目的tsconfig.json: { \"compilerOptions\": { \"lib\": [ \"es5\", \"es6\" ], \"target\": \"es5\", \"module\": \"commonjs\", \"moduleResolution\": \"node\", \"outDir\": \"./build\", \"emitDecoratorMetadata\": true, \"experimentalDecorators\": true, \"sourceMap\": true } } 再对比一下之前正常的项目: \"compilerOptions\": { \"module\": \"commonjs\", \"declaration\": true, \"removeComments\": true, \"emitDecoratorMetadata\": true, \"experimentalDecorators\": true, \"allowSyntheticDefaultImports\": true, \"target\": \"es2017\", \"sourceMap\": true, \"outDir\": \"./dist\", ... 把target改成: es2017就好了: { \"compilerOptions\": { \"target\": \"es2017\", \"module\": \"commonjs\", \"moduleResolution\": \"node\", \"outDir\": \"./build\", \"emitDecoratorMetadata\": true, \"experimentalDecorators\": true, \"sourceMap\": true } } ","date":"2023-02-28","objectID":"/class-constructor-typeormcrudservice-cannot-be-invoked-without-new/:2:0","tags":["nestjs","typescript","node","开发笔记","typeorm","es2017","es5","@nestjsx/crud-typeorm","chatgpt"],"title":"Class Constructor TypeOrmCrudService Cannot Be Invoked Without 'New'","uri":"/class-constructor-typeormcrudservice-cannot-be-invoked-without-new/"},{"categories":null,"content":"在Orange Pi Zero上安装pihole后,webui无法启动问题 ","date":"2023-02-27","objectID":"/pihile-lighttp-cannot-start-in-orange-pi-zero/:0:0","tags":["pihole","linux","lighttp"],"title":"在Orange Pi Zero上安装pihole后,webui无法启动问题","uri":"/pihile-lighttp-cannot-start-in-orange-pi-zero/"},{"categories":null,"content":"启因 最新在空闲Orange Pi Zero上安装了Pihole用来做家庭主DNS服务器,安装一路顺序: Armbian-\u003ePihole,结果安装好后,无法启动WebUI, Pihole用的是Lighttp ","date":"2023-02-27","objectID":"/pihile-lighttp-cannot-start-in-orange-pi-zero/:1:0","tags":["pihole","linux","lighttp"],"title":"在Orange Pi Zero上安装pihole后,webui无法启动问题","uri":"/pihile-lighttp-cannot-start-in-orange-pi-zero/"},{"categories":null,"content":"解决过程 使用命令检查: sudo lighttpd -t -f /etc/lighttpd/lighttpd.conf 结果是: Syntax OK 没有问题. 查看lighttpd服务: sudo systemctl status lighttpd, 发现一启动就退出了,exited=255. 继续查看日志: sudo tail -f /var/log/lighttpd/error-pihole.log 发现报错: 2023-02-26 21:53:03: server.c.1513) server started (lighttpd/1.4.59) 2023-02-26 21:53:03: mod_accesslog.c.612) opening log '/var/log/lighttpd/access.log' failed: Permission denied 说 /var/log/lighttpd/ 这个目录没有权限, 于是做下面的操作: sudo chown pihole:pihole /var/log/lighttpd -R sudo chmod 755 /var/log/lighttpd -R 再次启动: sudo systemctl start lighttpd 就ok了. ","date":"2023-02-27","objectID":"/pihile-lighttp-cannot-start-in-orange-pi-zero/:2:0","tags":["pihole","linux","lighttp"],"title":"在Orange Pi Zero上安装pihole后,webui无法启动问题","uri":"/pihile-lighttp-cannot-start-in-orange-pi-zero/"},{"categories":null,"content":"nestjs整合websocketgateway和microservice ","date":"2023-02-23","objectID":"/use-microservce-in-websocketgateway-in-nestjs/:0:0","tags":["nestjs","typescript","node","开发笔记","microservice","websocketg","websocketgateway"],"title":"nestjs整合websocketgateway和microservice","uri":"/use-microservce-in-websocketgateway-in-nestjs/"},{"categories":null,"content":"启因 使用WebsocketGateway做网关,接收客户端长连接后,将消息通过RabbitMQ消息队列转发到microservice,再做后续处理,microservice处理完成后,将结果也发送到RabbitMQ,WebsocketGateway接收到消息后,回传给客户端 ","date":"2023-02-23","objectID":"/use-microservce-in-websocketgateway-in-nestjs/:1:0","tags":["nestjs","typescript","node","开发笔记","microservice","websocketg","websocketgateway"],"title":"nestjs整合websocketgateway和microservice","uri":"/use-microservce-in-websocketgateway-in-nestjs/"},{"categories":null,"content":"目录结构 src ws-gateway ws-gateway.controller.ts ws-gateway.module.ts ws-gateway.ts gateway.controller.ts gateway.module.ts gateway.service.ts main.ts ","date":"2023-02-23","objectID":"/use-microservce-in-websocketgateway-in-nestjs/:1:1","tags":["nestjs","typescript","node","开发笔记","microservice","websocketg","websocketgateway"],"title":"nestjs整合websocketgateway和microservice","uri":"/use-microservce-in-websocketgateway-in-nestjs/"},{"categories":null,"content":"文件 先看 WSGateway模块 WSGateway.ts import { SHARED_SERVICE, SharedService } from '@app/shared'; import { Inject, Injectable } from '@nestjs/common'; import { ConfigService } from '@nestjs/config'; import { ClientProxy, ClientProxyFactory, Ctx, MessagePattern, Payload, RmqContext, Server, } from '@nestjs/microservices'; import { WebSocketGateway, WebSocketServer, SubscribeMessage, MessageBody, OnGatewayConnection, OnGatewayDisconnect, OnGatewayInit, ConnectedSocket, } from '@nestjs/websockets'; import { SendMsgDTO } from './dto/send-msg.dto'; import { Socket } from '@nestjs/platform-socket.io'; @Injectable() @WebSocketGateway(3333, { cors: { origin: '*', }, namespace: 'main', }) // implements OnGatewayInit, OnGatewayConnection, OnGatewayDisconnect export class WSGateway implements OnGatewayInit, OnGatewayConnection, OnGatewayDisconnect { apiClient: ClientProxy; clients: Map\u003cstring, Socket\u003e; // 存放客户端 constructor( @Inject(SHARED_SERVICE) private readonly sharedService: SharedService, private readonly configService: ConfigService, ) { console.log('WSGateway constructor: '); const client: ClientProxy = ClientProxyFactory.create( sharedService.getRmqOptions(configService.get('API_QUEUE'), ''), ); this.apiClient = client; this.clients = new Map\u003cstring, Socket\u003e(); } @WebSocketServer() server: Server; afterInit(server: any) { console.log('websocket init:'); this.server = server; } handleConnection(socket: Socket) { console.log('WebSocket client connecting, clients', this.clients.size); // 生成 socket_id，存储 socket 对象 const socket_id = Math.random().toString(36).substring(7); socket['socket_id'] = socket_id; // 将socket_id存到客户端socket连接对象中去 this.clients.set(socket_id, socket); } handleDisconnect(socket: Socket) { console.log('WebSocket client disconnected'); // 查找 socket_id，删除 socket 对象 const socket_id = socket['socket_id']; console.log('remove socket:', socket_id); this.clients.delete(socket_id); } // 订阅客户端发来的send消息: socket.emit('send', data) @SubscribeMessage('send') async handleMessage( @ConnectedSocket() client: Socket, @MessageBody() data: SendMsgDTO, ): Promise\u003cnumber\u003e { console.log('; got [send]: prompt: ', data.prompt); // 数据中加入metadata, socket_id表示此消息属于哪个socket,回传的消息带上metadata就知道发给谁了 const metadata = { socket_id: client['socket_id'], websocket_service: 'ws-gateway', }; data['metadata'] = metadata; this.apiClient.emit({ cmd: 'send' }, data); return 0; } // 此为发送消息给客户端 async emit(socket_id: string, event: any, content: string) { const client = this.clients.get(socket_id); const data = JSON.stringify(content); client.emit('recv', data); } } ws-gateway.controller.ts import { SHARED_SERVICE, SharedService } from '@app/shared'; import { Controller, Inject } from '@nestjs/common'; import { ConfigService } from '@nestjs/config'; import { Ctx, MessagePattern, Payload, RmqContext, } from '@nestjs/microservices'; import { WSGateway } from './ws-gateway'; @Controller() export class WSGatewayController { constructor( @Inject(SHARED_SERVICE) private readonly sharedService: SharedService, private readonly gateway: WSGateway, ) {} // 订阅微服务事件,从rabbitmq读取 recv事件 @MessagePattern({ cmd: 'recv' }) async recv(@Ctx() context: RmqContext, @Payload() content: string) { console.log('GatewayController got [recv]: ', content); this.sharedService.acknowledgeMessage(context); // 调用 wsgateway发送 return this.gateway.emit(content['metadata']['socket_id'], 'recv', content); } } ws-gateway.module.ts 注意: 在 providers中 需要提供WSGateway,这样,app.module中才可以拿启动这个 需要提供SHARED_SERVICE,这个是注入用的共享服务,没有可以不要 需要提供WS_QUEUE_SERVICE, 这个很关键, 没这个,WSGateway就只会启动Websocket监听,不会启动微服务 上面这个好像不需要,去掉也能正常用,在app.module中创建就可以了 import { SharedModule, SharedService, SHARED_SERVICE } from '@app/shared'; import { Module } from '@nestjs/common'; import { ConfigService } from '@nestjs/config'; import { ClientProxyFactory } from '@nestjs/microservices'; import { WSGateway } from './ws-gateway'; import { WSGatewayController } from './ws-gateway.controller'; @Module({ imports: [SharedModule], controllers: [WSGatewayC","date":"2023-02-23","objectID":"/use-microservce-in-websocketgateway-in-nestjs/:1:2","tags":["nestjs","typescript","node","开发笔记","microservice","websocketg","websocketgateway"],"title":"nestjs整合websocketgateway和microservice","uri":"/use-microservce-in-websocketgateway-in-nestjs/"},{"categories":null,"content":"总结 到这里,client-\u003ewebsocket-\u003erabbitmq-\u003eapp service-\u003erabbitmq-\u003ewebsocket-\u003eclient 流程就通了. 中间走了些弯路,nestjs的文档感觉不是很全面和细致,然后我本身对nestjs的微服务也没有那么熟,所以花了些时间. 几个问题花了许多时间调试: 启动了两个WSGateway,所以一个连接会进来两次,这样我存的clients就不准,找不到对应的客户socket,就无法回复消息 怎么把WSGateway和microservice整合在一起,花了些时间,主要还是nestjs的模块架构,需要的时候要import,在本模块内要使用imports的模块中的controller等就需要在providers中加上,如果要给其它模块使用,就要在exports中加上. ","date":"2023-02-23","objectID":"/use-microservce-in-websocketgateway-in-nestjs/:2:0","tags":["nestjs","typescript","node","开发笔记","microservice","websocketg","websocketgateway"],"title":"nestjs整合websocketgateway和microservice","uri":"/use-microservce-in-websocketgateway-in-nestjs/"},{"categories":null,"content":"proxmox ve 增加自动trim的cron job ","date":"2023-02-17","objectID":"/proxmox-ve-%E5%A2%9E%E5%8A%A0%E8%87%AA%E5%8A%A8trim%E7%9A%84cron-job/:0:0","tags":["proxmox ve","linux","分布式","ssd","trim","cron","部署"],"title":"proxmox ve 增加自动trim的cron job","uri":"/proxmox-ve-%E5%A2%9E%E5%8A%A0%E8%87%AA%E5%8A%A8trim%E7%9A%84cron-job/"},{"categories":null,"content":"检查状态 sudo systemctl status fstrim.timer # output: ● fstrim.timer - Discard unused blocks once a week Loaded: loaded (/lib/systemd/system/fstrim.timer; disabled; vendor preset: enabled) Active: inactive (dead) Trigger: n/a Triggers: ● fstrim.service Docs: man:fstrim ","date":"2023-02-17","objectID":"/proxmox-ve-%E5%A2%9E%E5%8A%A0%E8%87%AA%E5%8A%A8trim%E7%9A%84cron-job/:1:0","tags":["proxmox ve","linux","分布式","ssd","trim","cron","部署"],"title":"proxmox ve 增加自动trim的cron job","uri":"/proxmox-ve-%E5%A2%9E%E5%8A%A0%E8%87%AA%E5%8A%A8trim%E7%9A%84cron-job/"},{"categories":null,"content":"开启服务 sudo systemctl start fstrim.timer ","date":"2023-02-17","objectID":"/proxmox-ve-%E5%A2%9E%E5%8A%A0%E8%87%AA%E5%8A%A8trim%E7%9A%84cron-job/:2:0","tags":["proxmox ve","linux","分布式","ssd","trim","cron","部署"],"title":"proxmox ve 增加自动trim的cron job","uri":"/proxmox-ve-%E5%A2%9E%E5%8A%A0%E8%87%AA%E5%8A%A8trim%E7%9A%84cron-job/"},{"categories":null,"content":"检查下次清理时间 sudo systemctl list-timers --all # output: NEXT LEFT LAST PASSED UNIT ACTIVATES Fri 2023-02-17 23:54:54 CST 8h left Thu 2023-02-16 23:54:54 CST 15h ago systemd-tmpfiles-clean.timer systemd-tmpfiles-clean.servi\u003e Sat 2023-02-18 00:00:00 CST 8h left Fri 2023-02-17 00:00:00 CST 15h ago atop-rotate.timer atop-rotate.service Sat 2023-02-18 00:00:00 CST 8h left Fri 2023-02-17 00:00:00 CST 15h ago logrotate.timer logrotate.service Sat 2023-02-18 00:00:00 CST 8h left Fri 2023-02-17 00:00:00 CST 15h ago man-db.timer man-db.service Sat 2023-02-18 04:19:48 CST 13h left Fri 2023-02-17 05:29:22 CST 9h ago pve-daily-update.timer pve-daily-update.service Sat 2023-02-18 05:18:55 CST 14h left Fri 2023-02-17 06:45:48 CST 8h ago apt-daily.timer apt-daily.service Sat 2023-02-18 06:41:05 CST 15h left Fri 2023-02-17 06:02:36 CST 9h ago apt-daily-upgrade.timer apt-daily-upgrade.service Sun 2023-02-19 03:10:12 CST 1 day 12h left Sun 2023-02-12 03:10:19 CST 5 days ago e2scrub_all.timer e2scrub_all.service Mon 2023-02-20 00:37:59 CST 2 days left n/a n/a fstrim.timer fstrim.service n/a n/a n/a n/a pvesr.timer 完成 ","date":"2023-02-17","objectID":"/proxmox-ve-%E5%A2%9E%E5%8A%A0%E8%87%AA%E5%8A%A8trim%E7%9A%84cron-job/:3:0","tags":["proxmox ve","linux","分布式","ssd","trim","cron","部署"],"title":"proxmox ve 增加自动trim的cron job","uri":"/proxmox-ve-%E5%A2%9E%E5%8A%A0%E8%87%AA%E5%8A%A8trim%E7%9A%84cron-job/"},{"categories":null,"content":"proxmox ve 中扩展pvm-local空间 ","date":"2023-02-17","objectID":"/proxmox-ve-%E4%B8%AD%E6%89%A9%E5%B1%95pvm-local%E7%A9%BA%E9%97%B4/:0:0","tags":["proxmox ve","linux","部署","lvm","扩展"],"title":"proxmox ve 中扩展pvm-local空间","uri":"/proxmox-ve-%E4%B8%AD%E6%89%A9%E5%B1%95pvm-local%E7%A9%BA%E9%97%B4/"},{"categories":null,"content":"原因 之前在DIY E3服务器上安装的proxmox ve,用的一张120G的SSD,当时年纪轻,把pve的逻辑分区还分了一个30g的data分区出来了,现在想用local做glusterfs,那么就想把data中的空间合并到root中去了. ","date":"2023-02-17","objectID":"/proxmox-ve-%E4%B8%AD%E6%89%A9%E5%B1%95pvm-local%E7%A9%BA%E9%97%B4/:1:0","tags":["proxmox ve","linux","部署","lvm","扩展"],"title":"proxmox ve 中扩展pvm-local空间","uri":"/proxmox-ve-%E4%B8%AD%E6%89%A9%E5%B1%95pvm-local%E7%A9%BA%E9%97%B4/"},{"categories":null,"content":"步骤 ","date":"2023-02-17","objectID":"/proxmox-ve-%E4%B8%AD%E6%89%A9%E5%B1%95pvm-local%E7%A9%BA%E9%97%B4/:2:0","tags":["proxmox ve","linux","部署","lvm","扩展"],"title":"proxmox ve 中扩展pvm-local空间","uri":"/proxmox-ve-%E4%B8%AD%E6%89%A9%E5%B1%95pvm-local%E7%A9%BA%E9%97%B4/"},{"categories":null,"content":"先拷出data分区里面的东西 先在pve的webui上删除不需要的,对于需要的,先拷贝出来,我的data是挂载在/mnt/data中: sudo rsync -ar --info=progress2 /mnt/data/ /var/lib/vz 拷贝完成后,删除data 逻辑分区: sudo umount /mnt/data sudo lvdisplay 看一下结果: --- Logical volume --- LV Path /dev/pve/data LV Name data VG Name pve LV UUID xxxx LV Write Access read/write LV Creation host, time pve, 2020-12-13 12:19:01 +0800 LV Status available # open 0 LV Size 30.39 GiB Current LE 7781 Segments 1 Allocation inherit Read ahead sectors auto - currently set to 256 Block device 253:2 删除: sudo lvremove pve/data # Logical volume \"data\" successfully removed 查看vg空间, sudo vgdisplay: --- Volume group --- VG Name pve System ID Format lvm2 Metadata Areas 1 Metadata Sequence No 73 VG Access read/write VG Status resizable MAX LV 0 Cur LV 2 Open LV 2 Max PV 0 Cur PV 1 Act PV 1 VG Size \u003c106.60 GiB PE Size 4.00 MiB Total PE 27289 Alloc PE / Size 19508 / 76.20 GiB Free PE / Size 7781 / 30.39 GiB VG UUID xxxx 可以看到有30.39 Gib的空间,现在把他合并到pve-root: sudo lvresize -l +100%FREE /dev/pve/root: Size of logical volume pve/root changed from 72.70 GiB (18612 extents) to \u003c103.10 GiB (26393 extents). Logical volume pve/root successfully resized.` 变成103.10 GiB了. 扩展文件系统空间: sudo resize2fs -p /dev/mapper/pve-root 结果: resize2fs 1.46.5 (30-Dec-2021) Filesystem at /dev/mapper/pve-root is mounted on /; on-line resizing required old_desc_blocks = 10, new_desc_blocks = 13 The filesystem on /dev/mapper/pve-root is now 27026432 (4k) blocks long. 看看空间: df -h: Filesystem Size Used Avail Use% Mounted on udev 11G 0 11G 0% /dev tmpfs 2.2G 6.5M 2.2G 1% /run /dev/mapper/pve-root 102G 42G 56G 43% / .... 成功了 ","date":"2023-02-17","objectID":"/proxmox-ve-%E4%B8%AD%E6%89%A9%E5%B1%95pvm-local%E7%A9%BA%E9%97%B4/:2:1","tags":["proxmox ve","linux","部署","lvm","扩展"],"title":"proxmox ve 中扩展pvm-local空间","uri":"/proxmox-ve-%E4%B8%AD%E6%89%A9%E5%B1%95pvm-local%E7%A9%BA%E9%97%B4/"},{"categories":null,"content":"(补充)将另一块硬盘加入到pve的volume group中去 之前还有一块120G的SSD,想把他也装进去,这块硬盘已经加到vg里面了,sudo pvdisplay: --- Physical volume --- PV Name /dev/sdh3 VG Name pve PV Size 106.60 GiB / not usable \u003c2.55 MiB Allocatable yes (but full) PE Size 4.00 MiB Total PE 27289 Free PE 0 Allocated PE 27289 PV UUID xxxx \"/dev/sdf1\" is a new physical volume of \"119.24 GiB\" --- NEW Physical volume --- PV Name /dev/sdf1 VG Name PV Size 119.24 GiB Allocatable NO PE Size 0 Total PE 0 Free PE 0 Allocated PE 0 PV UUID xxxx ","date":"2023-02-17","objectID":"/proxmox-ve-%E4%B8%AD%E6%89%A9%E5%B1%95pvm-local%E7%A9%BA%E9%97%B4/:3:0","tags":["proxmox ve","linux","部署","lvm","扩展"],"title":"proxmox ve 中扩展pvm-local空间","uri":"/proxmox-ve-%E4%B8%AD%E6%89%A9%E5%B1%95pvm-local%E7%A9%BA%E9%97%B4/"},{"categories":null,"content":"加入vg sudo vgextend pve /dev/sdf1` # Volume group \"pve\" successfully extended` sudo vgdisplay # output: --- Volume group --- VG Name pve System ID Format lvm2 Metadata Areas 2 Metadata Sequence No 75 VG Access read/write VG Status resizable MAX LV 0 Cur LV 2 Open LV 2 Max PV 0 Cur PV 2 Act PV 2 VG Size \u003c225.84 GiB PE Size 4.00 MiB Total PE 57814 Alloc PE / Size 27289 / \u003c106.60 GiB Free PE / Size 30525 / \u003c119.24 GiB VG UUID qTOzVc-TkpO-iokP-8JGO-3MNo-4Id0-TAsIYi 可以看到已经有119.24G空闲空间了 ","date":"2023-02-17","objectID":"/proxmox-ve-%E4%B8%AD%E6%89%A9%E5%B1%95pvm-local%E7%A9%BA%E9%97%B4/:3:1","tags":["proxmox ve","linux","部署","lvm","扩展"],"title":"proxmox ve 中扩展pvm-local空间","uri":"/proxmox-ve-%E4%B8%AD%E6%89%A9%E5%B1%95pvm-local%E7%A9%BA%E9%97%B4/"},{"categories":null,"content":"扩展lv lvresize sudo lvresize -l +100%FREE /dev/pve/root` ### output: Size of logical volume pve/root changed from \u003c119.24 GiB (30525 extents) to \u003c222.34 GiB (56918 extents). Logical volume pve/root successfully resized. 扩展文件系统空间: sudo resize2fs -p /dev/mapper/pve-root 结果: resize2fs 1.46.5 (30-Dec-2021) Filesystem at /dev/mapper/pve-root is mounted on /; on-line resizing required old_desc_blocks = 13, new_desc_blocks = 28 The filesystem on /dev/mapper/pve-root is now 58284032 (4k) blocks long. 完成 ","date":"2023-02-17","objectID":"/proxmox-ve-%E4%B8%AD%E6%89%A9%E5%B1%95pvm-local%E7%A9%BA%E9%97%B4/:3:2","tags":["proxmox ve","linux","部署","lvm","扩展"],"title":"proxmox ve 中扩展pvm-local空间","uri":"/proxmox-ve-%E4%B8%AD%E6%89%A9%E5%B1%95pvm-local%E7%A9%BA%E9%97%B4/"},{"categories":null,"content":"总结 感觉 lvm在空间管理这块还是蛮方便的,只是,他的pv, vg, lv,一开始太绕,入门有点门槛,不像直接fdisk后格式化挂载那么方便. ","date":"2023-02-17","objectID":"/proxmox-ve-%E4%B8%AD%E6%89%A9%E5%B1%95pvm-local%E7%A9%BA%E9%97%B4/:4:0","tags":["proxmox ve","linux","部署","lvm","扩展"],"title":"proxmox ve 中扩展pvm-local空间","uri":"/proxmox-ve-%E4%B8%AD%E6%89%A9%E5%B1%95pvm-local%E7%A9%BA%E9%97%B4/"},{"categories":null,"content":"proxmox ve 中nvme电源管理问题导致的磁盘性能急剧下降问题 这几天部署了proxmox ve双节点集群,正常用没什么问题,但是过了一天,dell r720这台主机,ssh上去发现shell的反应好慢,然后进去里面的linux container,也是反应慢得狠,每打一个命令,zsh都要卡半天. 以为是zsh的问题,换了bash, fish只是强一点点,用vim打开本地文件也是很慢,是不是硬盘出了问题? 这台dell主机上的系统盘是West Digital的SN750 1T,照说应该不慢,于是我测了一下: time dd if=/dev/zero of=tst.out bs=4M count=256 不测不知道,一测吓一跳: 256+0 records in 256+0 records out 1073741824 bytes (1.1 GB, 1.0 GiB) copied, 42.666 s, 24 MB/s 慢得不正常, sudo dmesg | grep -i error, sudo grep -i 'error' /var/log/syslog 都没发现有什么问题,是系统磁盘,装好后就没动过. 重启大法试一下,发现进系统需要好长时间,用smarttools,查看,也没有坏道,没任何错误,郁闷了,google,bing搜索了半天,没有太大收获,有一个回答里面带过可能是apm电源管理的问题,要使用hdparm来查看设置,找了半天,对我的硬盘没效果,会报错. 想了半天,发现我搜索的是ssd,我换了个关键字nvme去搜索. 发现了一个新工具: nvme-ctl, 有人说用这个来检查nvme的电源管理配置,查了下manpage,要用nvme get-feature来查看电源管理,但是里面的参数--feature-id是什么没说,又继续找. 在nvme的官网找到一个,feature-id=0x02是指电源管理,试着运行了一下: sudo nvme get-feature -f 0x02 /dev/nvme0 -H 得到结果: get-feature:0x2 (Power Management), Current value:0x000003 Workload Hint (WH): 0 - No Workload Power State (PS): 3 有结果了,可是0x03具体是多少呢?我想起来之前用smarttools查看的时候好像有电源配置列表,试了一下,真有: Supported Power States St Op Max Active Idle RL RT WL WT Ent_Lat Ex_Lat 0 + 3.50W 2.90W - 0 0 0 0 0 0 1 + 2.70W 1.80W - 0 0 0 0 0 0 2 + 1.90W 1.50W - 0 0 0 0 0 0 3 - 0.0200W - - 3 3 3 3 3900 11000 4 - 0.0050W - - 4 4 4 4 5000 39000 可以看到0x03和前面的差距好大,基本就是休眠了,把他调到0x02试试: sudo nvme set-feature /dev/nvme0 -f 0x02 --value=2 结果舒服了: 4096+0 records in 4096+0 records out 16777216 bytes (17 MB, 16 MiB) copied, 0.0757074 s, 222 MB/s dd if=/dev/zero of=tst.out bs=4k count=4096 0.00s user 0.03s system 39% cpu 0.080 total 222 MB/s读写终于感觉了,给他改到0x01: sudo nvme set-feature /dev/nvme0 -f 0x02 --value=0x01 结果: 256+0 records in 256+0 records out 1073741824 bytes (1.1 GB, 1.0 GiB) copied, 2.3109 s, 465 MB/s dd if=/dev/zero of=tst.out bs=4M count=256 0.00s user 1.43s system 57% cpu 2.495 total 折腾了一晚上,准备重装系统了,用new bing的chat gpt一步步对话找到了答案,chat gpt虽然厉害,但是提问也很重要,他可没有人类那么强的猜测能力. 终于实现速度自由了. ","date":"2023-02-17","objectID":"/proxmox-ve-%E4%B8%ADnvme%E7%94%B5%E6%BA%90%E7%AE%A1%E7%90%86%E9%97%AE%E9%A2%98%E5%AF%BC%E8%87%B4%E7%9A%84%E7%A3%81%E7%9B%98%E6%80%A7%E8%83%BD%E6%80%A5%E5%89%A7%E4%B8%8B%E9%99%8D%E9%97%AE%E9%A2%98/:0:0","tags":["proxmox ve","linux","部署","nvme","APM","电源管理","性能"],"title":"proxmox ve 中nvme电源管理问题导致的磁盘性能急剧下降问题","uri":"/proxmox-ve-%E4%B8%ADnvme%E7%94%B5%E6%BA%90%E7%AE%A1%E7%90%86%E9%97%AE%E9%A2%98%E5%AF%BC%E8%87%B4%E7%9A%84%E7%A3%81%E7%9B%98%E6%80%A7%E8%83%BD%E6%80%A5%E5%89%A7%E4%B8%8B%E9%99%8D%E9%97%AE%E9%A2%98/"},{"categories":null,"content":"glusterfs重建volume ","date":"2023-02-16","objectID":"/glusterfs%E9%87%8D%E5%BB%BAvolume/:0:0","tags":["proxmox ve","linux","分布式","开发笔记","部署"],"title":"glusterfs重建volume","uri":"/glusterfs%E9%87%8D%E5%BB%BAvolume/"},{"categories":null,"content":"启因 因为之前做glusterfs集群时,比较急,直接用的pve主机的网络地址,运行了几天,发现volume同步的时候,占用了pve本身的网络通道,正好dell r720有4个网口,e3主机上有2个,所以都拿出一个来单独做gluster的绑定地址 结果没想到,我直接在两边的hosts文件里面将对应gluster1, gluster2的ip修改了,结果不行,还是走的原来的地址,而且,gluster1上一直显示gluster不在线,于是我就想删除了volume重新配置. ","date":"2023-02-16","objectID":"/glusterfs%E9%87%8D%E5%BB%BAvolume/:1:0","tags":["proxmox ve","linux","分布式","开发笔记","部署"],"title":"glusterfs重建volume","uri":"/glusterfs%E9%87%8D%E5%BB%BAvolume/"},{"categories":null,"content":"过程 先用new bing问了一下他,怎么删除volume, 他给出了步骤,不过我发现有一步反了,我自己试了一下,按如下步骤: 两边都执行:停止volume: sudo gluster vol stop VMS 两边都执行:sudo umount gluster1:/tank/gfs/s 两边都删除brick: sudo gluster vol remove-brick VMS replica 1 gluster2:/tank/gfs/s force, 注意,gluster2删除gluster1,gluster1删除gluster2 sudo gluster vol delete VMS start 这一步会报错,说有peer还在,因为我在gluster1上显示gluster2一直是disconnect,因此要删除peer 查看peer: sudo gluster peer statue, 会显示是disconnected 两边都删除peer: sudo gluster peer detach gluster2 再次sudo gluster peer status显示已经没有peer了 删除volume: sudo gluster volume delete VMS 显示删除成功 ","date":"2023-02-16","objectID":"/glusterfs%E9%87%8D%E5%BB%BAvolume/:2:0","tags":["proxmox ve","linux","分布式","开发笔记","部署"],"title":"glusterfs重建volume","uri":"/glusterfs%E9%87%8D%E5%BB%BAvolume/"},{"categories":null,"content":"重新加入时,如果报错 两边节点都要做: sudo systemctl stop glusterd peer probe: failed: g1 is either already part of another cluster or having volumes configured, 就需要在g1的主机上,将/var/lib/glusterd目录下面除glusterd.info文件的其它全部删除掉,再去sudo glusterd peer probe g1 删除/tank/gfs/s/.glusterfs 但是还是会报错/tanks/gfs/s已经在一个volume中了,没办法我又重新建了一个目录 重要, 新建的目录,一定要mount之后,再向mount之后的目录里面拷贝,如:sudo mount g1:vms, 挂载到/vms之后,向/vms里面拷贝,不然无法同步,参见: stackoverfow ","date":"2023-02-16","objectID":"/glusterfs%E9%87%8D%E5%BB%BAvolume/:2:1","tags":["proxmox ve","linux","分布式","开发笔记","部署"],"title":"glusterfs重建volume","uri":"/glusterfs%E9%87%8D%E5%BB%BAvolume/"},{"categories":null,"content":"总结 gluster节点的地址不能随便改,需要用命令去设置 ","date":"2023-02-16","objectID":"/glusterfs%E9%87%8D%E5%BB%BAvolume/:3:0","tags":["proxmox ve","linux","分布式","开发笔记","部署"],"title":"glusterfs重建volume","uri":"/glusterfs%E9%87%8D%E5%BB%BAvolume/"},{"categories":null,"content":"正确的做法 (未试过) 停止volume: sudo gluster volume stop VMS sudo umount /vms gluster volume set VMS config.transport tcp gluster volume set VMS config.transport.tcp.bind-address newaddress gluster volume set VMS config.transport.socket.bind-address newaddress gluster volume set VMS config.transport.rdma.bind-address newaddress sudo gluster volume start VMS sudo mount /vms ","date":"2023-02-16","objectID":"/glusterfs%E9%87%8D%E5%BB%BAvolume/:3:1","tags":["proxmox ve","linux","分布式","开发笔记","部署"],"title":"glusterfs重建volume","uri":"/glusterfs%E9%87%8D%E5%BB%BAvolume/"},{"categories":null,"content":"nestjs中,Service无法找到Repository依赖 ","date":"2023-02-14","objectID":"/nestjs%E4%B8%ADservice%E6%97%A0%E6%B3%95%E6%89%BE%E5%88%B0repository%E4%BE%9D%E8%B5%96/:0:0","tags":["nestjs","typescript","node","开发笔记"],"title":"nestjs中,Service无法找到Repository依赖.md","uri":"/nestjs%E4%B8%ADservice%E6%97%A0%E6%B3%95%E6%89%BE%E5%88%B0repository%E4%BE%9D%E8%B5%96/"},{"categories":null,"content":"启因 如下代码: @Injectable() export class SiteRbacService { constructor( @InjectRepository(RbacEntity) public readonly repository: Repository\u003cRbacEntity\u003e, ) {} create(createRbacDto: CreateRbacDto) { return 'This action adds a new rbac'; } findAll() { return `This action returns all rbac`; } findOne(id: number) { return `This action returns a #${id} rbac`; } update(id: number, updateRbacDto: UpdateRbacDto) { return `This action updates a #${id} rbac`; } remove(id: number) { return `This action removes a #${id} rbac`; } } 运行时会报错: Nest can't resolve dependencies of the SiteRbacService,日志显示就是: @InjectRepository(RbacEntity) public readonly repository: Repository\u003cRbacEntity\u003e 这个没有引入 ","date":"2023-02-14","objectID":"/nestjs%E4%B8%ADservice%E6%97%A0%E6%B3%95%E6%89%BE%E5%88%B0repository%E4%BE%9D%E8%B5%96/:1:0","tags":["nestjs","typescript","node","开发笔记"],"title":"nestjs中,Service无法找到Repository依赖.md","uri":"/nestjs%E4%B8%ADservice%E6%97%A0%E6%B3%95%E6%89%BE%E5%88%B0repository%E4%BE%9D%E8%B5%96/"},{"categories":null,"content":"解决方法 在 site-rbac.module.ts中增加: @Module( { imports: [ TypeOrmModule.forFeature([RbacEntity]), ] } ) ","date":"2023-02-14","objectID":"/nestjs%E4%B8%ADservice%E6%97%A0%E6%B3%95%E6%89%BE%E5%88%B0repository%E4%BE%9D%E8%B5%96/:2:0","tags":["nestjs","typescript","node","开发笔记"],"title":"nestjs中,Service无法找到Repository依赖.md","uri":"/nestjs%E4%B8%ADservice%E6%97%A0%E6%B3%95%E6%89%BE%E5%88%B0repository%E4%BE%9D%E8%B5%96/"},{"categories":null,"content":"proxmox ve VM挂载物理硬盘 先找到要挂载的硬盘的id: lsblk |awk 'NR==1{print $0\" DEVICE-ID(S)\"}NR\u003e1{dev=$1;printf $0\" \";system(\"find /dev/disk/by-id -lname \\\"*\"dev\"\\\" -printf \\\" %p\\\"\");print \"\";}'|grep -v -E 'part|lvm' 结果类似: NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT DEVICE-ID(S) loop0 7:0 0 20G 0 loop loop1 7:1 0 80G 0 loop loop2 7:2 0 50G 0 loop sda 8:0 0 3.6T 0 disk /dev/disk/by-id/ata-WDC_WD40EJRX-XXXXXXX_WD-WWWWW0XXXXXX /dev/disk/by-id/wwn-0x5000000000000 比如要挂载/dev/disk/by-id/wwn-0x5000000000000,VM编号为: 103,执行如下操作: # -scsi2为第二块scsi设备,如果已经被占用,就换一个编号 qm set 103 -scsi2 /dev/disk/by-id/wwn-0x5000000000000 #最后会输出: # update VM 103: -scsi2 /dev/disk/by-id/wwn-0x5000000000000 设置完成后,查询一下: grep wwn-0x5000000000000 /etc/pve/qemu-server/103.conf 拨出磁盘: qm unlink 103 --idlist scsi2 ","date":"2023-02-14","objectID":"/proxmox-ve-vm%E6%8C%82%E8%BD%BD%E7%89%A9%E7%90%86%E7%A1%AC%E7%9B%98/:0:0","tags":["proxmox ve","linux","虚拟机","磁盘"],"title":"proxmox ve VM挂载物理硬盘","uri":"/proxmox-ve-vm%E6%8C%82%E8%BD%BD%E7%89%A9%E7%90%86%E7%A1%AC%E7%9B%98/"},{"categories":null,"content":"gluster brick下线问题解决 ","date":"2023-02-11","objectID":"/gluster-brick%E4%B8%8B%E7%BA%BF%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/:0:0","tags":["proxmox ve","gluster","分布式","gstatus"],"title":"gluster brick下线问题解决","uri":"/gluster-brick%E4%B8%8B%E7%BA%BF%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/"},{"categories":null,"content":"下线问题 刚装好gluster,在上面存放了linux container的rootfs,这样linux container就可以在两台pve的群集中做高可用了. 空闲的时候,用命令:sudo gluster vol status VMS查看了下,发现有一个brick是offline的状态. 网上查了下,安装gstatus: curl -fsSL https://github.com/gluster/gstatus/releases/latest/download/install.sh | sudo bash -x gstatus --version 安装完成后, 运行: sudo gstatus -a -b, 发现: gluster1是offline状态, 查了下,找到一个解决办法: 强制启动, 照着来: sudo gluster vol start VMS force 运行后不一会儿就正常了. ","date":"2023-02-11","objectID":"/gluster-brick%E4%B8%8B%E7%BA%BF%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/:1:0","tags":["proxmox ve","gluster","分布式","gstatus"],"title":"gluster brick下线问题解决","uri":"/gluster-brick%E4%B8%8B%E7%BA%BF%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/"},{"categories":null,"content":"heal问题 查看gluster的时候,发现需要heal, 查看: sudo gluster heal VMS info 查看是否有需要heal的 heal: sudo gluster heal VMS, 查看汇总: sudo gluster vol heal VMS summary 查看统计: sudo gluster vol heal VMS statistics heal-count ","date":"2023-02-11","objectID":"/gluster-brick%E4%B8%8B%E7%BA%BF%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/:2:0","tags":["proxmox ve","gluster","分布式","gstatus"],"title":"gluster brick下线问题解决","uri":"/gluster-brick%E4%B8%8B%E7%BA%BF%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/"},{"categories":null,"content":"proxmox ve 部署双节点HA集群及glusterfs分布式文件系统 需要保存两个pve节点的版本一样 两个proxmox ve节点,实现高可用vm,lxc自动迁移 ","date":"2023-02-09","objectID":"/proxmox-ve-%E9%83%A8%E7%BD%B2%E5%8F%8C%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4%E5%8F%8Aglusterfs%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:0:0","tags":["proxmox ve","linux","分布式","开发笔记","部署"],"title":"proxmox ve 部署双节点HA集群及glusterfs分布式文件系统笔记","uri":"/proxmox-ve-%E9%83%A8%E7%BD%B2%E5%8F%8C%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4%E5%8F%8Aglusterfs%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":null,"content":"修改hosts文件 在两台pve的/etc/hosts中,增加如下host 192.168.1.229 pve1.local pve1 192.168.1.230 pve2.local pve2 192.168.1.229 gluster1 192.168.1.230 gluster2 ","date":"2023-02-09","objectID":"/proxmox-ve-%E9%83%A8%E7%BD%B2%E5%8F%8C%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4%E5%8F%8Aglusterfs%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:1:0","tags":["proxmox ve","linux","分布式","开发笔记","部署"],"title":"proxmox ve 部署双节点HA集群及glusterfs分布式文件系统笔记","uri":"/proxmox-ve-%E9%83%A8%E7%BD%B2%E5%8F%8C%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4%E5%8F%8Aglusterfs%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":null,"content":"安装glusterfs 以下操作都在两台机器上做, 这里分别为pve1, pve2 wget -O - https://download.gluster.org/pub/gluster/glusterfs/9/rsa.pub | apt-key add - DEBID=$(grep 'VERSION_ID=' /etc/os-release | cut -d '=' -f 2 | tr -d '\"') DEBVER=$(grep 'VERSION=' /etc/os-release | grep -Eo '[a-z]+') DEBARCH=$(dpkg --print-architecture) echo deb https://download.gluster.org/pub/gluster/glusterfs/LATEST/Debian/${DEBID}/${DEBARCH}/apt ${DEBVER} main \u003e /etc/apt/sources.list.d/gluster.list apt update \u0026\u0026 apt install -y glusterfs-server 需要保存gluster的版本一样 gluster --version 如果一样,请升级,我有一台是9.2,加了源也没不会直接升级到10.3,需要这样做: apt-get list -a glusterfs-server 会出现全部的版本,然后安装对应的 apt-get install glusterfs-server=\"10.3-1\" 在pve1上编辑: nano /etc/glusterfs/glusterd.vol, 在 option transport.socket.listen-port 24007 增加: option transport.rdma.bind-address gluster1 option transport.socket.bind-address gluster1 option transport.tcp.bind-address gluster1 在pve2上编辑: nano /etc/glusterfs/glusterd.vol, 在 option transport.socket.listen-port 24007 增加: option transport.rdma.bind-address gluster2 option transport.socket.bind-address gluster2 option transport.tcp.bind-address gluster2 ","date":"2023-02-09","objectID":"/proxmox-ve-%E9%83%A8%E7%BD%B2%E5%8F%8C%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4%E5%8F%8Aglusterfs%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:2:0","tags":["proxmox ve","linux","分布式","开发笔记","部署"],"title":"proxmox ve 部署双节点HA集群及glusterfs分布式文件系统笔记","uri":"/proxmox-ve-%E9%83%A8%E7%BD%B2%E5%8F%8C%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4%E5%8F%8Aglusterfs%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":null,"content":"开启服务 systemctl enable glusterd.service systemctl start glusterd.service 重要,在pve2上需要执行命令以加入集群 gluster peer probe gluster1 显示: peer probe: success 就OK ","date":"2023-02-09","objectID":"/proxmox-ve-%E9%83%A8%E7%BD%B2%E5%8F%8C%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4%E5%8F%8Aglusterfs%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:2:1","tags":["proxmox ve","linux","分布式","开发笔记","部署"],"title":"proxmox ve 部署双节点HA集群及glusterfs分布式文件系统笔记","uri":"/proxmox-ve-%E9%83%A8%E7%BD%B2%E5%8F%8C%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4%E5%8F%8Aglusterfs%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":null,"content":"增加volume 这里直接建立在zfs上,保证两台pve都使用一样的路径建立volume,这里的路径是/tank/gfs 注意如果是zfs的话,不要能使用挂载根目前,而要使用目录, 下面例子中,/tank/gfs就是一个zfs的挂载,在下面建立了一个子目录s来用作volume gluster volume create VMS replica 2 gluster1:/tank/gfs/s gluster2:/tank/gfs/s gluster vol start VMS ","date":"2023-02-09","objectID":"/proxmox-ve-%E9%83%A8%E7%BD%B2%E5%8F%8C%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4%E5%8F%8Aglusterfs%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:2:2","tags":["proxmox ve","linux","分布式","开发笔记","部署"],"title":"proxmox ve 部署双节点HA集群及glusterfs分布式文件系统笔记","uri":"/proxmox-ve-%E9%83%A8%E7%BD%B2%E5%8F%8C%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4%E5%8F%8Aglusterfs%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":null,"content":"检查状态 gluster vol info VMS gluster vol status VMS ","date":"2023-02-09","objectID":"/proxmox-ve-%E9%83%A8%E7%BD%B2%E5%8F%8C%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4%E5%8F%8Aglusterfs%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:2:3","tags":["proxmox ve","linux","分布式","开发笔记","部署"],"title":"proxmox ve 部署双节点HA集群及glusterfs分布式文件系统笔记","uri":"/proxmox-ve-%E9%83%A8%E7%BD%B2%E5%8F%8C%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4%E5%8F%8Aglusterfs%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":null,"content":"增加挂载 在两台pve上都要做 mkdir /vms 修改pve1的/etc/fstab,增加 gluster1:VMS /vms glusterfs defaults,_netdev,x-systemd.automount,backupvolfile-server=gluster2 0 0 修改pve2的/etc/fstab,增加 gluster2:VMS /vms glusterfs defaults,_netdev,x-systemd.automount,backupvolfile-server=gluster1 0 0 重启两台pve,让/mnt挂载 两台pve不重启挂载 mount /vms ","date":"2023-02-09","objectID":"/proxmox-ve-%E9%83%A8%E7%BD%B2%E5%8F%8C%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4%E5%8F%8Aglusterfs%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:2:4","tags":["proxmox ve","linux","分布式","开发笔记","部署"],"title":"proxmox ve 部署双节点HA集群及glusterfs分布式文件系统笔记","uri":"/proxmox-ve-%E9%83%A8%E7%BD%B2%E5%8F%8C%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4%E5%8F%8Aglusterfs%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":null,"content":"解决split-brain问题 两个节点的gluster会出现split-brain问题,就是两节点票数一样,谁也不听谁的,解决办法如下: gluster vol set vms cluster.heal-timeout 5 gluster volume heal vms enable gluster vol set vms cluster.quorum-reads false gluster vol set vms cluster.quorum-count 1 gluster vol set vms network.ping-timeout 2 gluster volume set vms cluster.favorite-child-policy mtime gluster volume heal vms granular-entry-heal enable gluster volume set vms cluster.data-self-heal-algorithm full ","date":"2023-02-09","objectID":"/proxmox-ve-%E9%83%A8%E7%BD%B2%E5%8F%8C%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4%E5%8F%8Aglusterfs%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:3:0","tags":["proxmox ve","linux","分布式","开发笔记","部署"],"title":"proxmox ve 部署双节点HA集群及glusterfs分布式文件系统笔记","uri":"/proxmox-ve-%E9%83%A8%E7%BD%B2%E5%8F%8C%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4%E5%8F%8Aglusterfs%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":null,"content":"pve双节点集群设置 第一个创建,第二个加入,没什么好说的 ","date":"2023-02-09","objectID":"/proxmox-ve-%E9%83%A8%E7%BD%B2%E5%8F%8C%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4%E5%8F%8Aglusterfs%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:4:0","tags":["proxmox ve","linux","分布式","开发笔记","部署"],"title":"proxmox ve 部署双节点HA集群及glusterfs分布式文件系统笔记","uri":"/proxmox-ve-%E9%83%A8%E7%BD%B2%E5%8F%8C%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4%E5%8F%8Aglusterfs%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":null,"content":"创建共享目录 在DataCenter中的Storage中,点Add,Directory填/vms, 钩选 share ","date":"2023-02-09","objectID":"/proxmox-ve-%E9%83%A8%E7%BD%B2%E5%8F%8C%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4%E5%8F%8Aglusterfs%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:4:1","tags":["proxmox ve","linux","分布式","开发笔记","部署"],"title":"proxmox ve 部署双节点HA集群及glusterfs分布式文件系统笔记","uri":"/proxmox-ve-%E9%83%A8%E7%BD%B2%E5%8F%8C%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4%E5%8F%8Aglusterfs%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":null,"content":"HA设置 修改 /etc/pve/corosync.conf 在quorum中增加,变成这样: quorum { provider: corosync_votequorum expected_votes: 1 two_node: 1 } 其中, expected_votes表示希望的节点数量, two_node: 1表示,只有两个节点,还有一个wait_for_all: 0, NOTES: enabling two_node: 1 automatically enables wait_for_all. It is still possible to override wait_for_all by explicitly setting it to 0. If more than 2 nodes join the cluster, the two_node option is automatically disabled. ","date":"2023-02-09","objectID":"/proxmox-ve-%E9%83%A8%E7%BD%B2%E5%8F%8C%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4%E5%8F%8Aglusterfs%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:4:2","tags":["proxmox ve","linux","分布式","开发笔记","部署"],"title":"proxmox ve 部署双节点HA集群及glusterfs分布式文件系统笔记","uri":"/proxmox-ve-%E9%83%A8%E7%BD%B2%E5%8F%8C%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4%E5%8F%8Aglusterfs%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":null,"content":"nestjs中,JwtService报错: “JsonWebTokenError: secret or public key must be provided” ","date":"2023-02-07","objectID":"/nestjs-jwtservice-seccret-or-public-key-must-be-provied/:0:0","tags":["nestjs","typescript","node","开发笔记"],"title":"nestjs中,JwtService报错,没有SECRET","uri":"/nestjs-jwtservice-seccret-or-public-key-must-be-provied/"},{"categories":null,"content":"原因 最近老是出现这个错误: JsonWebTokenError: secret or public key must be provided, 我已经在环境变量中增加imports: [JwtService], 也在底层库shared.module.ts里面增加了: imports: [ JwtModule.registerAsync({ imports: [ConfigModule], useFactory: (configService: ConfigService) =\u003e ({ secret: configService.get\u003cstring\u003e('JWT_SECRET') as string, signOptions: { expiresIn: '1d' }, }), inject: [ConfigService], }), ] 结果AuthGurad中的JwtService还是找不到secret, 按照之前的经验,应该是AuthModule中没有正确导入 ","date":"2023-02-07","objectID":"/nestjs-jwtservice-seccret-or-public-key-must-be-provied/:1:0","tags":["nestjs","typescript","node","开发笔记"],"title":"nestjs中,JwtService报错,没有SECRET","uri":"/nestjs-jwtservice-seccret-or-public-key-must-be-provied/"},{"categories":null,"content":"解决办法 将 auth.module.ts中的imports: [JwtService]换成imports: [SharedModule] 因为调用JwtModule.registerAsync是在SharedModule中,而如果在auth.module.ts中再次直接imports: [JwtModule],可能将原来的覆盖了. ","date":"2023-02-07","objectID":"/nestjs-jwtservice-seccret-or-public-key-must-be-provied/:2:0","tags":["nestjs","typescript","node","开发笔记"],"title":"nestjs中,JwtService报错,没有SECRET","uri":"/nestjs-jwtservice-seccret-or-public-key-must-be-provied/"},{"categories":null,"content":"nestjs中,AuthGuard类,在CanActive函数中无法调用Inject ","date":"2023-02-06","objectID":"/nestjs%E4%B8%ADauthguard%E7%B1%BB%E5%9C%A8canactive%E5%87%BD%E6%95%B0%E4%B8%AD%E6%97%A0%E6%B3%95%E8%B0%83%E7%94%A8inject/:0:0","tags":["nestjs","typescript","node","开发笔记"],"title":"nestjs中,AuthGuard类,在CanActive函数中无法调用Inject.md","uri":"/nestjs%E4%B8%ADauthguard%E7%B1%BB%E5%9C%A8canactive%E5%87%BD%E6%95%B0%E4%B8%AD%E6%97%A0%E6%B3%95%E8%B0%83%E7%94%A8inject/"},{"categories":null,"content":"启因 最近写nestjs项目,他的UserGuard很方便,相当于在route处理request时,可以经由AuthGuard来处理验证代码. 但是,我在写的过程中,出了一个问题,花了很长时间来解决,比如如下 StaffAuthGuard.ts代码: import { ExecutionContext, Inject, Injectable } from '@nestjs/common'; import { StaffAuthService } from './staff-auth.service'; import { of } from 'rxjs'; import { AuthGuard } from '@nestjs/passport'; @Injectable() export class StaffJwtAuthGuard extends AuthGuard('jwt') { constructor(private authService: StaffAuthService) { super(authService); this.authService = authService; console.log( '🚀 ~ file: staff-auth.guard.ts:11 ~ StaffJwtAuthGuard ~ constructor ~ authService', authService, ', this.authService: ', this.authService, ); } canActivate(context: ExecutionContext) { if (context.getType() != 'http') { return false; } const authHeader = context.switchToHttp().getRequest() .headers.authorization; if (!authHeader) { return false; } const authHeaderParts = authHeader.split(' '); if (authHeaderParts.length != 2) { return false; } const [, jwt] = authHeaderParts; this.authService .verifyJwt(jwt) .then((res) =\u003e { const exp = res.exp; if (!exp) return of(false); const TOKEN_EXP_MS = exp * 1000; const isJwtValid = Date.now() \u003c TOKEN_EXP_MS; // return of(isJwtValid); return isJwtValid; }) .catch((err) =\u003e { console.log( '🚀 ~ file: staff-auth.guard.ts:35 ~ StaffJwtAuthGuard ~ canActivate ~ err', err, ); // return of(false); return false; }); return super.canActivate(context); } } 在调用api时,经由StaffAuthGuard.canActivate时,就会报undefined,加了日志后,发现是这行: this.authService .verifyJwt(jwt) 出错,此处就是this.authService未定义,但是编译可以通过,于是我在constructor函数中加上了日志,this.authService明明是有值的,为什么到调用的时候就没有了? ","date":"2023-02-06","objectID":"/nestjs%E4%B8%ADauthguard%E7%B1%BB%E5%9C%A8canactive%E5%87%BD%E6%95%B0%E4%B8%AD%E6%97%A0%E6%B3%95%E8%B0%83%E7%94%A8inject/:1:0","tags":["nestjs","typescript","node","开发笔记"],"title":"nestjs中,AuthGuard类,在CanActive函数中无法调用Inject.md","uri":"/nestjs%E4%B8%ADauthguard%E7%B1%BB%E5%9C%A8canactive%E5%87%BD%E6%95%B0%E4%B8%AD%E6%97%A0%E6%B3%95%E8%B0%83%E7%94%A8inject/"},{"categories":null,"content":"解决过程 百思不得其解,搞了几天,我都要放弃了,其间我还用了ChatGPT来帮我解决问题,他给了我的问题: It's difficult to determine what could be causing this.authService to be undefined without seeing the entire code. However, here are a few common issues that could be causing the problem: The AuthService has not been imported correctly: Make sure that you have imported the AuthService using the correct import statement and path. The AuthService has not been added to the providers array in the module: If the AuthService is not part of the module's providers array, it won't be available for injection. The AuthService has not been injected into the constructor of the StaffJwtAuthGuard: If you are not injecting the AuthService into the constructor of the StaffJwtAuthGuard, then it won't be available as a property on the class. Here's an example of how to correctly inject the AuthService into the StaffJwtAuthGuard: 照着对比了下,基本是这样做的,但是还是解决不了问题. 过了几天,中间我搞了点别的事情,换换心情,然后又回来解决这个,继续google,在nestjs的官方issue中找到一条: [# Nest can’t resolve dependencies of the AuthGuard (Guard decorator) #893](Nest can't resolve dependencies of the AuthGuard (Guard decorator) · Issue #893 · nestjs/nest · GitHub) 跟我的问题一样,也是在AuthGuard中无法引用inject后的服务,有一个回答: [Also ensure that you aren’t providing AuthService twice](Nest can't resolve dependencies of the AuthGuard (Guard decorator) · Issue #893 · nestjs/nest · GitHub) 引起了我的注意, 仔细观察日志,我发现StaffAuthGuard被初始化了两次,第一次日志里面有authSerivce,是正常有值的,第二次是undefined.顺着这个思路,把所有的StaffAuthGuard的地方都找出来, 使用//大法,一个个屏蔽测试,发现原因: 我的StaffJwtAuth是定义在app中,而需要用到此模块的controller在其引用的shared库中,按照官方文档(忘了具体位置了),如果在库中这样就需要在app中将guard定义为全局,如: providers: [ { provide: APP_GUARD, useClass: StaffJwtAuthGuard, }, ], 我就是这样定义了全局了,但是,在我调用的api的controller位置,也加上了@UseGuard(StaffJwtAuthGuard),就导致初始化了两次,并且第二次参数为undefined,将controller上的@UseGuard去掉后,就正常了. ","date":"2023-02-06","objectID":"/nestjs%E4%B8%ADauthguard%E7%B1%BB%E5%9C%A8canactive%E5%87%BD%E6%95%B0%E4%B8%AD%E6%97%A0%E6%B3%95%E8%B0%83%E7%94%A8inject/:2:0","tags":["nestjs","typescript","node","开发笔记"],"title":"nestjs中,AuthGuard类,在CanActive函数中无法调用Inject.md","uri":"/nestjs%E4%B8%ADauthguard%E7%B1%BB%E5%9C%A8canactive%E5%87%BD%E6%95%B0%E4%B8%AD%E6%97%A0%E6%B3%95%E8%B0%83%E7%94%A8inject/"},{"categories":null,"content":"思考 之后做了几个测试,把StaffAuthModule也放到库里面,屏掉全局APP_GUARD代码,在controller中加上代码,结果只有一个初始constructor调用,而且里面的authService是undefined 之后我又继续google, 在官方issue里面又找到一个: middlewares are loosely coupled from modules, thus it may be better to use them instead. If you prefer to use guards, you need to guarantee an access to the AuthService. You can export this service from the AuthModule, and then import this module wherever you want to use your guard. ,意思就是说,在我这个场景中,在使用StaffAuthGuard.StaffAuthService的模块中,需要保证能访问到StaffAuthService, 于是,我在controller所在的模块的imports中增加了导入StaffAuthModule,结果,OK了,结论就是在使用AuthGurad的模块中,因为AuthGuard是松散的,所有需要在调用他的模块中,保证他所有的依赖都会被import 终于解决了,花了几天时间,不解决不舒服,现在舒服了,可以继续折腾了. ","date":"2023-02-06","objectID":"/nestjs%E4%B8%ADauthguard%E7%B1%BB%E5%9C%A8canactive%E5%87%BD%E6%95%B0%E4%B8%AD%E6%97%A0%E6%B3%95%E8%B0%83%E7%94%A8inject/:3:0","tags":["nestjs","typescript","node","开发笔记"],"title":"nestjs中,AuthGuard类,在CanActive函数中无法调用Inject.md","uri":"/nestjs%E4%B8%ADauthguard%E7%B1%BB%E5%9C%A8canactive%E5%87%BD%E6%95%B0%E4%B8%AD%E6%97%A0%E6%B3%95%E8%B0%83%E7%94%A8inject/"},{"categories":null,"content":"nestjsx/crud xxxRepository not found问题解决 nestjsx/crud可以快速帮我生成 使用@Entity 定义好typeorm对象的对应service,controller的 增删改查操作API . 但是,使用 nestjsx/crud时,总是会有例如: Nest can't resolve dependencies of the XXXService (?). Please make sure that the argument UtilsService at index [0] is available in the UtilsModule context.的错误, 其原因一般为,在XXXModule中没有import对应 TypeOrm.forFeature([XXXEntity]),在exports及providers中没有导出XXXService, 总要, 在app.module.ts中,同样也需要在@Muldue的imports中增加XXXModule. 注意,如果XXXModule是定义在nestjs的library中,需要在XXXModule.eports中增加TypeOrmModule,不然在app编译运行后,会报错提示XXXService中没有导入XXXEntityRepository对象. tags: tag: nestjs, typeorm, entity, nestjsx/crud, can’t resolve dependencies ","date":"2023-02-06","objectID":"/nestjsx-crud-xxxrepository-not-found%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/:0:0","tags":["nestjs","typescript","node","开发笔记"],"title":"nestjsx/crud xxxRepository not found问题解决","uri":"/nestjsx-crud-xxxrepository-not-found%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/"},{"categories":null,"content":"Nestjs, typeorm中的entity中的互相引用问题 20230131-152600 使用nestjs时,用到typeorm,有互相引用关系的entity,老是报错,按照官方文档,最后总会报一个entity metadata not found的错误. ","date":"2023-01-31","objectID":"/nestjs-typeorm-entity-%E4%BA%92%E7%9B%B8%E5%BC%95%E7%94%A8%E9%97%AE%E9%A2%98/:0:0","tags":["nestjs","typescript","node","开发笔记"],"title":"Nestjs, typeorm中的entity中的互相引用问题","uri":"/nestjs-typeorm-entity-%E4%BA%92%E7%9B%B8%E5%BC%95%E7%94%A8%E9%97%AE%E9%A2%98/"},{"categories":null,"content":"会出错的方式 试了好多次,发现需要这样写,假设有两个entity, 一个是UserEntity, 一个是CarEntity, 互相引用,按以下方法写,会报circular import errors ","date":"2023-01-31","objectID":"/nestjs-typeorm-entity-%E4%BA%92%E7%9B%B8%E5%BC%95%E7%94%A8%E9%97%AE%E9%A2%98/:1:0","tags":["nestjs","typescript","node","开发笔记"],"title":"Nestjs, typeorm中的entity中的互相引用问题","uri":"/nestjs-typeorm-entity-%E4%BA%92%E7%9B%B8%E5%BC%95%E7%94%A8%E9%97%AE%E9%A2%98/"},{"categories":null,"content":"user.entity.ts import { Column, Entity, ManyToMany, PrimaryGeneratedColumn, } from 'typeorm'; import { CarEntity } from './car.entity.ts' @Entity({ name: 'users' }) export class UserEntity() { @PrimaryGeneratedColumn() id: number; @Column() name: string; @ManyToMany(() =\u003e CarEntity, (car) =\u003e car.id) car: CarEntity } ","date":"2023-01-31","objectID":"/nestjs-typeorm-entity-%E4%BA%92%E7%9B%B8%E5%BC%95%E7%94%A8%E9%97%AE%E9%A2%98/:1:1","tags":["nestjs","typescript","node","开发笔记"],"title":"Nestjs, typeorm中的entity中的互相引用问题","uri":"/nestjs-typeorm-entity-%E4%BA%92%E7%9B%B8%E5%BC%95%E7%94%A8%E9%97%AE%E9%A2%98/"},{"categories":null,"content":"car.entity.ts import { Column, Entity, ManyToMany, PrimaryGeneratedColumn, } from 'typeorm'; import { UserEntity } from './user.entity.ts' @Entity({ name: 'users' }) export class CarEntity() { @PrimaryGeneratedColumn() id: number; @Column() name: string; @ManyToMany(() =\u003e UserEntity, (user) =\u003e user.id) user: UserEntity } 这种方式就会报找不到循环引用错误的错误: circular import errors, ","date":"2023-01-31","objectID":"/nestjs-typeorm-entity-%E4%BA%92%E7%9B%B8%E5%BC%95%E7%94%A8%E9%97%AE%E9%A2%98/:1:2","tags":["nestjs","typescript","node","开发笔记"],"title":"Nestjs, typeorm中的entity中的互相引用问题","uri":"/nestjs-typeorm-entity-%E4%BA%92%E7%9B%B8%E5%BC%95%E7%94%A8%E9%97%AE%E9%A2%98/"},{"categories":null,"content":"全部按官方方式写,也会报错 ","date":"2023-01-31","objectID":"/nestjs-typeorm-entity-%E4%BA%92%E7%9B%B8%E5%BC%95%E7%94%A8%E9%97%AE%E9%A2%98/:2:0","tags":["nestjs","typescript","node","开发笔记"],"title":"Nestjs, typeorm中的entity中的互相引用问题","uri":"/nestjs-typeorm-entity-%E4%BA%92%E7%9B%B8%E5%BC%95%E7%94%A8%E9%97%AE%E9%A2%98/"},{"categories":null,"content":"user.entity.ts import { Column, Entity, ManyToMany, PrimaryGeneratedColumn, } from 'typeorm'; import type { CarEntity } from './car.entity.ts' @Entity({ name: 'users' }) export class UserEntity() { @PrimaryGeneratedColumn() id: number; @Column() name: string; @ManyToMany('CarEntity', 'id') car: CarEntity } ","date":"2023-01-31","objectID":"/nestjs-typeorm-entity-%E4%BA%92%E7%9B%B8%E5%BC%95%E7%94%A8%E9%97%AE%E9%A2%98/:2:1","tags":["nestjs","typescript","node","开发笔记"],"title":"Nestjs, typeorm中的entity中的互相引用问题","uri":"/nestjs-typeorm-entity-%E4%BA%92%E7%9B%B8%E5%BC%95%E7%94%A8%E9%97%AE%E9%A2%98/"},{"categories":null,"content":"car.entity.ts import { Column, Entity, ManyToMany, PrimaryGeneratedColumn, } from 'typeorm'; import type { UserEntity } from './user.entity.ts' @Entity({ name: 'users' }) export class CarEntity() { @PrimaryGeneratedColumn() id: number; @Column() name: string; @ManyToMany('UserEntity', 'id') user: UserEntity } 这样的方式又会报entity metadata not found的错误. ","date":"2023-01-31","objectID":"/nestjs-typeorm-entity-%E4%BA%92%E7%9B%B8%E5%BC%95%E7%94%A8%E9%97%AE%E9%A2%98/:2:2","tags":["nestjs","typescript","node","开发笔记"],"title":"Nestjs, typeorm中的entity中的互相引用问题","uri":"/nestjs-typeorm-entity-%E4%BA%92%E7%9B%B8%E5%BC%95%E7%94%A8%E9%97%AE%E9%A2%98/"},{"categories":null,"content":"正确的方式 正确的方式是,只需要一个文件按import type方式,另一个文件还是正常import user.entity.ts import { Column, Entity, ManyToMany, PrimaryGeneratedColumn, } from 'typeorm'; import { CarEntity } from './car.entity.ts' @Entity({ name: 'users' }) export class UserEntity() { @PrimaryGeneratedColumn() id: number; @Column() name: string; @ManyToMany(() =\u003e CarEntity, (car) =\u003e car.id) car: CarEntity } ","date":"2023-01-31","objectID":"/nestjs-typeorm-entity-%E4%BA%92%E7%9B%B8%E5%BC%95%E7%94%A8%E9%97%AE%E9%A2%98/:3:0","tags":["nestjs","typescript","node","开发笔记"],"title":"Nestjs, typeorm中的entity中的互相引用问题","uri":"/nestjs-typeorm-entity-%E4%BA%92%E7%9B%B8%E5%BC%95%E7%94%A8%E9%97%AE%E9%A2%98/"},{"categories":null,"content":"car.entity.ts import { Column, Entity, ManyToMany, PrimaryGeneratedColumn, } from 'typeorm'; import type { UserEntity } from './user.entity.ts' @Entity({ name: 'users' }) export class CarEntity() { @PrimaryGeneratedColumn() id: number; @Column() name: string; @ManyToMany('UserEntity', 'id') user: UserEntity } 这样就OK了. tag: nestjs, typeorm, entity, metadata not found, circular import errors ","date":"2023-01-31","objectID":"/nestjs-typeorm-entity-%E4%BA%92%E7%9B%B8%E5%BC%95%E7%94%A8%E9%97%AE%E9%A2%98/:3:1","tags":["nestjs","typescript","node","开发笔记"],"title":"Nestjs, typeorm中的entity中的互相引用问题","uri":"/nestjs-typeorm-entity-%E4%BA%92%E7%9B%B8%E5%BC%95%E7%94%A8%E9%97%AE%E9%A2%98/"},{"categories":null,"content":"设置左边栏目菜单修改位置在 chrome/browser/resources/settings/settings_menu/settings_menu.html 如果需要增加或者去掉设置就在里面改 增加的话，加一段： \u003ca id=\"new_setting\" href=\"/new_setting\" hidden=\"[[!pageVisibility.new_setting]]\"\u003e \u003ciron-icon icon=\"settings:assignment\"\u003e\u003c/iron-icon\u003e $i18n{newSettingTitle} \u003c/a\u003e 然后增加 一个目录 chrome/browser/resources/settings/new_setting 在里面放设置的页面 新建 new_setting_page.html 和new_setting_page.js, 这个是内容 新建 new_setting_section.htm, new_setting_section.js 这个是区块 新建 BUILD.gn # Copyright 2018 The Chromium Authors. All rights reserved. # Use of this source code is governed by a BSD-style license that can be # found in the LICENSE file. import(\"//third_party/closure_compiler/compile_js.gni\") js_type_check(\"closure_compile\") { deps = [ ] } js_library(\"new_setting_page\") { deps = [ \":new_setting_section\", \"..:open_window_proxy\", \"..:route\", \"../prefs:prefs_behavior\", \"../settings_page:settings_animated_pages\", \"//ui/webui/resources/js:assert\", \"//ui/webui/resources/js:cr\", ] externs_list = [ \"$externs_path/passwords_private.js\", \"$externs_path/settings_private.js\", ] } js_library(\"new_setting_section\") { deps = [ \":address_edit_dialog\", \"//ui/webui/resources/cr_elements/cr_action_menu:cr_action_menu\", \"//ui/webui/resources/js:assert\", \"//ui/webui/resources/js:load_time_data\", \"//ui/webui/resources/js/cr/ui:focus_without_ink\", ] externs_list = [ ] } ../basic_page/basic_page.html增加 \u003clink rel=\"import\" href=\"../new_setting_page/new_setting_page.html\"\u003e \u003ctemplate is=\"dom-if\" if=\"[[showPage_(pageVisibility.new_setting)]]\" restamp\u003e \u003csettings-section page-title=\"$i18n{newSettingTitle}\" section=\"new_setting\"\u003e \u003csettings-new_setting-page prefs=\"{{prefs}}\" page-visibility=\"[[pageVisibility]]\"\u003e \u003c/settings-new_setting-page\u003e \u003c/settings-section\u003e \u003c/template\u003e 注意，如果是直接从其它页面拷贝过来的，要注册 settings-new_setting-page 这个名字，中间\"new_setting\"改成对应自己的页面名字 其中 prefs=\"…\" ,需要自己增加对应设置名称，在chrome/common/pref_names.h / .c中增加，值路径不需要前面加“prefs\",如，增加一个new_setting.some_switcher,那么在html页面中，就对应：prefs=\"prefs.new_setting.some_switcher\"，然后在 chrome/browser/profiles/profile_impl.cc → ProfileImpl::RegisterProfilePrefs 中注册(也可以自己专门写个ProfileImpl来管理），然后 在chrome/browser/profile_resetter/profile_resetter.cc 中增加一个方法来重置属性，或者放到别的方法里面（当然不好）,头文件中修改 Resettable，增加需要的属性页enum值,ProfileResetter::Reset中，将新加的值和对应的函数加进去 chrome/browser/prefs/chrome_pref_service_factory.cc 增加对应条目 重要： 在 chrome/browser/extensions/api/settings_private/prefs_util.cc 中，增加对应的白名单，不然打开设置页面会报错：”Prefs not found on element....“ // add by boost 2020-08-13 16:23:59 (*s_whitelist)[::prefs::knew_settingSomeSwitch] = settings_api::PrefType::PREF_TYPE_BOOLEAN; 增加文字i18n 在chrome/app/settings_strings.grdp 中增加一个新的ID 在chrome/browser/ui/webui/settings/settings_localized_strings_provider.cc 中，增加对应id到webui的对照变量 在chrome/app/settings_strings.grdp 中增加新的message,如： \u003cmessage name=\"IDS_SETTINGS_new_setting_SETTINGS_TITLE\" desc=\"The tile text of new_setting settings\"\u003e some settings \u003c/message\u003e 然后 运行 src\\tools\\grit\u003epython from grit.extern import tclib \u003e\u003e\u003e tclib.GenerateMessageId(\"some settings\"); 会得到一个输出id，如49303453453534，使用这个输出，在src\\chrome\\app\\resources\\generated_resources_zh-CN.xtb 中增加对应翻译 \u003ctranslation id=\"49303453453534\"\u003e一些设置\u003c/translation\u003e 增加资源打包，在chrome/browser/resources/settings/settings_resources.grd中，有几个文件就得加几个 \u003cstructure name=\"IDR_SETTINGS_new_setting_PAGE_HTML\" file=\"new_setting/new_setting_page.html\" type=\"chrome_html\" /\u003e \u003cstructure name=\"IDR_SETTINGS_new_setting_PAGE_JS\" file=\"new_setting/new_setting_page.js\" type=\"chrome_html\" /\u003e 增加 显示属性， 在chrome/browser/resources/settings/page_visibility.js * new_setting: (boolean|undefined), 并在下面增加各自的初始值 在chrome/browser/resources/settings/route.js 增加对应路由 * new_setting: (undefined|!settings.Route) if (pageVisibility.new_setting != false) { r.NEW_SETTING = r.BASIC.createSection('/new_setting', 'new_setting'); } chrome/browser/resources/settings/BUILD.gn 增加一行 group(\"closure_compile\") { deps = [ \":settings_resources\", .... \"new_setting_page:closure_compile\", ] ","date":"2020-08-14","objectID":"/chromium-zai-chromesettings-zeng-jia-xin-de-she-zhi-fang-fa/:0:0","tags":null,"title":"chromium 在chrome://settings增加新的设置方法","uri":"/chromium-zai-chromesettings-zeng-jia-xin-de-she-zhi-fang-fa/"},{"categories":null,"content":"关于 LoveIt","date":"2019-08-02","objectID":"/about/","tags":null,"title":"关于 LoveIt","uri":"/about/"},{"categories":null,"content":"  LoveIt 是一个由  Dillon 开发的简洁、优雅且高效的 Hugo 博客主题。 它的原型基于 LeaveIt 主题 和 KeepIt 主题。 Hugo 主题 LoveIt ","date":"2019-08-02","objectID":"/about/:0:0","tags":null,"title":"关于 LoveIt","uri":"/about/"},{"categories":null,"content":"特性 ","date":"2019-08-02","objectID":"/about/:1:0","tags":null,"title":"关于 LoveIt","uri":"/about/"},{"categories":null,"content":"性能和 SEO  性能优化：在 Google PageSpeed Insights 中， 99/100 的移动设备得分和 100/100 的桌面设备得分  使用基于 JSON-LD 格式 的 SEO SCHEMA 文件进行 SEO 优化  支持 Google Analytics  支持 Fathom Analytics  支持 Plausible Analytics  支持 Yandex Metrica  支持搜索引擎的网站验证 (Google, Bind, Yandex and Baidu)  支持所有第三方库的 CDN  基于 lazysizes 自动转换图片为懒加载 ","date":"2019-08-02","objectID":"/about/:1:1","tags":null,"title":"关于 LoveIt","uri":"/about/"},{"categories":null,"content":"外观和布局  桌面端/移动端 响应式布局  浅色/深色 主题模式  全局一致的设计语言  支持分页  易用和自动展开的文章目录  支持多语言和国际化  美观的 CSS 动画 社交和评论系统  支持 Gravatar 头像  支持本地头像  支持多达 73 种社交链接  支持多达 24 种网站分享  支持 Disqus 评论系统  支持 Gitalk 评论系统  支持 Valine 评论系统  支持 Facebook comments 评论系统  支持 Telegram comments 评论系统  支持 Commento 评论系统  支持 utterances 评论系统  支持 giscus 评论系统 ","date":"2019-08-02","objectID":"/about/:1:2","tags":null,"title":"关于 LoveIt","uri":"/about/"},{"categories":null,"content":"扩展功能  支持基于 Lunr.js 或 algolia 的搜索  支持 Twemoji  支持代码高亮  一键复制代码到剪贴板  支持基于 lightGallery 的图片画廊  支持 Font Awesome 图标的扩展 Markdown 语法  支持上标注释的扩展 Markdown 语法  支持分数的扩展 Markdown 语法  支持基于 $\\KaTeX$ 的数学公式  支持基于 mermaid 的图表 shortcode  支持基于 ECharts 的交互式数据可视化 shortcode  支持基于 Mapbox GL JS 的 Mapbox shortcode  支持基于 APlayer 和 MetingJS 的音乐播放器 shortcode  支持 Bilibili 视频 shortcode  支持多种注释的 shortcode  支持自定义样式的 shortcode  支持自定义脚本的 shortcode  支持基于 TypeIt 的打字动画 shortcode  支持基于 cookieconsent 的 Cookie 许可横幅  支持人物标签的 shortcode … ","date":"2019-08-02","objectID":"/about/:1:3","tags":null,"title":"关于 LoveIt","uri":"/about/"},{"categories":null,"content":"许可协议 LoveIt 根据 MIT 许可协议授权。 更多信息请查看 LICENSE 文件。 ","date":"2019-08-02","objectID":"/about/:2:0","tags":null,"title":"关于 LoveIt","uri":"/about/"},{"categories":null,"content":"特别感谢 LoveIt 主题中用到了以下项目，感谢它们的作者： normalize.css Font Awesome Simple Icons Animate.css autocomplete Lunr.js algoliasearch lazysizes object-fit-images Twemoji emoji-data lightGallery clipboard.js Sharer.js TypeIt $\\KaTeX$ mermaid ECharts Mapbox GL JS APlayer MetingJS Gitalk Valine cookieconsent ","date":"2019-08-02","objectID":"/about/:3:0","tags":null,"title":"关于 LoveIt","uri":"/about/"},{"categories":null,"content":"一直用position去得，后来发现代码输出跟属性上显示不一样，后来把ugui的源代码拿下来看了，才知道，要用anchoredPosition ","date":"2016-07-26","objectID":"/recttransform%E4%B8%AD%E7%9A%84%E5%9D%90%E6%A0%87/:0:0","tags":["unity3d","游戏开发"],"title":"RectTransform中的坐标","uri":"/recttransform%E4%B8%AD%E7%9A%84%E5%9D%90%E6%A0%87/"},{"categories":null,"content":"Silverlight中绑定自定义样式的ListBox,要注意以下几点 ItemTemplate 指定的属性可以单独放在一个资源文件中. 要绑定的对象,如一个ItemTestData,要从接口INotifyPropertyChanged继承,所使用到的绑定的set属性要调用NotifyPropertyChanged(“属性名称”); 如果要绑定数据到Item对象, 自定义的ItemTemplate 样式,要在其根LayoutRoot 中指定绑定名称. 假设其根是一个Grid,一个Item由2个TextBlock组成,分别要绑定到一个ItemTestData对象的 Data1和Data2上去, 那么,在Grid下首先要指定一个ItemTestData的别名 \u003cGrid.Resources\u003e \u003csrc:ItemTestData x:Key=\"itemTestData\"/\u003e \u003c/Grid.Resources\u003e 注意src是ItemTestData所在的命名空间,x:Key为指定一个别名 然后在TextBlock中就可以指定绑定的属性 \u003cGrid.Resources\u003e \u003csrc:ItemTestData x:Key=\"itemTestData\"/\u003e \u003c/Grid.Resources\u003e 注意src是ItemTestData所在的命名空间,x:Key为指定一个别名 然后在TextBlock中就可以指定绑定的属性 \u003cTextBlock x:Name=\"someData\" Text=\"{Binding Data1}\"/\u003e 最后,别忘了指定ListBox的ItemsSource到一个ItemTestData的集合上.\\\\ 如果在Item中要加入控件的事件,还要注意的就是资源不能放到全局的资源文件XAML中去了,事件处理需要cs文件 最后发现,WPF的绑定确实是方便又简单 ","date":"2010-11-07","objectID":"/listbox%E6%8E%A7%E5%88%B6%E6%A0%B7%E5%BC%8F%E8%87%AA%E5%AE%9A%E4%B9%89%E4%B8%8E%E7%BB%91%E5%AE%9A%E5%B0%8F%E8%AE%B0/:0:0","tags":[".NET","C#","绑定","ListBox","Silverlight","控件自定义","游戏开发"],"title":"ListBox控制样式自定义与绑定小记","uri":"/listbox%E6%8E%A7%E5%88%B6%E6%A0%B7%E5%BC%8F%E8%87%AA%E5%AE%9A%E4%B9%89%E4%B8%8E%E7%BB%91%E5%AE%9A%E5%B0%8F%E8%AE%B0/"},{"categories":null,"content":"在网上找到的,http://myapad.wordpress.com/author/xaueious/ 这个家伙,用爱可视的内核源代码编了一个cifs的RK2808可用模块 把这个下载下来,放在flash随便什么目录下面,假设是/flash/cifs.ko 然后在命令行执行 insmod /flash/cifs.ko 将模块挂载,之后就可以挂载网络共享了 mount –t cifs –o username=guest,iocharset=utf8 //192.168.0.3/movie /sdcard/movie username我指定的是guest用户,所以没有密码,如果有密码,还要加一个 password=somekey, //192.168.0.3/movie是WINDOWS共享的位置, /sdcard/movie 是本地挂载目录 注意一定要指定iocharset=utf8 不然中文就是乱码,OK,这比使用NFS还要方便,不用在台式机上装NFS服务器,也不会有乱码. cifs.ko我已经上传到群共享了. QQ群:83895562 ","date":"2010-10-27","objectID":"/%E7%9B%B4%E6%8E%A5%E4%BD%BF%E7%94%A8cifs-ko%E6%8C%82%E8%BD%BDwindows-%E5%85%B1%E4%BA%AB/:0:0","tags":["ANDROID","android 1.5 cifs smb WIDNOWS共享"],"title":"直接使用cifs.ko挂载WINDOWS 共享","uri":"/%E7%9B%B4%E6%8E%A5%E4%BD%BF%E7%94%A8cifs-ko%E6%8C%82%E8%BD%BDwindows-%E5%85%B1%E4%BA%AB/"},{"categories":null,"content":"参见:RK2808 System磁盘映像拿到root权限, 其他自作自定义固件的资料 瑞芯微RK28XX_安卓(android)系统固件包修改基础教程 很麻烦,搞了很多次,发现教程有,但是都不完全,差一步,就可能开不了ROOT. 准备工作: 刷机工具.下载地址:刷机工具 ROM,有很多版本,有原始的,有修改版的,我用的修改版的,从国外论坛上下载的hybrid 5.1 注意此ROM号称开了ROOT,实际上是没有的.可以加QQ群,里面的共享有:83895562 LINUX系统,没有LINUX系统就装个虚拟机啦,推荐VirtualBox,然后安装一个Ubuntu,就很方便了. 要安装cramfs工具,因为天杀的RK2808使用的就是这个系统,具体的请谷歌或者BING,简单的说就是一个压缩包,是只读的系统,因此必须要在刷机前对固件进行修改. 装update.img解开后,拷贝到UBUNTU下面.这里假设拷贝到了/home/zzz/rom/ 下面(注:zzz是你的登录用户名) 然后运行 cd /home/zzz/rom mkdir system sudo mount -t cramfs -o loop system.img system tar cvzf system.tgz system sudo umount system rm -r system tar xzvf system.tgz 这一步就是将IMG解压到一个system目录中,如果你用的是5.1的那个固件,里面已经有SU了,只需要改一下权限就可以了,如果没有,就去下载一个:[XDA的SUPERUSER](http://forum.xda-developers.com/showthread.php?t=682828) 然后将里面的system/bin/su 拷贝到刚才解开目录下面的system/bin/su, system/xbin/su 注意两个都要拷 system/app/Superuser.apk 也拷到对应目录下去,注意大小写. 然后运行 sudo chown root system/bin/su sudo chown root system/xbin/su sudo chmod 4577 system/bin/su sudo chmod 4577 system/xbin/su sudo chmod 644 system/app/Superuser.apk ``` 这一步就是给权限,我以前搞了N次失败了,就是差前面两句,一定要将此文件的所有权分配给root用户才行. 好了,上面完成后,就可以打包SYSTEM.IMG了 ``` mkcramfs system system.img ``` 将这个system.img拷贝到原来解开的Image目录去,然后用工具重新打包成udpate.img,刷机 安装一个BetterTerminal,就是一个终端工具,装好后在终端输入su回车,会有一个提示,选yes,然后终端上的提示符由$变为#就表明成功了,如果显示Permission denied就是没成功. 以下是开NFS网络硬盘所需要的工作,如果你不准备挂NFS,可以跳过 参见:[CIFS and NFS modules](http://www.slatedroid.com/nationite-midnite-firmware-development/8087-cifs-nfs-modules-3.html) [windows NFS 配置](http://ygliang.blog.51cto.com/69909/52898) 在共享的台式机上安装[Windows Services for UNIX Version 3.5](http://www.microsoft.com/downloads/en/details.aspx?FamilyID=896c9688-601b-44f1-81a4-02878ff11778),应该都是WINDOWS系统吧,只试过XP,WIN7没试过,应该差不多.如果是LINUX好像就可以直接开了 主要目的,就是因为1.5的ANDROID不支持CJFS格式,是内核不支持,咱又不会编内核(现在在学习中),不然就可以直接拷SMB共享(就是WINDOWS的共享啦)到本地目录,然后什么小说啊,电影啊,之类 的,就 不用从台式机上拷贝到平板,而可以直接通过共享,WIFI来随时访问了,直接播放电影什么的.可惜不支持CJFS格式,所以又有一种方式,搞了好半天才找到,就是用NFS格式,在国外的论坛上无意中看到的, 1.5的内核支持NFS 先下载[Windows Services for UNIX Version 3.5](http://www.microsoft.com/downloads/en/details.aspx?FamilyID=896c9688-601b-44f1-81a4-02878ff11778),然后按照上面的参考帖子配置共享,注意在本地安全策划中,有一项一定要打开,不然可以挂载,但是目录却是空的: 网络访问: 将 Everyone 权限应用于匿名用户 具体方法,运行gpedit.msc,在\"计算机配置-WINDOWS设置-安全设置-本地策略-安全选项\"下面. 然后在[CIFS and NFS modules](http://www.slatedroid.com/nationite-midnite-firmware-development/8087-cifs-nfs-modules-3.html)这个帖子中,有一个MountNfs.apk,下载安装,然后运行MOUNTNFS,在第一个对话框上填写地址,格式应该是: IP:/FOLDER\\_NAME,IP就是你的WINDOWS的IP,FOLDER\\_NAME就是在NFS共享上设置的名字(注意不是你硬盘上的目标名,而是属性里面NFS 共享的名字),注意不要掉了:号. 下面填写平板上的目录,自己先建一个空目录,如sdcard/movie,然后点MOUNT,如果提示MOUNT成功,就OK了,用ES文件管理器查看此目录,就可以看到共享了(如果没有,使用终端,然后切换到su,使用ls命令查看:ls /sdcard/movie 看看有没有,如果 有,很可能是WINDOWS的策略没改,我之前就是这样,MOUNT成功了,但是用文件管理器看不到,用超级用户用LS命令可以看到) 点击一个电影,就可以直接播放了,不用拷过来,注意WIFI要信号好才行,不然就会卡. 有一个问题还没解决,就是NFS不支持UTF8,所以中文是乱码,最好手动把文件名改成英文,哈哈 有什么问题可以到QQ群交流. 还有我的GOOGLE MAP无法定位自己的位置,在设置里面开了\"我的位置\"也没用,哪位知道 ","date":"2010-10-26","objectID":"/apad-rk2808-%E5%BC%80root%E6%9D%83%E9%99%90%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9%E6%8C%82nfs%E7%BD%91%E7%BB%9C%E7%A1%AC%E7%9B%98/:0:0","tags":["ANDROID","APAD RK2808 平板 ANDROID NFS ROOT权限"],"title":"APAD RK2808 开ROOT权限注意事项,挂NFS网络硬盘","uri":"/apad-rk2808-%E5%BC%80root%E6%9D%83%E9%99%90%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9%E6%8C%82nfs%E7%BD%91%E7%BB%9C%E7%A1%AC%E7%9B%98/"},{"categories":null,"content":" DSC04231 分区是重力使命，火星编年史，真名实姓。重力使用这本的书的封面，可是好早以前，科幻世界上某期的插图啊，当时就在想这样的飞机怎么飞，没引擎，难道是滑翔机?不知道跟小说有没有直接关系.传说这本书很硬.所以买了. 火星编年史,还有另一套\"火星三部曲\",什么红火星之类的,那一套看书评好像很难看懂,以至于所有的火星的书都不想看了,结果,看到豆瓣上的书评说这本还可以,就收了列,万恶的豆瓣。 真名实姓是肯定要的啦,上次收书搞掉了这本,这次不能忘,不然以后又没货了,哎,什么时候能收到\"天渊\"和\"深渊上的火啊\". 这几本是新华书店上买的,还有几本是卓越上的,估计这两天都会到.一本本看罗,看完了再写书评. 刚发完帖子，第二批就到罗： DSC04233 有文奇的短篇集，奇点天空，还有一本日本的科幻（日本的科幻就看过一个，日本沉没，不知道这个核弹头怎么样，哈哈）。最后是丹西蒙斯的极地恶灵，看了海伯利安后就期待他的大作了。 ","date":"2010-10-14","objectID":"/%E4%BB%8A%E5%B9%B4%E4%B8%8B%E5%8D%8A%E5%B9%B4%E7%AC%AC%E9%87%87%E8%B4%AD%E7%9A%84%E7%AC%AC%E4%B8%80%E6%B3%A2%E7%A7%91%E5%B9%BB%E4%B9%A6%E5%88%B0%E8%B4%A7/:0:0","tags":["读书"],"title":"今年下半年第采购的第一波科幻书到货","uri":"/%E4%BB%8A%E5%B9%B4%E4%B8%8B%E5%8D%8A%E5%B9%B4%E7%AC%AC%E9%87%87%E8%B4%AD%E7%9A%84%E7%AC%AC%E4%B8%80%E6%B3%A2%E7%A7%91%E5%B9%BB%E4%B9%A6%E5%88%B0%E8%B4%A7/"},{"categories":null,"content":"突然觉得,一个支持快速开发的引擎,除了有好的底层,方便的模板,还应该具体一套完善的开发工具, 这套工具中,包括了一些自动化生成代码的处理,就是VS里面自动生成MFC应用程序一样.省去咱们很多不必要的工作啊. 自动化生成工具真是谁用谁知道,以前做每个系统时,总有一些重复工作,而这些工作又不方便使用模板或者接口基类来实现,每次复制,粘贴,然后再修改,实在是很烦,突然有一天,一个同仁跟我说,可以用程序来生成这些代码啊.于是呼,我像吃了30年的饭才知道原来可以煮稀饭一样. 之后的过程,那便没有什么新意了,凡是可以自动生成的代码,全部自动生成,定义一个对象的字段,就自动生成数据库表的SQL语句,对应的服务器端的读存此数据对象的类及操作代码,与客户端通讯的消息类,客户端的消息定义,当然,这还没有完,未来还要加上客户端处理的代码等等,凡是可以自动生成的,基本不变的代码,全部自动生成.这样之后,发现写一个程序,再也不用纠结于这些琐碎的工作了,省出更多的时间和精力完成一个系统应该去花脑子去操心的事情. 回头一看,其实自动生成代码从接触编码开始就有了,TC里面的最简单的MAIN函数,VC6的APP生成工具,都是会自动生成一些代码,减少用户操作.现在觉得自己好笨,很没有观察力,明明一直发生在自己身边的事情,却不加以利用.这也许就是高人与凡人之间的区别吧啦. ","date":"2010-10-06","objectID":"/%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E4%BB%A3%E7%A0%81%E7%9A%84%E5%A5%BD%E5%A4%84-%E7%BA%AA%E5%BF%B5%E7%AC%AC%E4%B8%80%E4%B8%AA%E9%9B%86%E6%88%90%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90%E5%B7%A5%E4%BD%9Cd/:0:0","tags":["游戏开发"],"title":"自动生成代码的好处-纪念第一个集成代码生成工作DBCodeGen","uri":"/%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E4%BB%A3%E7%A0%81%E7%9A%84%E5%A5%BD%E5%A4%84-%E7%BA%AA%E5%BF%B5%E7%AC%AC%E4%B8%80%E4%B8%AA%E9%9B%86%E6%88%90%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90%E5%B7%A5%E4%BD%9Cd/"},{"categories":null,"content":" http://book.douban.com/review/3801851/ “实时放逐”明显是“为和平而战”的继集啦。 虽然方式不一样，实时很像是侦破小说，不过我觉得描述方式没有太大的区别。 文奇的小说，总是在前期要花很大篇幅展开环境背景，人物，线索等，因此，读文奇的小说，要至少读到一半，才会让人欲罢不能。“实时”，“为和平”都是这样的小说，还有原来曾经看过的“深渊上的火”也是如此，看到前面很没意思，前面一半我看了几天，看一点停一点，后一半完全是一口气看完的。后面才是真实的高潮。让人不想放下。 故事到最后也没有交待“大灭绝”的原因，到底是人类自己玩死了自己，还是外星人，或者跟陆黛拉想的一样，是升华了，很多小说有这种意思，比如刘大的“超新星纪元”，人类提升后，肉体就消失了。我想文奇会不会继续写下一部，讲的就是“大灭绝”的原因，更有可能不是讲述原来的“大灭绝”，而是讲述后来由陆黛拉等人建立起新社会的人类的第二次“大灭绝”，由此来推测第一次“大灭绝”的原因，如果真要写，我想文奇肯定会给我一个惊喜的，他的小说基本上我没有失望过，最后准备去把“天渊”，“深渊上的火”两本收购，结果没新的了，看看有没有二手的淘。 下个月的大作就是“三体”3了，当然还有COD7，哈哈，现在抓紧时间看别的。再收几本科幻哦。文奇的短篇上次没买，这次补上。 ","date":"2010-10-03","objectID":"/%E4%B9%A6%E8%AF%84%E5%AE%9E%E6%97%B6%E6%94%BE%E9%80%90/:0:0","tags":["科幻，弗诺文奇，终极人类，未来战争","读书"],"title":"书评：实时放逐","uri":"/%E4%B9%A6%E8%AF%84%E5%AE%9E%E6%97%B6%E6%94%BE%E9%80%90/"},{"categories":null,"content":"Abstract Factory 对一整套产品的统一创建。 也就是说，相当于一个模板，一个具体的工厂，创建一个系列的产品，这一系列的产品可能有着同一个风格，因此，将不同系列的产品分派到不同的工厂中去做。缺点就是这一系列的产品规划，是已经知道的，如果要加入新的产品到系列中，就需要扩展工厂，修改底层。这模式可以用来控制差异化，也就是说，我要在一个统一系列同，对某一个产品做特别修改，必需要重新生成一个新的工厂。 Builder 我个人觉得跟Abstract Factory很相似，之所以称为Builder，就是因为在他提供的接口中，并不是生成最基本的零件（这是Abstract Factory做的事情），而是生成零件后，还负责装配和组和（Abstract Factory不做组和），这样调用者，就不用关心是哪些零件组成的最终产品，而只需要找到能够生成最终产品的Builder就可以了，而通过派生Builder，就可以实现不同规格的零件，按不同的方式组合。说白了，Builder比Abstract Factory多一个装配过程，如果在底层中不能确定装配过程以及零件细节，就使用Builder，反之如果在底层就要限制装配过程及零件规格，就使用Abstract Factory。 Factory Method 跟Abstract Factory有点相似，但是Abstract Factory提供的是一整套零件，而Factory Method提供的是单个零件，当一个产品的装配方式及零件规格固定后，可以使用Factory Method，让派生类按零件规格生成自己需要的零件。 《设计模式》这书02年买的，老实说当时根本看不懂，翻了一下头大了就放边上了，做了这长时间后，翻出来看看，发现可以懂一点了。就拿这几种创建模式来说，放到现实工业生产上去，就好比一条流水线，在什么样的情况下，可以让这个流水线生成更多类型的产品。流水线上输入的是有规格的零件，输出的是最终产品。打个比方，Abstract Factory就是为这个流水线提供零件而存在的，而且，每个具体的工厂，提供的是一整套零件，但是他们的规格相同，可以适用于这套流水线，如果有规格不适应的零件出现，那么这个流水线是无法工作的。 而Factory Method是这样一种流水线，他的每一道工序及零件规格是固定的，如果要修改流水线，只用换零件就可以了，想换哪个零件，自己做主，只要在零件的规格范围内（重围工厂方法）。 Builder，就是一个自给自足的流水线了，使用这个流水线的人，不需要知道他是怎么工作的，他需要哪些零件，而只用知道他生产的最终产品是不是你所需要的就可以了。这样，流水线提供者，就可以重新定义零件和装配方式。 ","date":"2010-06-23","objectID":"/%E5%87%A0%E4%B8%AA%E5%88%9B%E5%BB%BA%E6%A8%A1%E5%BC%8F%E7%9A%84%E7%90%86%E8%A7%A3/:0:0","tags":["游戏开发"],"title":"几个创建模式的理解","uri":"/%E5%87%A0%E4%B8%AA%E5%88%9B%E5%BB%BA%E6%A8%A1%E5%BC%8F%E7%9A%84%E7%90%86%E8%A7%A3/"},{"categories":null,"content":"今天晕头了，居然把昨天做完的工作今天 又做了一次。 一个将领管理类，昨天写了个CHeroCenter,基本已经写完了，今天又写了个一个，叫CHeroTender,队了类名字不一样，其它的完全一样，函数，成员变量，连函数的参数都一样。在写解聘将领时，需要返回错误代码，准备让策划加到string.xml里，结果发现string.xml里已经有了，惊奇的我在代码中搜索，结果就发现了这一模一样的类，郁闷啊。 还好这个类不大。百把行代码。 ","date":"2010-05-18","objectID":"/%E6%99%95%E5%A4%B4%E4%BA%86%E5%81%9A%E4%BA%86%E6%AC%A1%E9%87%8D%E5%A4%8D%E5%B7%A5%E4%BD%9C/:0:0","tags":["游戏开发"],"title":"晕头了，做了次重复工作","uri":"/%E6%99%95%E5%A4%B4%E4%BA%86%E5%81%9A%E4%BA%86%E6%AC%A1%E9%87%8D%E5%A4%8D%E5%B7%A5%E4%BD%9C/"},{"categories":null,"content":"年后就收到全套原版书了，一直没机会看，本来想从第一部开始看起的，发现没有剧情的新鲜感，看英文的很难继续，所以决定直接从继集开始看了。 看了两天，才看了两张纸，一堆生单词。不过还好，不查字典，大概的情节还是可以猜出来，再查查字典，就到位了，但是要让我完全翻译成中文，估计还是没那个水平，现在只能说停留在“意会”这个初级阶段吧。 我的野心很大啊，如果这两本能够顺利看完，那以后就不用等中文译好的科幻书了，直接去蓝泉订最新的原版或者从网上下电子书看，那不是走在最前面啦？ 附书的封面，我很喜欢，原版书的封面看到就是舒服，国产的封面都是用电脑拼出来的，很没意思。 边上那个全身长毛刺的，就是著名的未来杀手“伯劳鸟“了，左边那个划船的和那个蓝皮人，不认识，右边那个小小的女人可能是被反老还童的“ Rachel ”，第二部完结的时候，好已经还童成婴儿了，就快死了，从封面上看，应该是后来活了，我还没看到这。 Endymion这部是以Endymion这个人的第一人称写的，故事发生在第二部247年以后。 人类和人工智能的生存到底如何，我将继续读下去。 ","date":"2010-05-17","objectID":"/%E5%BC%80%E5%A7%8B%E6%8B%9C%E8%AF%BB%E7%A7%91%E5%B9%BB%E5%A4%A7%E4%BD%9C%E6%B5%B7%E4%BC%AF%E5%88%A9%E5%AE%89-%E7%9A%84%E7%BB%A7%E9%9B%86endymion/:0:0","tags":["读书"],"title":"开始拜读科幻大作“海伯利安”    的继集“Endymion\"","uri":"/%E5%BC%80%E5%A7%8B%E6%8B%9C%E8%AF%BB%E7%A7%91%E5%B9%BB%E5%A4%A7%E4%BD%9C%E6%B5%B7%E4%BC%AF%E5%88%A9%E5%AE%89-%E7%9A%84%E7%BB%A7%E9%9B%86endymion/"},{"categories":null,"content":" 今天陪老婆看了一部电影，名叫“(500) Days of Summer”，男主角没见过，女主角是Yes Man中的女主角，佐伊・丹斯切尔，很有点当年美国甜心 梅格•瑞安的感觉。她在这部片子里也是一样，古怪精灵。 片子的情节也不俗，结局不是大团员，但是也不是什么悲剧，就像生活一样，一段感情痛苦的结束，这个结束，却是一个新的开始。 最让人难忘的是电影原声。不同的情节，响起不同的音乐，配合得很好，节奏体现了剧情的发展。我个人最喜欢听的是一首Kevin Michael 的 At Last (Bonus Track) , 很蓝调，很爵士，果然爵士乐还是我的最爱。 http://www.xiami.com/widget/857636_1769359034/singlePlayer.swf ","date":"2010-05-16","objectID":"/%E5%92%8C%E8%8E%8E%E8%8E%AB%E7%9A%84500%E5%A4%A9-500-days-of-summer/:0:0","tags":["电影"],"title":"和莎莫的500天 (500) Days of Summer","uri":"/%E5%92%8C%E8%8E%8E%E8%8E%AB%E7%9A%84500%E5%A4%A9-500-days-of-summer/"},{"categories":null,"content":"今天陪老婆去吃了DQ，然后去陪吃味千拉面的时候喝了点冰柠檬水，结果回来就直冲去蹲点，当然没有忘记拿本杂志，家里一堆过刊，随手拿了本“第一财经周刊”，也不知道是什么时候的了，翻了下，搞IT的，当然是对IT最感兴趣，一篇关于谷歌WAVE的报道第一个就看起来。 以前总听过，今天一看才知道WAVE是个什么，原来就是把聊天和邮件结合起来的东东，心想谷歌总有新东西，但是细细一想，这玩艺儿，MSN几百年前就有了，直接跟联系人聊天，又可以向联系人发邮件，后来的QQ也有啊。这算什么新东西，不过WAVE还在内测，所以到底怎么样还要等用过才知道。但是这一想，我又想到了微软和谷歌的竞争，这两公司文化可以说完全不同，软件或者说互联网，我看就是这两家公司竞争了。微软也推出了WAVE，微软还真是没有创新力啊，除了搞了个DOS，好像别的都是等小公司创新，快成气候了，就一把收购过来，微软就这样一步步做大。这方法对于那个年代，软件公司都还没有行成这大市场的时候有用，但是现在，面对新市场互联网和强力对手谷歌，这招可用不上了。微软所有的行动都在争对谷歌，搜索引擎，聊天工具等，而谷歌好像从来不把微软当作对手。 他们之间的竞争谁会赢呢，有时我会想，当然我希望是微软，因为我的事业跟他靠得比较紧吗，哈哈！但是其它我并不看好微软，为什么呢，虽然微软在操作系统上现在无人能敌（WIN7真是太牛比了，用了就不想放弃，曾经因为玩实况2010有点卡一气之下换回XP，过了个年，又想WIN7了，哈哈，装了个双系统,我想有很多人跟我一样吧），但是，也只是这个领域了，微软的缺少创新精神，看看WINDOWS MOBILE吧，从CE，2003到6.0，根本没变化，除了主页变了变，后台的界面完全没有多少改变，本来在智能手机市场很看好他的，结果现在呢，谷歌的ANDROID一下子后来居上。别人界面就是好看。 谷歌更强调实际的用户体验，而微软只是口头上这样做。还好，只有竞争才有发展，微软推出了WINDOW PHONE 7，爽，虽然还没有正式上式，但是看演示就让我蛮爽了。毕竟，微软平台下，.NET,C++都是可靠和高效的编程工具，而其它平台，则更喜欢用JAVA。 但是即使是这样，我觉得微软还是在走下坡路，为什么我总这样想，实际上在互联网这一块，几大公司相争，实际上就是企业文化的竞争，说得再白一点，就是人才竞争。谁的企业文化更能吸引新兴人才，谁就能笑到最后，放眼世界，或者放眼历史，哪个国家不是因为人才而强大？看看微软的企业文化吧，听说微软内部都不让员工使用IPHONE，虽然我不觉得IPHONE好，但是没必要禁止员工使用啊，逼近搞IT的小伙子都喜欢新东西，喜欢怪东西的人都有，那喜欢大众都喜欢的IPHONE也不奇怪了。 别说WM不怎么样，就算你WM牛比，也不能这样罗，越是这样，越是有反抗，说不定未来打败微软的人，就出自微软自己的这样被压制的员工哦（历史上这样的例子不少啊）。反观谷歌更开放，这样就更容易吸引人才。IT企业跳槽的风险可比古代打仗倒戈的风险小多啦（不用担心家小被报复哈哈）。如果微软一直这样以老大自居，极有可能被谷歌这样有开放文化，有创新精神的企业击败。微软赚程序员的钱，谷歌却让程序和他一起赚钱（可惜咱不会JAVA，也不准备学JAVA，不然那是一件多么美妙的事情啊）。 看看微软谷歌的竞争，再看看自己身边的这些公司，虽然不能跟谷歌微软比大小，但是就现在的情况来说，那不是差一点点，这样的公司，所谓的文化，就是要你加班加点把有一堆张牙列嘴向用户抢钱功能的产品做出来，然后过把瘾就死，这样的企业，没有远见，只顾眼前利益，最终只会导致人才流失，而消失在竞争的环境中。 ","date":"2010-05-09","objectID":"/%E7%94%B1%E8%B0%B7%E6%AD%8Cwave%E8%81%94%E6%83%B3%E5%88%B0%E7%9A%84it%E4%BC%81%E4%B8%9A%E7%AB%9E%E4%BA%89/:0:0","tags":["瞎想"],"title":"由谷歌WAVE联想到的IT企业竞争","uri":"/%E7%94%B1%E8%B0%B7%E6%AD%8Cwave%E8%81%94%E6%83%B3%E5%88%B0%E7%9A%84it%E4%BC%81%E4%B8%9A%E7%AB%9E%E4%BA%89/"},{"categories":null,"content":"底层函数可以继续使用原来的方式，就是直接写字符串。由其它输出日志函数调用。 再写一个参数为XMLNODE的代理函数，此函数接受其它全部上层写日志函数的调用，上层函数将其日志格式全部统一，将信息放入XMLNODE中，然后由此代理调用底层函数写日志。 上层函数，最常用的日志输出有以下几种：直接输出文本（LOGERROR），断言ASSERT，异常CATCH。将这三种独立成三个函数或者宏，实际操作，如LOGERROR生成一个XMLNODE，将日志类型，时间，字符串，等信息写入XMLNODE的属性，然后调用代理函数。 再讲到每个功能块的日志，如物品流失日志，就需要单独写个上层日志函数，将信息格式化成XMLNODE交给代理函数写入。 再谈到服务器日志输出容器，就可以根据不同类型的日志进行过滤显示，以及颜色区分，可以将异常日志标为红色以作警示等。 最后说明一下日志查看器，之所以要做成XML格式的日志，就是方便使用日志查看器，需要说明的是，每加一种新的日志类型，除了要编写加入日志的上层函数外，还要在日志查看器上编写日志解析代码。 ","date":"2010-03-15","objectID":"/%E6%A0%BC%E5%BC%8F%E5%8C%96%E6%97%A5%E5%BF%97%E8%BE%93%E5%87%BA%E5%85%B7%E4%BD%93%E6%96%B9%E5%BC%8F/:0:0","tags":["游戏开发"],"title":"格式化日志输出具体方式","uri":"/%E6%A0%BC%E5%BC%8F%E5%8C%96%E6%97%A5%E5%BF%97%E8%BE%93%E5%87%BA%E5%85%B7%E4%BD%93%E6%96%B9%E5%BC%8F/"},{"categories":null,"content":"以往的几个系统都是使用一种比较随意的日志输出方式，就是有什么问题就输出，超时日志，错误日志，ASSERT，异常等全部在一个文件中，这样不方便查看，也不方便于对于紧急事件的反应；也无法控制输出级别，有些输出可能只在DEBUG版本或者第一个RELEASE版本才需要，当版本稳定后，就不需要这些日志了，日志级别应该全部是可以控制的。分两部分来谈这个问题： 1.可控级别：可控级别分在两个部位控制，第一个是编译级别，在编译级别中通过预编译参数或者宏来实现最高可输出级别，别一种是动态控制，使用参数来控制级别，只在小于参数值的级别才可以输出。编译级别的参数值优先级应该大于动态级别的，这样就可以方便显示控制日志输出量。 2.格式化输出：以往的日志很随意，无法格式化输出，关于格式化输出，以前我有过一次尝试，在新的系统中使用格式化输出，如“贵重物品流向”日志，这种日志使用空格分割字段，这样可以使用工具方便的读取日志，进行过滤，查询操作，速度也比较快。缺点是日志格式单一，且非常严格，只能适用于有共性的系统。还有一种格式化方式是使用XML格式，这样不同类型的日志可以用不同的标志来区别，各自也可以有自己的属性，对于工具来说，也可以方便的查阅，最大的问题就是文件大小，会成倍增加日志输出的字节数量。最后一种方式是通过分成不同的文件来存放，这样会生成多种文件，而且不好使用工具来查阅。 我个人比较偏向于使用XML，虽然日志过大，但是管理方便，使用工具很容易查询。但是有很多底层日志不是使用的这种方式，我要评估一下这样的改支有多大。 另一个现在无法解决的问题就是”重复日志”，如果有一个错误，而且这个错误会在每次心跳时记录，那么这个日志就会很多，很浪费空间，日志常常几百M，现在还没有找到办法解决。 ","date":"2010-03-12","objectID":"/%E6%96%B0%E6%97%A5%E5%BF%97%E5%87%BD%E6%95%B0%E6%A0%BC%E5%BC%8F%E5%8C%96%E5%8F%AF%E6%8E%A7%E7%BA%A7%E5%88%AB%E6%97%A5%E5%BF%97%E8%BE%93%E5%87%BA/:0:0","tags":["游戏开发"],"title":"新日志函数:格式化可控级别日志输出","uri":"/%E6%96%B0%E6%97%A5%E5%BF%97%E5%87%BD%E6%95%B0%E6%A0%BC%E5%BC%8F%E5%8C%96%E5%8F%AF%E6%8E%A7%E7%BA%A7%E5%88%AB%E6%97%A5%E5%BF%97%E8%BE%93%E5%87%BA/"},{"categories":null,"content":"士兵突击有一次出现故障，就是因为同步服务把时间同步回去了，这样就造成当前时间可能会比内存中已经发现的事件的时间更早，一相减，是一个负数，因为我们使用的是DWORD，所以就变成一个很大的数目，造成数据异常。 解决办法：首先最好关掉服务器上的时间同步服务，然后对DWORD差值做检查，如果是负的，就不做操作，我认为使用DWORD要谨慎，在这上面出的问题不止一次了！ ","date":"2010-03-12","objectID":"/%E5%85%B3%E4%BA%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%87%AA%E5%8A%A8%E5%90%8C%E6%AD%A5%E6%97%B6%E9%97%B4%E6%9C%8D%E5%8A%A1%E5%BC%95%E8%B5%B7%E7%9A%84%E9%97%AE%E9%A2%98/:0:0","tags":["游戏开发"],"title":"关于服务器自动同步时间服务引起的问题","uri":"/%E5%85%B3%E4%BA%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%87%AA%E5%8A%A8%E5%90%8C%E6%AD%A5%E6%97%B6%E9%97%B4%E6%9C%8D%E5%8A%A1%E5%BC%95%E8%B5%B7%E7%9A%84%E9%97%AE%E9%A2%98/"},{"categories":null,"content":"使用优先队列，元素为指针，如： typedef priority_queue\u003cTimeEvent*, deque \u003cTimeEvent*\u003e, less\u003cdeque\u003cTimeEvent*\u003e::value_type\u003e TIME_EVENT_QUEUE; 这样比较的话，其结果是比较指针值，如果我要比较TimeEvent中的某个成员，就不行了，经过谷歌，可以采取一个方式，将less替换成一个结构的函数： struct TimeEventLessComp { bool operator () (TimeEvent*\u0026 a, TimeEvent*\u0026 b) const { return a-\u003edwTick \u003e b-\u003edwTick; }; }; 然后申明时改为： typedef priority_queue\u003cTimeEvent*, deque \u003cTimeEvent*\u003e, TimeEventLessComp\u003e TIME_EVENT_QUEUE; ","date":"2010-03-12","objectID":"/%E5%85%B3%E4%BA%8E%E4%BC%98%E5%85%88%E9%98%9F%E5%88%97%E5%AE%B9%E5%99%A8%E4%B8%AD%E5%85%83%E7%B4%A0%E4%B8%BA%E6%8C%87%E9%92%88%E7%9A%84%E6%83%85%E5%86%B5/:0:0","tags":["游戏开发"],"title":"关于优先队列容器中元素为指针的情况","uri":"/%E5%85%B3%E4%BA%8E%E4%BC%98%E5%85%88%E9%98%9F%E5%88%97%E5%AE%B9%E5%99%A8%E4%B8%AD%E5%85%83%E7%B4%A0%E4%B8%BA%E6%8C%87%E9%92%88%E7%9A%84%E6%83%85%E5%86%B5/"},{"categories":null,"content":"经过简单测试，生成500000个计时器，将指针分别插入list和priority_queue，其中priority_queue使用vector容器(不能使用list),先使用list自的sort函数，用时516ms,反复测了几次，都在500ms以上550ms以下 ,对priority_queue进行插入，在500000个的基础上，进行100000次插入，总用时31ms，平均每个0.00031ms 输出结果如下： list sort time:516 ms priority_queue push 100000 event use 31 ms time, average 0.000310 ms per event sorted list sort time:516 ms sorted list trace 0 sorted list trace 1 …. priority_queue trace 0 priority_queue trace 1 …. 经过测试，优先队列明显性能高于LIST的自排序，很适合我的要求！ ","date":"2010-03-12","objectID":"/%E5%85%B3%E4%BA%8E%E6%97%B6%E9%97%B4%E6%9C%8D%E5%8A%A1%E7%9A%84%E6%B5%8B%E8%AF%95%E7%BB%93%E6%9E%9C/:0:0","tags":["游戏开发"],"title":"关于时间服务的测试结果","uri":"/%E5%85%B3%E4%BA%8E%E6%97%B6%E9%97%B4%E6%9C%8D%E5%8A%A1%E7%9A%84%E6%B5%8B%E8%AF%95%E7%BB%93%E6%9E%9C/"},{"categories":null,"content":"使用一个单向或者双向链表，或者使用一个优先队列（priority_queue）. 队列中的元素为一个计时器对象。计时器对象包括，从标准时间（程序运行时）开始的时间差。越晚触发的计时器，这个值越大，及触发器事件类型。 如果只使用链表，每次插入后，就要进行一次重排，如果使用优先队列，自动插入顺序位置，我想使用优先队列应该效果好些，还要实验。 每次心跳（服务器线程循环），调用时间服务OnTicker函数，此函数检查队列中最前一个计时器的时间值，如果到达或者超过当前时间的时间差，就将此计时器取出，然后调用其触发器事件。 现在，有二个问题还未解答： 1.时间差值的精确程度,精确到什么程度？最好的情况是精确到微秒，那样，时间服务中的队列可能就会到几十万，这样对插入会有多大的影响，需要具体测试。 2.关于时间差的问题，以什么方式设置？目前使用的TICK是DWORD，32位，42亿多毫秒，换成天数是是49.71天，如果时间差直接放系统TICK+触发事件需要的时间，那么很可能会溢出。如果以程序运行时间为0点，且此时间点的系统TICK为SYSTEM_TICK，以此为参照，新加入的事件的时间值EVENT_TICK为： EVENT_TICK = NOW_TICK(当前系统TICK) - SYSTEM_TICK+NEED_TIME（需要的时间），也就是说存放时有一个换算过程。这样最多可以存放离程序运行49天内的触发器。还没有考虑好 ","date":"2010-03-11","objectID":"/%E6%97%B6%E9%97%B4%E6%9C%8D%E5%8A%A1%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F/:0:0","tags":["游戏开发"],"title":"时间服务实现方式","uri":"/%E6%97%B6%E9%97%B4%E6%9C%8D%E5%8A%A1%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F/"},{"categories":null,"content":"昨天发现登录时,任务初始化读取数据库操作频繁问题，今天为了找出其它数据库操作频繁问题，加入数据库操作计数变量，如果在登录或者运行某些计算时操作过于频繁，就再输出数据库操作日志，找出原因。 任务的初始化方式换了，但是现在的问题是自动激活使用WEBSERVICE，速度太慢了，不算数据库查询时间，光调用WEB服务函数的时间就去了125MS，太慢了，必需做一个中间服务器。 ","date":"2009-07-15","objectID":"/%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95%E7%AC%94%E8%AE%B0-2/:0:0","tags":["游戏开发"],"title":"压力测试笔记 2","uri":"/%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95%E7%AC%94%E8%AE%B0-2/"},{"categories":null,"content":"10055错误,压力测试客户端开了1000个连接,就报10055错误,查了发现是资源不足,后来想想,应该是连得太快了,服务器响应不过来,所以客户端的缓冲满了.调多点线程,或者发送每个连接的之间停一下. 后来发现,每个连接之间停一下没有用,只有加线程有用. ","date":"2009-07-14","objectID":"/windows-socket-%E7%AC%94%E8%AE%B0/:0:0","tags":["游戏开发"],"title":"windows socket 笔记","uri":"/windows-socket-%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":" 当时看这部片子的时候,本人正在外地出长差,虽然不说事业正劲,但是至少也没想过要回武汉。 片子是在一个普通的工作日，下班之后，没地方去，一个人在办公室看完的，虽然只有不到两小时，但是我仿佛跟着主角杰克一起过了相当长的一段时间，在这段时间里，杰克经历了一个虚幻的过程，从一个什么都有，又什么都没有的钻石王老五，脱变成一个家庭至上的居家男人。 应该说，本片的故事情节是极其荒谬，根本就不可能发生，但是我，却相信，如果杰克在电影开场，做出的和他的女友在一起的选择，也许就会生活就会向着那个虚构的情节发展。 一个人的选择约定了他的命运，当杰克放弃女友之后，他从此平步青云，在华尔街的高层办公室上，有自己的一席领地，每天有不同的女人投怀送抱，自己宽大卧室的衣柜里，有无数名牌服饰给他选择，好像他自己就是开服装店的，影片有一个长镜头，杰克边洗澡，边哼着帕瓦罗蒂的调子，打开超豪华的衣柜，随便挑选一样精制的衣服，然后站在镜子前，我的天，当时我就在想，也许这就是我想要的生活，不，这就是所有中国人想要的生活。 如果本片讲的是一个钻石王老五的生活，那么也许第二天我就会忘了这故事，同时还会降低凯奇在我心中的地位。 实际上，凯奇没有让我失望，好戏在后面：在圣诞节前夜,凯奇一个人在一个小超市里(钻石王老五可没什么家人),遇到一个被误认为是自己伪造彩票,所以持枪抢劫的黑人,杰克为了避免麻烦,用自己的钱摆本了这个黑人,这个黑人为了给了他一个铃铛,并说了一通让杰克摸不着头脑的话,杰克回到家后,将铃铛放床上,然后就睡着了. 故事到这里,引来了新的情节,而且绝对是我没有想到的,第二天早上,他被自己的女儿和狗吵醒了,奇怪,他不是钻石王老五吗?影片现在将杰克带到了他未与女友分离,并从此安居乐业的生活中去了. 如果一个人的人生在一天之内发生天翻地覆的改变,他肯定抓狂,如果他又一个什么都不缺少的钻石王老五,变成一个居家男人,每天被孩子烦,时时刻刻为钱烦,他会怎么样? 杰克崩溃啦.以前所有的一切全部不属于他了,他的公寓,跑车,地位,女人,所以的都没了,换来的,是天天闹人的孩子,不停在他旁边唠叨的老婆,还有每天无聊的汽车车胎销售工作. 于是杰克开始想办法了,他找到了那个黑人,黑人取代了杰克的地位,告诉他,当铃铛再次想起时,杰克就会回到过去的生活. 后面的故事我就不想说了,大家自己去看电影,反正结束也是很有意思的. 看完这个片子,我很久不能平静,有太多东西值得我去思考了,什么样的生活才是我要的,是我追求的,高品质的物质生活,所有的人都想要,但是如果为此付出的代价是精神上的孤立和贫穷,你如何选择? 也许大部分的人都像杰克变成普通人后那样,繁琐,无聊,无奈,时时刻刻幻想自己飞黄腾达,却没有人想过,如果过上那样的生活,自己可能会付出什么样的代价? 我们愿意为了钱,而放弃家庭,放弃那些关心你的人吗,在中国这个为钱至上的社会,到底什么最重要?什么才是自己的选择 ","date":"2008-10-25","objectID":"/%E5%B0%BC%E5%8F%A4%E6%8B%89%E6%96%AF%E5%87%AF%E5%A5%87-%E5%B1%85%E5%AE%B6%E7%94%B7%E4%BA%BA-the-family-man/:0:0","tags":["电影"],"title":"尼古拉斯凯奇 居家男人 The Family Man","uri":"/%E5%B0%BC%E5%8F%A4%E6%8B%89%E6%96%AF%E5%87%AF%E5%A5%87-%E5%B1%85%E5%AE%B6%E7%94%B7%E4%BA%BA-the-family-man/"},{"categories":null,"content":" 以前总是下载APE,自己克碟子,这次不同了,偶然的机会听到了一首\"海上花\",于是毫不犹豫的买了一张! 歌手玛丽亚,说实话,以前听都没听过这名字,将这首歌演艺得出神入话,个人觉得非常到位.那种低调的气氛,一点点忧郁,平淡中的激情,也许正是生活在一个平淡的世界中,一种自我陶醉的感觉,陶醉什么呢?听了歌就可以发现,其实任何点滴的事情,只要细细的品味,总可以找出一丝乐趣. 听这首歌,最好是一个人,在一个傍晚,关上灯,外面下着小雨,雨滴轻轻从窗上顺着玻璃向下串,自己就懒懒地躺沙发上,旁边放一杯红酒,偶尔品上一口,嗯…..~~~~,不知道什么时候有这种机会.有时间,有地点…. 试用地址:http://url2.51wma.com/uuauth/2/6507/228672.wma ","date":"2008-10-18","objectID":"/cd-%E8%82%A5%E5%A6%88%E6%AD%A3%E4%BC%A0/:0:0","tags":["唱片"],"title":"CD 肥妈正传","uri":"/cd-%E8%82%A5%E5%A6%88%E6%AD%A3%E4%BC%A0/"},{"categories":null,"content":"摘之:Advanced.Animation.with.DirectX Here’s where using key frames comes in handy. Suppose you want to calculate the orientation of the bones at a specific timesay, at 648 milliseconds. That time just so happens to fall between the second and third keys (148 milliseconds past the second key). Now, assume that the two transformation matrices represent the orientations of each bone in the animation. D3DXMATRIX matKey1, matKey2; By taking each key and interpolating the values between them, you can come up with a transformation to use at any time between the keys. In this example, at 648 milliseconds in the animation, you can interpolate the transformations as follows: // Get the difference in the matrices D3DXMATRIX matTransformation = matKey2 − MatKey1; // 请坐标位移 // Get keys’ times float Key1Time = 500.0f; float Key2Time = 1200.0f; // Get the time difference of the keys float TimeDiff = Key2Time − Key1Time; // 算出时间差 // Get the scalar from animation time and time difference float Scalar = (648.0f − Key1Time) / TimeDiff; // 当前帧在两关键帧中间的比值 // Calculate the interpolated transformation matrix matTransformation *= Scalar; // 算出当前帧的相对变换矩阵 matTransformation += matKey1; // 算出最终的当前帧的变换矩阵 ","date":"2008-10-09","objectID":"/%E6%96%87%E6%91%98%E9%AA%A8%E9%AA%BC%E5%8A%A8%E7%94%BB%E4%B8%AD%E7%9A%84%E5%9D%90%E6%A0%87%E6%8F%92%E5%80%BC/:0:0","tags":["游戏开发"],"title":"文摘:骨骼动画中的坐标插值","uri":"/%E6%96%87%E6%91%98%E9%AA%A8%E9%AA%BC%E5%8A%A8%E7%94%BB%E4%B8%AD%E7%9A%84%E5%9D%90%E6%A0%87%E6%8F%92%E5%80%BC/"},{"categories":null,"content":"昨天在新华路换527时被偷了,哎,分期才付了1期,还有23期,哎! 都怪太困了,一心想到上车抢位置,前面那个人那明显是为后面的人挡着的,我还一心想挤过去! 以后上车再不能迷糊了,找到位置再睡! 腰包也不用了. 用双肩包. 马的,白天兄弟的钱包被偷,我还特别提醒自己要小心啊. 同是天涯沦落人哦. 就当破财挡灾吧! 我的D600啊,用得HI爽啊,老婆给我的生日礼物啊!哎! 血的教训啊! ","date":"2008-09-03","objectID":"/%E6%88%91%E7%9A%84%E5%A4%9A%E6%99%AE%E8%BE%BE%E6%89%8B%E6%9C%BA%E8%A2%AB%E5%81%B7%E4%BA%86%E9%83%81%E9%97%B7/:0:0","tags":["生活在武汉"],"title":"我的多普达手机被偷了,郁闷~!","uri":"/%E6%88%91%E7%9A%84%E5%A4%9A%E6%99%AE%E8%BE%BE%E6%89%8B%E6%9C%BA%E8%A2%AB%E5%81%B7%E4%BA%86%E9%83%81%E9%97%B7/"},{"categories":null,"content":"昨天同事告诉我一个不幸的消息,常青路要封路啦,一封就是52天,那边80W人,全部会从我每天经过的姑嫂树路经过. 晕死哦,本来每天从汉口到武昌上班都快2个小时了,现在一搞,哎! 果不其然,昨天8点多才到家,那个堵啊,真不知道中国作为一个发展中国家,怎么那么多车! 今天上网看新闻,记者说:3公里走了40分钟,原文地址:http://hb.qq.com/a/20080806/000042.htm 居然还有交警说这几条路平时的流量就已接近饱和，昨天的堵车尚属可以接受的范围。 哎,无语啊,中国人也是麻木啊! 据介绍，为配合此次交通管制措施，交管部门动用了200多名警力指挥交通，在沿途还设置了100多个分流岗和220块指路牌，有效缓解了管制区域的压力。 警察是有的,可就是没看到有200个,20个看有没有! 记者在现场了解到，仍有不少驾驶员不知道这里封闭施工，有的驾驶员看见公交、的士可以走，就“装胡涂”闯了进去。一名交警介绍，为避免在路口拦截形成堵塞，因此，在两侧翼道通行还比较正常的情况下，就没有强行拦截，但这不等于禁行区内没有电子警察摄像，擅自闯入的车辆将面临处罚。 处理交通问题能力就不谈了,罚款收钱那都是一流的! 武汉市交管局和施工单位中铁十一局集团解释，全封闭的方案是反复权衡后制定的：施工方前后制定了3个方案，分别需要半封、全封、半封，工期分别需要104天、52天、192天。如果半封闭，则本已很大的流量全部压到半幅路面，通行状况势必更加恶化，加之施工工期延长，不是上策。全封闭的方案所需工期最短，考虑到“长痛不如短痛”，因此决定采用第二种方案 可怜那些开车的,什么这税那税没少交,桥1年能有365/2天可以过,现在路也不能走了,只能去挤… 今天早上上班,提前了20分钟出门,本以为会早到,到处堵啊,石桥,唐家墩,北湖,航空路,长江大桥,阅马场,傅家坡…地铁啊,什么时候可以修好呢 ","date":"2008-08-06","objectID":"/%E6%AD%A6%E6%B1%89%E7%9A%84%E4%BA%A4%E9%80%9A%E5%B7%B2%E7%BB%8F%E6%88%90%E4%B8%BA%E5%9F%8E%E5%B8%82%E5%8F%91%E5%B1%95%E7%9A%84%E7%93%B6%E9%A2%88/:0:0","tags":["生活在武汉"],"title":"武汉的交通,已经成为城市发展的瓶颈!","uri":"/%E6%AD%A6%E6%B1%89%E7%9A%84%E4%BA%A4%E9%80%9A%E5%B7%B2%E7%BB%8F%E6%88%90%E4%B8%BA%E5%9F%8E%E5%B8%82%E5%8F%91%E5%B1%95%E7%9A%84%E7%93%B6%E9%A2%88/"},{"categories":null,"content":"每天怪事不断,编辑器快做完了,发现TinyXml的保存居然没有可以选择编码格式的!搞得我们读的时候用的UTF8,结果保存就用了ANSI,现在解决办法还在查找中! ","date":"2008-07-22","objectID":"/tinyxml%E7%9A%84%E4%BF%9D%E5%AD%98%E7%BC%96%E7%A0%81%E9%97%AE%E9%A2%98/:0:0","tags":["游戏开发"],"title":"TinyXml的保存编码问题","uri":"/tinyxml%E7%9A%84%E4%BF%9D%E5%AD%98%E7%BC%96%E7%A0%81%E9%97%AE%E9%A2%98/"},{"categories":null,"content":"时代的步伐越来越快,如果不在而立之前赶上这股快车,恐怕以后就更没有机会了! 我宣布正式开篇! ","date":"2008-07-18","objectID":"/%E5%BC%80%E5%A4%A9%E7%AC%AC%E4%B8%80%E7%AF%87/:0:0","tags":["默认分类"],"title":"开天第一篇!","uri":"/%E5%BC%80%E5%A4%A9%E7%AC%AC%E4%B8%80%E7%AF%87/"},{"categories":null,"content":"今天BOSS说DEMO有点卡,一看发现是垂直同步的问题!于是乎在HGE的参数上加上了垂直同步的属性,谁知不行,一查资料,发现D3D8 只有在全屏下才能实现垂直同步,万能的微软啊,你不是成心整我们吗? 查了点资料,这种不同步,术语叫:Image Tearing, 大概的意思就是显卡发送到显示器的数据是按行来的,而不是一次传一屏,所以当显卡发送到一个屏的一部分时,这时候放显存里写数据,就会导致图像错位! 原文地址:www.virtualdub.org/blog/pivot/entry.php 解决方法,找了一下午,也没找到用D3D8可以解决的,我还试着使用: GetRasterStatus 来取当前是否已经发送完成,也不行!看来只有换D3D9了! 终于,换成了DX9,冒似好了,结果到了下午,工作了一天,把程序打开一看,居然又开始图像错位了,后来发现,可能的原因是由于在窗口模式下面DX不是独占的,会被GID抢资源,如果程序开多了,而显卡不好的话(我是INTEL集成显卡)可能就会卡,这也只是猜测,还没找到具体原因! 换成DX9后,TEARING问题是解决了,但是又随之而来了新问题,DX9相对于DX8又做了很多改动,原来的程序里面有一套机制,是基于DX8的,将一系列的纹理ALPHA渲染到一个渲染表面中去,然后再将这个渲染表面的纹理渲染到主场景中去.因为HGE使用的DX8,使用D3DXCreateTexture在D3DPOOL_DEFAULT(显存,DX8 DOC原文:This is usually video memory, including both local video memory and AGP memory)创建了一个D3DUSAGE_RENDERTARGET类型的纹理,因此不能直接锁取出地址来拷贝,所以要先调用CreateImageSurface在D3DPOOL_SYSTEMMEM(系统内存,Consumes system RAM but does not reduce pageable RAM.)创建一个图像表面,调用CopyRects将显存中的表面拷贝到内存中的图像表面中去,然后LockRect锁定内存中的图像表面,将其数据流拷贝到新的纹理中去! 上面是DX8的方法,然而到了DX9,都全了,首先,没有CopyRects了,CreateImageSurface没有了,经过不断的调试,试验,最后使用CreateOffscreenPlainSurface在D3DPOOL_SYSTEMMEM中创建替代CreateImageSurface,使用GetRenderTargetData将显存中的表面拷贝到内存中的表面去! 这个过程中,发现在DX9中同DX8的CopyRects函数有关的几个函数: 函数 源表面位置 目标表面位置 GetRenderTargetData POOL_DEFAULT D3DPOOL_SYSTEMMEM UpdateSurface D3DPOOL_SYSTEMMEM D3DPOOL_DEFAULT 最后说一下,微软的DX接口老在变,很不爽,可能是不习惯吧!就连DX9的不同版本都在变! ","date":"2008-07-18","objectID":"/d3d8-%E7%AA%97%E5%8F%A3%E6%A8%A1%E5%BC%8F%E5%9E%82%E7%9B%B4%E5%90%8C%E6%AD%A5-fighting-tearing/:0:0","tags":["游戏开发"],"title":"D3D8 窗口模式垂直同步! Fighting Tearing!","uri":"/d3d8-%E7%AA%97%E5%8F%A3%E6%A8%A1%E5%BC%8F%E5%9E%82%E7%9B%B4%E5%90%8C%E6%AD%A5-fighting-tearing/"},{"categories":null,"content":"马上要封测了,现在开始压力测试. 1000个连接上,没有问题,但是登录后问题来了,处理一个登录要1秒钟时间,可想而知1000个需要多长时间. 这是肯定不行. 于是加入测试语句,查找是谁在拖时间. 最后找到是登录时初始化玩家的任务,才发现有900多个任务,每个任务又有小任务,而且小任务不管数据库有没有记录,都要去数据库中SELECT 一次.难怪,明天找人改过来,已经完成和还没有开始的任务就不需要读了.应该会快很多. 又发现写日志问题,在每次TICK调用的函数中,如果有CHECK之类的日志出错,会不停的写,导致服务器没有响应,除了关掉日志写硬盘外,几乎没有别的办法.在介面线程显示时,取日志消息时,每取一个,要加一个判断,看是否超出此次TICK可能使用的时间,如果超出,还未处理的TICK就下次再处理,这样介面就不会死掉了. ","date":"0001-01-01","objectID":"/%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95%E7%AC%94%E8%AE%B0-1/:0:0","tags":["游戏开发"],"title":"压力测试笔记 1","uri":"/%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95%E7%AC%94%E8%AE%B0-1/"}]